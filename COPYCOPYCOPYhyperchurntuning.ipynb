{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        },
        "id": "OgV3aHz4yoke",
        "outputId": "d59d0150-b527-42aa-be5c-de992882fe65"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-2bc37157-3e87-4426-bc49-67535539cc5d\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-2bc37157-3e87-4426-bc49-67535539cc5d\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving sampledtesting2.csv to sampledtesting2.csv\n",
            "Saving sampledtraining2.csv to sampledtraining2.csv\n"
          ]
        }
      ],
      "source": [
        "from google.colab import files\n",
        "uploaded=files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "_bkG-YPOytYL"
      },
      "outputs": [],
      "source": [
        "import io\n",
        "import pandas as pd\n",
        "training=pd.read_csv(io.BytesIO(uploaded['sampledtraining2.csv']))\n",
        "testing=pd.read_csv(io.BytesIO(uploaded['sampledtesting2.csv']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "Kue4Z6pEI-dx",
        "outputId": "e0cb320b-ddda-4d78-ac19-e8da3f5c39b1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Unnamed: 0  credit_score  country  gender  age  tenure   balance  \\\n",
              "0        2611     -0.839783        0       0  2.0     0.0  0.436870   \n",
              "1        5368     -1.125050        0       1  3.0     0.0 -0.101940   \n",
              "2       14513      1.034827        2       1  2.0     1.0  0.427989   \n",
              "3        8904      0.352225        1       0  1.0     0.0  0.225041   \n",
              "4        1021     -1.665020        1       0  1.0     1.0  0.342498   \n",
              "\n",
              "   products_number  credit_card  active_member  estimated_salary  churn  \n",
              "0                1            1              1          0.987657      0  \n",
              "1                1            0              0         -1.445631      1  \n",
              "2                1            1              0          0.443701      1  \n",
              "3                1            1              1          0.279804      1  \n",
              "4                2            1              1          1.623358      0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3c159d3d-087e-429a-9350-7fa1f4c2bbbc\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>credit_score</th>\n",
              "      <th>country</th>\n",
              "      <th>gender</th>\n",
              "      <th>age</th>\n",
              "      <th>tenure</th>\n",
              "      <th>balance</th>\n",
              "      <th>products_number</th>\n",
              "      <th>credit_card</th>\n",
              "      <th>active_member</th>\n",
              "      <th>estimated_salary</th>\n",
              "      <th>churn</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2611</td>\n",
              "      <td>-0.839783</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.436870</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.987657</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5368</td>\n",
              "      <td>-1.125050</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.101940</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>-1.445631</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>14513</td>\n",
              "      <td>1.034827</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.427989</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.443701</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>8904</td>\n",
              "      <td>0.352225</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.225041</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.279804</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1021</td>\n",
              "      <td>-1.665020</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.342498</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1.623358</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3c159d3d-087e-429a-9350-7fa1f4c2bbbc')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-3c159d3d-087e-429a-9350-7fa1f4c2bbbc button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-3c159d3d-087e-429a-9350-7fa1f4c2bbbc');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "training.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yzCTbxVm0OOI",
        "outputId": "adec7be9-fc33-44b9-a936-ffd82849feb0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting scikit-plot\n",
            "  Downloading scikit_plot-0.3.7-py3-none-any.whl (33 kB)\n",
            "Requirement already satisfied: joblib>=0.10 in /usr/local/lib/python3.7/dist-packages (from scikit-plot) (1.2.0)\n",
            "Requirement already satisfied: scipy>=0.9 in /usr/local/lib/python3.7/dist-packages (from scikit-plot) (1.7.3)\n",
            "Requirement already satisfied: scikit-learn>=0.18 in /usr/local/lib/python3.7/dist-packages (from scikit-plot) (1.0.2)\n",
            "Requirement already satisfied: matplotlib>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from scikit-plot) (3.2.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=1.4.0->scikit-plot) (3.0.9)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=1.4.0->scikit-plot) (1.4.4)\n",
            "Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=1.4.0->scikit-plot) (1.21.6)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=1.4.0->scikit-plot) (0.11.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=1.4.0->scikit-plot) (2.8.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib>=1.4.0->scikit-plot) (4.1.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib>=1.4.0->scikit-plot) (1.15.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.18->scikit-plot) (3.1.0)\n",
            "Installing collected packages: scikit-plot\n",
            "Successfully installed scikit-plot-0.3.7\n"
          ]
        }
      ],
      "source": [
        "!pip install scikit-plot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O_ynI2Yd0Y_9",
        "outputId": "45d46961-b375-4a4a-9172-4504114a1d44"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting keras_tuner\n",
            "  Downloading keras_tuner-1.1.3-py3-none-any.whl (135 kB)\n",
            "\u001b[K     |████████████████████████████████| 135 kB 4.2 MB/s \n",
            "\u001b[?25hCollecting kt-legacy\n",
            "  Downloading kt_legacy-1.0.4-py3-none-any.whl (9.6 kB)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.7/dist-packages (from keras_tuner) (2.9.1)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.7/dist-packages (from keras_tuner) (7.9.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from keras_tuner) (21.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from keras_tuner) (1.21.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from keras_tuner) (2.23.0)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from ipython->keras_tuner) (4.8.0)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython->keras_tuner) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.7/dist-packages (from ipython->keras_tuner) (5.1.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython->keras_tuner) (4.4.2)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython->keras_tuner) (2.6.1)\n",
            "Requirement already satisfied: prompt-toolkit<2.1.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from ipython->keras_tuner) (2.0.10)\n",
            "Collecting jedi>=0.10\n",
            "  Downloading jedi-0.18.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.6 MB 35.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: backcall in /usr/local/lib/python3.7/dist-packages (from ipython->keras_tuner) (0.2.0)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython->keras_tuner) (57.4.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from jedi>=0.10->ipython->keras_tuner) (0.8.3)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.1.0,>=2.0.0->ipython->keras_tuner) (1.15.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.1.0,>=2.0.0->ipython->keras_tuner) (0.2.5)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->keras_tuner) (3.0.9)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect->ipython->keras_tuner) (0.7.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->keras_tuner) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->keras_tuner) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->keras_tuner) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->keras_tuner) (2022.9.24)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras_tuner) (0.6.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras_tuner) (3.4.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras_tuner) (0.4.6)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras_tuner) (3.19.6)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras_tuner) (0.38.4)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras_tuner) (1.50.0)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras_tuner) (1.0.1)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras_tuner) (1.3.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras_tuner) (1.8.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras_tuner) (2.14.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard->keras_tuner) (0.2.8)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard->keras_tuner) (5.2.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard->keras_tuner) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard->keras_tuner) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard->keras_tuner) (4.13.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard->keras_tuner) (4.1.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard->keras_tuner) (3.10.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard->keras_tuner) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard->keras_tuner) (3.2.2)\n",
            "Installing collected packages: jedi, kt-legacy, keras-tuner\n",
            "Successfully installed jedi-0.18.2 keras-tuner-1.1.3 kt-legacy-1.0.4\n"
          ]
        }
      ],
      "source": [
        "!pip install keras_tuner"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "UntG4md70ZxF"
      },
      "outputs": [],
      "source": [
        "\n",
        "import keras_tuner"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "z3X-1P1D0P6I"
      },
      "outputs": [],
      "source": [
        "import scikitplot as skplt\n",
        "from sklearn.metrics import roc_curve,auc\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "DizGv2J6Oh9e"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "Hw5XaoBjjBQD"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d0ZLamj9zKUe"
      },
      "outputs": [],
      "source": [
        "\n",
        "def my_l1(weights):\n",
        "    return tf.reduce_sum(tf.abs(0.01*weights))\n",
        "class hypermodel3(keras_tuner.HyperModel):\n",
        "    def build(self,hp):\n",
        "        model=keras.Sequential(\n",
        "      [tf.keras.layers.Dense(units=hp.Int(f\"units_1\", min_value=28, max_value=56, step=4),\n",
        "                                          activation=hp.Choice(f\"activation_1\", [\"relu\", \"tanh\"])),\n",
        "       tf.keras.layers.BatchNormalization(),\n",
        "       tf.keras.layers.Dropout(.2),\n",
        "        tf.keras.layers.Dense(units=hp.Int(f\"units_2\", min_value=24, max_value=52,step=4),activation=hp.Choice(f\"activation_2\", [\"relu\", \"tanh\"])),\n",
        "       tf.keras.layers.BatchNormalization(),\n",
        "       tf.keras.layers.Dropout(.2),\n",
        "        #tf.keras.layers.Dense(units=hp.Int(f\"units_3\", min_value=16, max_value=44,step=4),activation=hp.Choice(f\"activation_3\", [\"relu\", \"tanh\"])),\n",
        "       tf.keras.layers.BatchNormalization(),\n",
        "       tf.keras.layers.Dropout(.2),\n",
        "        tf.keras.layers.Dense(units=hp.Int(f\"units_4\", min_value=2, max_value=30, step=4),activation=hp.Choice(f\"activation_4\", [\"relu\", \"tanh\"])),\n",
        "       tf.keras.layers.BatchNormalization(),\n",
        "       tf.keras.layers.Dropout(.2),\n",
        "        #tf.keras.layers.Dense(units=hp.Int(f\"units_5\", min_value=2, max_value=30, step=4),activation=hp.Choice(f\"activation_5\", [\"relu\", \"tanh\"])),\n",
        "       tf.keras.layers.BatchNormalization(),\n",
        "       #tf.keras.layers.Dropout(.2),\n",
        "        tf.keras.layers.Dense(units=hp.Int(f\"units_6\", min_value=24, max_value=52,step=4),activation=hp.Choice(f\"activation_6\", [\"relu\", \"tanh\"])),\n",
        "       tf.keras.layers.BatchNormalization(),\n",
        "       #tf.keras.layers.Dropout(.2),\n",
        "        tf.keras.layers.Dense(units=hp.Int(f\"units_7\", min_value=28, max_value=56, step=4),activation=hp.Choice(f\"activation_7\", [\"relu\", \"tanh\"]),\n",
        "                                                                                                                  ),\n",
        "       tf.keras.layers.BatchNormalization(),\n",
        "       tf.keras.layers.Dropout(.2),\n",
        "        tf.keras.layers.Dense(1,activation='sigmoid')])\n",
        "        model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.01),loss=\"mse\",metrics =[\"accuracy\"])\n",
        "        return model\n",
        "    def fit(self,hp,model,x,y,*args,**kwargs):\n",
        "        return model.fit(x,y,**kwargs)\n",
        "    def predict(self,hp,model,x,**kwargs):\n",
        "        return model.predict(x,**kwargs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QeFMGGYEiwzc"
      },
      "outputs": [],
      "source": [
        "\n",
        "class hypermodel3L(keras_tuner.HyperModel):\n",
        "    def build(self,hp):\n",
        "        model=keras.Sequential(\n",
        "      [tf.keras.layers.Dense(units=hp.Int(f\"units_1\", min_value=28, max_value=56, step=4),\n",
        "                                          activation=hp.Choice(f\"activation_1\", [\"relu\", \"tanh\"])),\n",
        "       tf.keras.layers.BatchNormalization(),\n",
        "       tf.keras.layers.Dropout(hp.Float(\"dropout1\",.01,.02,.002)),\n",
        "        tf.keras.layers.Dense(units=hp.Int(f\"units_2\", min_value=24, max_value=52,step=4),activation=hp.Choice(f\"activation_2\", [\"relu\", \"tanh\"])),\n",
        "       tf.keras.layers.BatchNormalization(),\n",
        "       tf.keras.layers.Dropout(.2),\n",
        "        #tf.keras.layers.Dense(units=hp.Int(f\"units_3\", min_value=16, max_value=44,step=4),activation=hp.Choice(f\"activation_3\", [\"relu\", \"tanh\"])),\n",
        "       tf.keras.layers.BatchNormalization(),\n",
        "       tf.keras.layers.Dropout(.2),\n",
        "        tf.keras.layers.Dense(units=hp.Int(f\"units_4\", min_value=2, max_value=30, step=4),activation=hp.Choice(f\"activation_4\", [\"relu\", \"tanh\"])),\n",
        "       tf.keras.layers.BatchNormalization(),\n",
        "       tf.keras.layers.Dropout(.2),\n",
        "        #tf.keras.layers.Dense(units=hp.Int(f\"units_5\", min_value=2, max_value=30, step=4),activation=hp.Choice(f\"activation_5\", [\"relu\", \"tanh\"])),\n",
        "       tf.keras.layers.BatchNormalization(),\n",
        "       #tf.keras.layers.Dropout(.2),\n",
        "        tf.keras.layers.Dense(units=hp.Int(f\"units_6\", min_value=24, max_value=52,step=4),activation=hp.Choice(f\"activation_6\", [\"relu\", \"tanh\"])),\n",
        "       tf.keras.layers.BatchNormalization(),\n",
        "       #tf.keras.layers.Dropout(.2),\n",
        "        tf.keras.layers.Dense(units=hp.Int(f\"units_7\", min_value=28, max_value=56, step=4),activation=hp.Choice(f\"activation_7\", [\"relu\", \"tanh\"]),\n",
        "                                                                                                                  kernel_regularizer=my_l1),\n",
        "       tf.keras.layers.BatchNormalization(),\n",
        "       tf.keras.layers.Dropout(.2),\n",
        "        tf.keras.layers.Dense(1,activation='sigmoid')])\n",
        "        model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.01),loss=\"mse\",metrics =[\"accuracy\"])\n",
        "        return model\n",
        "    def fit(self,hp,model,x,y,*args,**kwargs):\n",
        "        return model.fit(x,y,**kwargs)\n",
        "    def predict(self,hp,model,x,**kwargs):\n",
        "        return model.predict(x,**kwargs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "QcTjNSl-1Wdj"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "from collections import deque\n",
        "# list like container with fast appens and pops on either end \n",
        "class hypermodel3Ltwo(keras_tuner.HyperModel):\n",
        "    def build(self,hp):\n",
        "        model=keras.Sequential(\n",
        "      [tf.keras.layers.Dense(units=hp.Int(f\"units_1\", min_value=18, max_value=46, step=4),\n",
        "                                          activation=hp.Choice(f\"activation_1\", [\"relu\", \"tanh\"])),\n",
        "       #tf.keras.layers.BatchNormalization(),\n",
        "       #tf.keras.layers.Dropout(rate=hp.Float(\"dropout1\", 0.0,.02,.002)),\n",
        "        tf.keras.layers.Dense(units=hp.Int(f\"units_2\", min_value=14, max_value=42,step=4),activation=hp.Choice(f\"activation_2\", [\"relu\", \"tanh\"])),\n",
        "       #tf.keras.layers.BatchNormalization(),\n",
        "       #tf.keras.layers.Dropout(rate=hp.Float(\"dropout2\", 0.0,.02,.002)),\n",
        "        tf.keras.layers.Dense(units=hp.Int(f\"units_3\", min_value=16, max_value=44,step=4),activation=hp.Choice(f\"activation_3\", [\"relu\", \"tanh\"])),\n",
        "       #tf.keras.layers.BatchNormalization(),\n",
        "       #tf.keras.layers.Dropout(units=hp.Float(\"dropout2\", .01,.02,.002)),\n",
        "        tf.keras.layers.Dense(units=hp.Int(f\"units_4\", min_value=2, max_value=10, step=4),activation=hp.Choice(f\"activation_4\", [\"relu\", \"tanh\"])),\n",
        "      # tf.keras.layers.BatchNormalization(),\n",
        "       #tf.keras.layers.Dropout(rate=hp.Float(\"dropout4\", 0.0,.02,.002)),\n",
        "        #tf.keras.layers.Dense(units=hp.Int(f\"units_5\", min_value=2, max_value=30, step=4),activation=hp.Choice(f\"activation_5\", [\"relu\", \"tanh\"])),\n",
        "       #tf.keras.layers.BatchNormalization(),\n",
        "       #tf.keras.layers.Dropout(.2),\n",
        "        tf.keras.layers.Dense(units=hp.Int(f\"units_6\", min_value=14, max_value=32,step=4),activation=hp.Choice(f\"activation_6\", [\"relu\", \"tanh\"])),\n",
        "       #tf.keras.layers.BatchNormalization(),\n",
        "       #tf.keras.layers.Dropout(.2),\n",
        "        tf.keras.layers.Dense(units=hp.Int(f\"units_7\", min_value=18, max_value=36, step=4),activation=hp.Choice(f\"activation_7\", [\"relu\", \"tanh\"]),\n",
        "                                                                                                                  ),\n",
        "       #tf.keras.layers.BatchNormalization(),\n",
        "       #f.keras.layers.Dropout(rate=hp.Float(\"dropout7\", .01,.02,.002)),\n",
        "        tf.keras.layers.Dense(1,activation='sigmoid')])\n",
        "        model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.01),loss=\"binary_crossentropy\",metrics =[tf.keras.metrics.BinaryCrossentropy(from_logits=False)])\n",
        "        return model\n",
        "    def fit(self,hp,model,x,y,batch_size,epochs,xval,yval,**kwargs):\n",
        "        #x,xval,y,yval=train_test_split(training.drop('churn',axis=1).values,training.churn.values.reshape(-1,1),test_size=hp.Float(f\"val_split\", 0.1,0.4,.02))\n",
        "        epochs=hp.Int(f\"epochs\",2000,2200,100)\n",
        "        batch_size=hp.Int(f\"batch_size\",300,540,20)\n",
        "        #loss_fn=keras.losses.MeanSquaredError()\n",
        "        loss_fn=tf.keras.losses.BinaryCrossentropy(from_logits=False)\n",
        "        lr=hp.Float(f\"learning_rate\", .0001,.03,.0001)\n",
        "        optimizer=keras.optimizers.Adam(learning_rate=lr)\n",
        "        #train_acc_metric=keras.metrics.MeanSquaredError()\n",
        "        train_acc_metric = tf.keras.metrics.BinaryCrossentropy(from_logits=False)\n",
        "        #val_acc_metric=keras.metrics.MeanSquaredError()\n",
        "        val_acc_metric=tf.keras.metrics.AUC(from_logits=False)\n",
        "        train_dataset = tf.data.Dataset.from_tensor_slices((x,y))\n",
        "        train_dataset = train_dataset.batch(batch_size)\n",
        "        val_dataset = tf.data.Dataset.from_tensor_slices((xval, yval))\n",
        "        val_dataset = val_dataset.batch(batch_size)\n",
        "        patience=3\n",
        "        delta=0.001\n",
        "        loss_history=deque(maxlen=patience+1)\n",
        "\n",
        "        @tf.function\n",
        "        def train_step(x, y):\n",
        "            with tf.GradientTape() as tape:\n",
        "                logits = model(x, training=True)\n",
        "                loss_value = loss_fn(y, logits)\n",
        "        # Add any extra losses created during the forward pass.\n",
        "                loss_value += sum(model.losses)\n",
        "            \n",
        "            grads = tape.gradient(loss_value, model.trainable_weights)\n",
        "            optimizer.apply_gradients(zip(grads, model.trainable_weights))\n",
        "            train_acc_metric.update_state(y, logits)\n",
        "            return loss_value\n",
        "        #@tf.function\n",
        "        #def train_step(x,y):\n",
        "        #    with tf.GradientTape() as tape:\n",
        "       #         logits=model(x,training=True)\n",
        "        #        loss_value=loss_fn(y,logits)\n",
        "        #    grads=tape.gradient(loss_value,model.trainable_weights )\n",
        "        #    train_acc_metric.update_state(y,logits)\n",
        "        #    return loss_value\n",
        "        \n",
        "        @tf.function\n",
        "        def test_step(x, y):\n",
        "            val_logits = model(x, training=False)\n",
        "            val_acc_metric.update_state(y, val_logits)\n",
        "        \n",
        "        for epoch in range(epochs):\n",
        "            print(\"\\nStart of epoch %d\" % (epoch,))\n",
        "            start_time = time.time()\n",
        "\n",
        "    # Iterate over the batches of the dataset.\n",
        "            for step, (x_batch_train,y_batch_train ) in enumerate(train_dataset):\n",
        "                loss_value = train_step(x_batch_train, y_batch_train)\n",
        "\n",
        "        # Log every 200 batches.\n",
        "                if step % 200 == 0:\n",
        "                    print(\n",
        "                        \"Training loss (for one batch) at step %d: %.4f\"\n",
        "                        % (step, float(loss_value))\n",
        "                         )\n",
        "                    print(\"Seen so far: %d samples\" % ((step + 1) * batch_size))\n",
        "\n",
        "    # Display metrics at the end of each epoch.\n",
        "            train_acc = train_acc_metric.result()\n",
        "            print(\"Training acc over epoch: %.4f\" % (float(train_acc),))\n",
        "\n",
        "    # Reset training metrics at the end of each epoch\n",
        "            train_acc_metric.reset_states()\n",
        "\n",
        "\n",
        "            for x_batch_val, y_batch_val in val_dataset:\n",
        "                test_step(x_batch_val, y_batch_val)\n",
        "            loss_history.append(train_acc_metric.result())\n",
        "            val_acc = val_acc_metric.result()\n",
        "            val_acc_metric.reset_states()\n",
        "            print(\"Validation acc: %.4f\" % (float(val_acc),))\n",
        "            print(\"Time taken: %.2fs\" % (time.time() - start_time))\n",
        "            \n",
        "            if len(loss_history) > patience:\n",
        "                if loss_history.popleft()*delta < min(loss_history):\n",
        "                    print(f'\\nEarly stopping. No improvement of more than {delta:.5%} in '\n",
        "                  f'validation loss in the last {patience} epochs.')\n",
        "                    break \n",
        "        return {\n",
        "            \"metric_a\": loss_value,\n",
        "            \"metric_b\": val_acc,\n",
        "        }\n",
        "\n",
        "\n",
        "\n",
        "    def predict(self,hp,model,x,*args,**kwargs):\n",
        "        return model.predict(x,*args,**kwargs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KlNfoBkZuQsL"
      },
      "outputs": [],
      "source": [
        "class hypermodel3Ltwo2(keras_tuner.HyperModel):\n",
        "    def build(self,hp):\n",
        "        model=keras.Sequential(\n",
        "      [tf.keras.layers.Dense(units=hp.Int(f\"units_1\", min_value=18, max_value=46, step=4),\n",
        "                                          activation=hp.Choice(f\"activation_1\", [\"relu\", \"tanh\"])),\n",
        "       tf.keras.layers.BatchNormalization(),\n",
        "       tf.keras.layers.Dropout(rate=hp.Float(\"dropout1\", .01,.02,.002)),\n",
        "        tf.keras.layers.Dense(units=hp.Int(f\"units_2\", min_value=14, max_value=42,step=4),activation=hp.Choice(f\"activation_2\", [\"relu\", \"tanh\"])),\n",
        "       tf.keras.layers.BatchNormalization(),\n",
        "       tf.keras.layers.Dropout(rate=hp.Float(\"dropout2\", 0.0,.02,.002)),\n",
        "        #tf.keras.layers.Dense(units=hp.Int(f\"units_3\", min_value=16, max_value=44,step=4),activation=hp.Choice(f\"activation_3\", [\"relu\", \"tanh\"])),\n",
        "       tf.keras.layers.BatchNormalization(),\n",
        "       #tf.keras.layers.Dropout(units=hp.Float(\"dropout2\", .01,.02,.002)),\n",
        "        tf.keras.layers.Dense(units=hp.Int(f\"units_4\", min_value=2, max_value=10, step=4),activation=hp.Choice(f\"activation_4\", [\"relu\", \"tanh\"])),\n",
        "       tf.keras.layers.BatchNormalization(),\n",
        "       tf.keras.layers.Dropout(rate=hp.Float(\"dropout4\", 0.0,.02,.002)),\n",
        "        #tf.keras.layers.Dense(units=hp.Int(f\"units_5\", min_value=2, max_value=30, step=4),activation=hp.Choice(f\"activation_5\", [\"relu\", \"tanh\"])),\n",
        "       tf.keras.layers.BatchNormalization(),\n",
        "       #tf.keras.layers.Dropout(.2),\n",
        "        tf.keras.layers.Dense(units=hp.Int(f\"units_6\", min_value=14, max_value=32,step=4),activation=hp.Choice(f\"activation_6\", [\"relu\", \"tanh\"])),\n",
        "       tf.keras.layers.BatchNormalization(),\n",
        "       #tf.keras.layers.Dropout(.2),\n",
        "        tf.keras.layers.Dense(units=hp.Int(f\"units_7\", min_value=18, max_value=36, step=4),activation=hp.Choice(f\"activation_7\", [\"relu\", \"tanh\"]),\n",
        "                                                                                                                  ),\n",
        "       tf.keras.layers.BatchNormalization(),\n",
        "       tf.keras.layers.Dropout(rate=hp.Float(\"dropout7\", 0.0,.02,.002)),\n",
        "        tf.keras.layers.Dense(1,activation='sigmoid')])\n",
        "        model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.01),loss=\"mse\",metrics =[\"loss\"])\n",
        "        return model\n",
        "    def fit(self,hp,model,x,y,**kwargs):\n",
        "        return model.fit(x,y,**kwargs)\n",
        "    def predict(self,hp,model,x,**kwargs):\n",
        "        return model.predict(x,**kwargs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "6nn6j1rBi3_o",
        "outputId": "852a5699-a1b9-4f4f-f81c-cf7d5bd79f44"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Trial 6 Complete [00h 03m 20s]\n",
            "loss: 0.27194899320602417\n",
            "\n",
            "Best loss So Far: 0.12703856825828552\n",
            "Total elapsed time: 00h 19m 59s\n",
            "\n",
            "Search: Running Trial #7\n",
            "\n",
            "Value             |Best Value So Far |Hyperparameter\n",
            "52                |44                |units_1\n",
            "relu              |relu              |activation_1\n",
            "0.018             |0.012             |dropout1\n",
            "28                |32                |units_2\n",
            "relu              |relu              |activation_2\n",
            "22                |6                 |units_4\n",
            "tanh              |relu              |activation_4\n",
            "40                |44                |units_6\n",
            "tanh              |relu              |activation_6\n",
            "32                |40                |units_7\n",
            "tanh              |tanh              |activation_7\n",
            "\n",
            "Epoch 1/700\n",
            "28/28 [==============================] - 3s 19ms/step - loss: 0.9361 - accuracy: 0.8445 - val_loss: 0.4019 - val_accuracy: 0.5896\n",
            "Epoch 2/700\n",
            "28/28 [==============================] - 0s 9ms/step - loss: 0.2227 - accuracy: 0.8530 - val_loss: 0.2755 - val_accuracy: 0.7054\n",
            "Epoch 3/700\n",
            "28/28 [==============================] - 0s 11ms/step - loss: 0.1733 - accuracy: 0.8589 - val_loss: 0.2305 - val_accuracy: 0.7972\n",
            "Epoch 4/700\n",
            "28/28 [==============================] - 0s 8ms/step - loss: 0.1859 - accuracy: 0.8594 - val_loss: 0.1851 - val_accuracy: 0.8599\n",
            "Epoch 5/700\n",
            "28/28 [==============================] - 0s 9ms/step - loss: 0.1798 - accuracy: 0.8580 - val_loss: 0.2068 - val_accuracy: 0.8273\n",
            "Epoch 6/700\n",
            "28/28 [==============================] - 0s 9ms/step - loss: 0.1751 - accuracy: 0.8640 - val_loss: 0.1962 - val_accuracy: 0.8619\n",
            "Epoch 7/700\n",
            "28/28 [==============================] - 0s 9ms/step - loss: 0.1826 - accuracy: 0.8597 - val_loss: 0.2248 - val_accuracy: 0.8301\n",
            "Epoch 8/700\n",
            "28/28 [==============================] - 0s 10ms/step - loss: 0.1821 - accuracy: 0.8591 - val_loss: 0.2362 - val_accuracy: 0.7514\n",
            "Epoch 9/700\n",
            "28/28 [==============================] - 0s 9ms/step - loss: 0.1971 - accuracy: 0.8581 - val_loss: 0.3380 - val_accuracy: 0.6973\n",
            "Epoch 10/700\n",
            "28/28 [==============================] - 0s 8ms/step - loss: 0.2072 - accuracy: 0.8578 - val_loss: 0.2831 - val_accuracy: 0.7695\n",
            "Epoch 11/700\n",
            "28/28 [==============================] - 0s 9ms/step - loss: 0.1879 - accuracy: 0.8616 - val_loss: 0.2395 - val_accuracy: 0.7162\n",
            "Epoch 12/700\n",
            "28/28 [==============================] - 0s 9ms/step - loss: 0.1646 - accuracy: 0.8590 - val_loss: 0.2274 - val_accuracy: 0.7157\n",
            "Epoch 13/700\n",
            "28/28 [==============================] - 0s 10ms/step - loss: 0.1680 - accuracy: 0.8593 - val_loss: 0.1639 - val_accuracy: 0.8605\n",
            "Epoch 14/700\n",
            "28/28 [==============================] - 0s 10ms/step - loss: 0.1786 - accuracy: 0.8565 - val_loss: 0.1698 - val_accuracy: 0.8546\n",
            "Epoch 15/700\n",
            "28/28 [==============================] - 0s 9ms/step - loss: 0.1488 - accuracy: 0.8589 - val_loss: 0.2262 - val_accuracy: 0.4891\n",
            "Epoch 16/700\n",
            "28/28 [==============================] - 0s 9ms/step - loss: 0.1482 - accuracy: 0.8608 - val_loss: 0.2544 - val_accuracy: 0.7963\n",
            "Epoch 17/700\n",
            "28/28 [==============================] - 0s 8ms/step - loss: 0.1765 - accuracy: 0.8596 - val_loss: 0.2294 - val_accuracy: 0.4891\n",
            "Epoch 18/700\n",
            "28/28 [==============================] - 0s 10ms/step - loss: 0.1548 - accuracy: 0.8575 - val_loss: 0.2522 - val_accuracy: 0.4891\n",
            "Epoch 19/700\n",
            "28/28 [==============================] - 0s 11ms/step - loss: 0.1323 - accuracy: 0.8581 - val_loss: 0.1945 - val_accuracy: 0.8039\n",
            "Epoch 20/700\n",
            "28/28 [==============================] - 0s 8ms/step - loss: 0.1725 - accuracy: 0.8585 - val_loss: 0.1898 - val_accuracy: 0.8262\n",
            "Epoch 21/700\n",
            "28/28 [==============================] - 0s 8ms/step - loss: 0.1446 - accuracy: 0.8624 - val_loss: 0.1594 - val_accuracy: 0.8488\n",
            "Epoch 22/700\n",
            "28/28 [==============================] - 0s 11ms/step - loss: 0.1323 - accuracy: 0.8596 - val_loss: 0.2318 - val_accuracy: 0.4891\n",
            "Epoch 23/700\n",
            "28/28 [==============================] - 0s 13ms/step - loss: 0.1494 - accuracy: 0.8600 - val_loss: 0.1721 - val_accuracy: 0.8401\n",
            "Epoch 24/700\n",
            "28/28 [==============================] - 0s 14ms/step - loss: 0.1354 - accuracy: 0.8622 - val_loss: 0.1597 - val_accuracy: 0.8393\n",
            "Epoch 25/700\n",
            "28/28 [==============================] - 0s 8ms/step - loss: 0.1423 - accuracy: 0.8616 - val_loss: 0.1816 - val_accuracy: 0.8033\n",
            "Epoch 26/700\n",
            "28/28 [==============================] - 0s 9ms/step - loss: 0.1320 - accuracy: 0.8641 - val_loss: 0.2299 - val_accuracy: 0.7681\n",
            "Epoch 27/700\n",
            "28/28 [==============================] - 0s 8ms/step - loss: 0.1416 - accuracy: 0.8606 - val_loss: 0.2313 - val_accuracy: 0.4891\n",
            "Epoch 28/700\n",
            "28/28 [==============================] - 0s 8ms/step - loss: 0.1342 - accuracy: 0.8606 - val_loss: 0.1711 - val_accuracy: 0.8387\n",
            "Epoch 29/700\n",
            "28/28 [==============================] - 0s 10ms/step - loss: 0.1414 - accuracy: 0.8593 - val_loss: 0.1647 - val_accuracy: 0.8393\n",
            "Epoch 30/700\n",
            "28/28 [==============================] - 0s 9ms/step - loss: 0.1492 - accuracy: 0.8565 - val_loss: 0.1632 - val_accuracy: 0.8574\n",
            "Epoch 31/700\n",
            "28/28 [==============================] - 0s 8ms/step - loss: 0.1474 - accuracy: 0.8597 - val_loss: 0.1683 - val_accuracy: 0.8574\n",
            "Epoch 32/700\n",
            "28/28 [==============================] - 0s 8ms/step - loss: 0.1411 - accuracy: 0.8620 - val_loss: 0.2183 - val_accuracy: 0.7804\n",
            "Epoch 33/700\n",
            "28/28 [==============================] - 0s 8ms/step - loss: 0.1404 - accuracy: 0.8597 - val_loss: 0.2699 - val_accuracy: 0.7296\n",
            "Epoch 34/700\n",
            "28/28 [==============================] - 0s 11ms/step - loss: 0.1306 - accuracy: 0.8585 - val_loss: 0.2473 - val_accuracy: 0.7330\n",
            "Epoch 35/700\n",
            "28/28 [==============================] - 0s 8ms/step - loss: 0.1315 - accuracy: 0.8615 - val_loss: 0.2203 - val_accuracy: 0.7885\n",
            "Epoch 36/700\n",
            "28/28 [==============================] - 0s 11ms/step - loss: 0.1290 - accuracy: 0.8587 - val_loss: 0.2482 - val_accuracy: 0.4891\n",
            "Epoch 37/700\n",
            "28/28 [==============================] - 0s 10ms/step - loss: 0.1321 - accuracy: 0.8615 - val_loss: 0.2002 - val_accuracy: 0.4891\n",
            "Epoch 38/700\n",
            "28/28 [==============================] - 0s 7ms/step - loss: 0.1291 - accuracy: 0.8610 - val_loss: 0.1645 - val_accuracy: 0.8357\n",
            "Epoch 39/700\n",
            "28/28 [==============================] - 0s 9ms/step - loss: 0.1266 - accuracy: 0.8591 - val_loss: 0.2142 - val_accuracy: 0.4891\n",
            "Epoch 40/700\n",
            "28/28 [==============================] - 0s 8ms/step - loss: 0.1368 - accuracy: 0.8585 - val_loss: 0.1915 - val_accuracy: 0.8616\n",
            "Epoch 41/700\n",
            "28/28 [==============================] - 0s 10ms/step - loss: 0.1477 - accuracy: 0.8596 - val_loss: 0.1408 - val_accuracy: 0.8560\n",
            "Epoch 42/700\n",
            "28/28 [==============================] - 0s 8ms/step - loss: 0.1283 - accuracy: 0.8634 - val_loss: 0.1580 - val_accuracy: 0.8544\n",
            "Epoch 43/700\n",
            "28/28 [==============================] - 0s 8ms/step - loss: 0.1287 - accuracy: 0.8585 - val_loss: 0.1441 - val_accuracy: 0.8580\n",
            "Epoch 44/700\n",
            "28/28 [==============================] - 0s 9ms/step - loss: 0.1403 - accuracy: 0.8612 - val_loss: 0.1401 - val_accuracy: 0.8630\n",
            "Epoch 45/700\n",
            "28/28 [==============================] - 0s 8ms/step - loss: 0.1316 - accuracy: 0.8600 - val_loss: 0.1591 - val_accuracy: 0.8563\n",
            "Epoch 46/700\n",
            "28/28 [==============================] - 0s 8ms/step - loss: 0.1386 - accuracy: 0.8596 - val_loss: 0.1396 - val_accuracy: 0.8630\n",
            "Epoch 47/700\n",
            "28/28 [==============================] - 0s 8ms/step - loss: 0.1359 - accuracy: 0.8577 - val_loss: 0.1824 - val_accuracy: 0.8231\n",
            "Epoch 48/700\n",
            "28/28 [==============================] - 0s 11ms/step - loss: 0.1256 - accuracy: 0.8663 - val_loss: 0.1809 - val_accuracy: 0.4891\n",
            "Epoch 49/700\n",
            "28/28 [==============================] - 0s 7ms/step - loss: 0.1329 - accuracy: 0.8585 - val_loss: 0.1375 - val_accuracy: 0.8650\n",
            "Epoch 50/700\n",
            "28/28 [==============================] - 0s 9ms/step - loss: 0.1290 - accuracy: 0.8578 - val_loss: 0.1706 - val_accuracy: 0.8518\n",
            "Epoch 51/700\n",
            "28/28 [==============================] - 0s 8ms/step - loss: 0.1271 - accuracy: 0.8585 - val_loss: 0.1603 - val_accuracy: 0.8507\n",
            "Epoch 52/700\n",
            "28/28 [==============================] - 0s 8ms/step - loss: 0.1261 - accuracy: 0.8587 - val_loss: 0.1295 - val_accuracy: 0.8636\n",
            "Epoch 53/700\n",
            "28/28 [==============================] - 0s 8ms/step - loss: 0.1271 - accuracy: 0.8632 - val_loss: 0.1418 - val_accuracy: 0.8624\n",
            "Epoch 54/700\n",
            "28/28 [==============================] - 0s 8ms/step - loss: 0.1272 - accuracy: 0.8614 - val_loss: 0.1449 - val_accuracy: 0.8415\n",
            "Epoch 55/700\n",
            "28/28 [==============================] - 0s 8ms/step - loss: 0.1290 - accuracy: 0.8616 - val_loss: 0.1992 - val_accuracy: 0.4891\n",
            "Epoch 56/700\n",
            "28/28 [==============================] - 0s 10ms/step - loss: 0.1243 - accuracy: 0.8633 - val_loss: 0.1926 - val_accuracy: 0.4891\n",
            "Epoch 57/700\n",
            "28/28 [==============================] - 0s 8ms/step - loss: 0.1333 - accuracy: 0.8624 - val_loss: 0.1823 - val_accuracy: 0.8516\n",
            "Epoch 58/700\n",
            "28/28 [==============================] - 0s 10ms/step - loss: 0.1393 - accuracy: 0.8626 - val_loss: 0.1348 - val_accuracy: 0.8658\n",
            "Epoch 59/700\n",
            "28/28 [==============================] - 0s 8ms/step - loss: 0.1299 - accuracy: 0.8604 - val_loss: 0.1408 - val_accuracy: 0.8401\n",
            "Epoch 60/700\n",
            "28/28 [==============================] - 0s 8ms/step - loss: 0.1442 - accuracy: 0.8615 - val_loss: 0.1427 - val_accuracy: 0.8482\n",
            "Epoch 61/700\n",
            "28/28 [==============================] - 0s 8ms/step - loss: 0.1322 - accuracy: 0.8602 - val_loss: 0.1403 - val_accuracy: 0.8518\n",
            "Epoch 62/700\n",
            "28/28 [==============================] - 0s 8ms/step - loss: 0.1287 - accuracy: 0.8597 - val_loss: 0.1367 - val_accuracy: 0.8463\n",
            "Epoch 63/700\n",
            "28/28 [==============================] - 0s 8ms/step - loss: 0.1277 - accuracy: 0.8632 - val_loss: 0.1486 - val_accuracy: 0.8326\n",
            "Epoch 64/700\n",
            "28/28 [==============================] - 0s 11ms/step - loss: 0.1242 - accuracy: 0.8617 - val_loss: 0.1877 - val_accuracy: 0.8449\n",
            "Epoch 65/700\n",
            "28/28 [==============================] - 0s 8ms/step - loss: 0.1251 - accuracy: 0.8600 - val_loss: 0.1632 - val_accuracy: 0.8175\n",
            "Epoch 66/700\n",
            "28/28 [==============================] - 0s 9ms/step - loss: 0.1291 - accuracy: 0.8599 - val_loss: 0.1965 - val_accuracy: 0.7263\n",
            "Epoch 67/700\n",
            "28/28 [==============================] - 0s 7ms/step - loss: 0.1273 - accuracy: 0.8605 - val_loss: 0.2056 - val_accuracy: 0.7408\n",
            "Epoch 68/700\n",
            "28/28 [==============================] - 0s 7ms/step - loss: 0.1307 - accuracy: 0.8602 - val_loss: 0.1992 - val_accuracy: 0.7486\n",
            "Epoch 69/700\n",
            "28/28 [==============================] - 0s 10ms/step - loss: 0.1303 - accuracy: 0.8543 - val_loss: 0.1792 - val_accuracy: 0.7581\n",
            "Epoch 70/700\n",
            "28/28 [==============================] - 0s 9ms/step - loss: 0.1250 - accuracy: 0.8596 - val_loss: 0.1726 - val_accuracy: 0.7759\n",
            "Epoch 71/700\n",
            "28/28 [==============================] - 0s 9ms/step - loss: 0.1242 - accuracy: 0.8632 - val_loss: 0.1698 - val_accuracy: 0.7983\n",
            "Epoch 72/700\n",
            "28/28 [==============================] - 0s 7ms/step - loss: 0.1252 - accuracy: 0.8599 - val_loss: 0.2241 - val_accuracy: 0.4891\n",
            "Epoch 73/700\n",
            "28/28 [==============================] - 0s 9ms/step - loss: 0.1253 - accuracy: 0.8606 - val_loss: 0.1806 - val_accuracy: 0.7759\n",
            "Epoch 74/700\n",
            "28/28 [==============================] - 0s 9ms/step - loss: 0.1223 - accuracy: 0.8630 - val_loss: 0.2233 - val_accuracy: 0.4891\n",
            "Epoch 75/700\n",
            "28/28 [==============================] - 0s 8ms/step - loss: 0.1258 - accuracy: 0.8590 - val_loss: 0.2190 - val_accuracy: 0.4891\n",
            "Epoch 76/700\n",
            "28/28 [==============================] - 0s 7ms/step - loss: 0.1267 - accuracy: 0.8621 - val_loss: 0.1359 - val_accuracy: 0.8485\n",
            "Epoch 77/700\n",
            "28/28 [==============================] - 0s 10ms/step - loss: 0.1221 - accuracy: 0.8647 - val_loss: 0.1340 - val_accuracy: 0.8644\n",
            "Epoch 78/700\n",
            "28/28 [==============================] - 0s 7ms/step - loss: 0.1223 - accuracy: 0.8633 - val_loss: 0.1594 - val_accuracy: 0.8273\n",
            "Epoch 79/700\n",
            "28/28 [==============================] - 0s 10ms/step - loss: 0.1228 - accuracy: 0.8632 - val_loss: 0.1959 - val_accuracy: 0.7640\n",
            "Epoch 80/700\n",
            "28/28 [==============================] - 0s 8ms/step - loss: 0.1229 - accuracy: 0.8630 - val_loss: 0.2642 - val_accuracy: 0.7475\n",
            "Epoch 81/700\n",
            "28/28 [==============================] - 0s 8ms/step - loss: 0.1222 - accuracy: 0.8632 - val_loss: 0.3040 - val_accuracy: 0.4891\n",
            "Epoch 82/700\n",
            "28/28 [==============================] - 0s 9ms/step - loss: 0.1255 - accuracy: 0.8575 - val_loss: 0.1881 - val_accuracy: 0.7999\n",
            "Epoch 83/700\n",
            "28/28 [==============================] - 0s 9ms/step - loss: 0.1253 - accuracy: 0.8604 - val_loss: 0.1485 - val_accuracy: 0.8312\n",
            "Epoch 84/700\n",
            "28/28 [==============================] - 0s 9ms/step - loss: 0.1247 - accuracy: 0.8612 - val_loss: 0.1317 - val_accuracy: 0.8524\n",
            "Epoch 85/700\n",
            "28/28 [==============================] - 0s 8ms/step - loss: 0.1231 - accuracy: 0.8622 - val_loss: 0.1260 - val_accuracy: 0.8666\n",
            "Epoch 86/700\n",
            "28/28 [==============================] - 0s 8ms/step - loss: 0.1281 - accuracy: 0.8620 - val_loss: 0.1389 - val_accuracy: 0.8426\n",
            "Epoch 87/700\n",
            "28/28 [==============================] - 0s 8ms/step - loss: 0.1278 - accuracy: 0.8615 - val_loss: 0.1638 - val_accuracy: 0.8337\n",
            "Epoch 88/700\n",
            "28/28 [==============================] - 0s 8ms/step - loss: 0.1271 - accuracy: 0.8651 - val_loss: 0.1574 - val_accuracy: 0.8136\n",
            "Epoch 89/700\n",
            "28/28 [==============================] - 0s 9ms/step - loss: 0.1299 - accuracy: 0.8561 - val_loss: 0.1386 - val_accuracy: 0.8474\n",
            "Epoch 90/700\n",
            "28/28 [==============================] - 0s 9ms/step - loss: 0.1280 - accuracy: 0.8586 - val_loss: 0.1498 - val_accuracy: 0.8348\n",
            "Epoch 91/700\n",
            "28/28 [==============================] - 0s 9ms/step - loss: 0.1235 - accuracy: 0.8623 - val_loss: 0.1398 - val_accuracy: 0.8583\n",
            "Epoch 92/700\n",
            "28/28 [==============================] - 0s 10ms/step - loss: 0.1220 - accuracy: 0.8646 - val_loss: 0.1641 - val_accuracy: 0.8474\n",
            "Epoch 93/700\n",
            "28/28 [==============================] - 0s 9ms/step - loss: 0.1228 - accuracy: 0.8654 - val_loss: 0.1531 - val_accuracy: 0.8454\n",
            "Epoch 94/700\n",
            "28/28 [==============================] - 0s 8ms/step - loss: 0.1239 - accuracy: 0.8650 - val_loss: 0.1461 - val_accuracy: 0.8290\n",
            "Epoch 95/700\n",
            "28/28 [==============================] - 0s 9ms/step - loss: 0.1233 - accuracy: 0.8633 - val_loss: 0.1354 - val_accuracy: 0.8474\n",
            "Epoch 96/700\n",
            "28/28 [==============================] - 0s 8ms/step - loss: 0.1264 - accuracy: 0.8603 - val_loss: 0.1597 - val_accuracy: 0.8348\n",
            "Epoch 97/700\n",
            "28/28 [==============================] - 0s 8ms/step - loss: 0.1280 - accuracy: 0.8589 - val_loss: 0.1825 - val_accuracy: 0.7999\n",
            "Epoch 98/700\n",
            "28/28 [==============================] - 0s 9ms/step - loss: 0.1255 - accuracy: 0.8615 - val_loss: 0.2003 - val_accuracy: 0.4891\n",
            "Epoch 99/700\n",
            "28/28 [==============================] - 0s 8ms/step - loss: 0.1263 - accuracy: 0.8600 - val_loss: 0.1810 - val_accuracy: 0.8172\n",
            "Epoch 100/700\n",
            "28/28 [==============================] - 0s 9ms/step - loss: 0.1252 - accuracy: 0.8615 - val_loss: 0.1780 - val_accuracy: 0.8287\n",
            "Epoch 101/700\n",
            "28/28 [==============================] - 0s 9ms/step - loss: 0.1255 - accuracy: 0.8604 - val_loss: 0.1812 - val_accuracy: 0.7902\n",
            "Epoch 102/700\n",
            "28/28 [==============================] - 0s 8ms/step - loss: 0.1276 - accuracy: 0.8591 - val_loss: 0.3370 - val_accuracy: 0.6526\n",
            "Epoch 103/700\n",
            "28/28 [==============================] - 0s 9ms/step - loss: 0.1379 - accuracy: 0.8639 - val_loss: 0.4145 - val_accuracy: 0.5324\n",
            "Epoch 104/700\n",
            "28/28 [==============================] - 0s 8ms/step - loss: 0.1329 - accuracy: 0.8615 - val_loss: 0.2148 - val_accuracy: 0.7818\n",
            "Epoch 105/700\n",
            "28/28 [==============================] - 0s 9ms/step - loss: 0.1325 - accuracy: 0.8573 - val_loss: 0.1924 - val_accuracy: 0.8041\n",
            "Epoch 106/700\n",
            "28/28 [==============================] - 0s 9ms/step - loss: 0.1273 - accuracy: 0.8603 - val_loss: 0.2123 - val_accuracy: 0.7701\n",
            "Epoch 107/700\n",
            "28/28 [==============================] - 0s 9ms/step - loss: 0.1290 - accuracy: 0.8569 - val_loss: 0.1679 - val_accuracy: 0.8105\n",
            "Epoch 108/700\n",
            "28/28 [==============================] - 0s 10ms/step - loss: 0.1263 - accuracy: 0.8592 - val_loss: 0.1398 - val_accuracy: 0.8468\n",
            "Epoch 109/700\n",
            "28/28 [==============================] - 0s 9ms/step - loss: 0.1255 - accuracy: 0.8627 - val_loss: 0.1686 - val_accuracy: 0.8242\n",
            "Epoch 110/700\n",
            "28/28 [==============================] - 0s 8ms/step - loss: 0.1274 - accuracy: 0.8610 - val_loss: 0.1421 - val_accuracy: 0.8594\n",
            "Epoch 111/700\n",
            "28/28 [==============================] - 0s 9ms/step - loss: 0.1327 - accuracy: 0.8622 - val_loss: 0.1375 - val_accuracy: 0.8644\n",
            "Epoch 112/700\n",
            "28/28 [==============================] - 0s 9ms/step - loss: 0.1269 - accuracy: 0.8644 - val_loss: 0.1338 - val_accuracy: 0.8652\n",
            "Epoch 113/700\n",
            "28/28 [==============================] - 0s 10ms/step - loss: 0.1240 - accuracy: 0.8636 - val_loss: 0.1835 - val_accuracy: 0.4891\n",
            "Epoch 114/700\n",
            "28/28 [==============================] - 0s 9ms/step - loss: 0.1284 - accuracy: 0.8602 - val_loss: 0.1419 - val_accuracy: 0.8516\n",
            "Epoch 115/700\n",
            "28/28 [==============================] - 0s 9ms/step - loss: 0.1230 - accuracy: 0.8640 - val_loss: 0.2201 - val_accuracy: 0.4891\n",
            "Epoch 116/700\n",
            "28/28 [==============================] - 0s 8ms/step - loss: 0.1276 - accuracy: 0.8609 - val_loss: 0.1567 - val_accuracy: 0.8253\n",
            "Epoch 117/700\n",
            "28/28 [==============================] - 0s 9ms/step - loss: 0.1318 - accuracy: 0.8581 - val_loss: 0.1784 - val_accuracy: 0.8223\n",
            "Epoch 118/700\n",
            "28/28 [==============================] - 0s 9ms/step - loss: 0.1317 - accuracy: 0.8586 - val_loss: 0.1576 - val_accuracy: 0.8092\n",
            "Epoch 119/700\n",
            "28/28 [==============================] - 0s 9ms/step - loss: 0.1262 - accuracy: 0.8621 - val_loss: 0.1577 - val_accuracy: 0.8052\n",
            "Epoch 120/700\n",
            "28/28 [==============================] - 0s 8ms/step - loss: 0.1260 - accuracy: 0.8621 - val_loss: 0.1627 - val_accuracy: 0.8027\n",
            "Epoch 121/700\n",
            "28/28 [==============================] - 0s 8ms/step - loss: 0.1274 - accuracy: 0.8623 - val_loss: 0.1909 - val_accuracy: 0.7455\n",
            "Epoch 122/700\n",
            "28/28 [==============================] - 0s 9ms/step - loss: 0.1262 - accuracy: 0.8602 - val_loss: 0.2035 - val_accuracy: 0.7667\n",
            "Epoch 123/700\n",
            "28/28 [==============================] - 0s 9ms/step - loss: 0.1243 - accuracy: 0.8642 - val_loss: 0.2415 - val_accuracy: 0.6306\n",
            "Epoch 124/700\n",
            "28/28 [==============================] - 0s 8ms/step - loss: 0.1246 - accuracy: 0.8636 - val_loss: 0.1811 - val_accuracy: 0.7561\n",
            "Epoch 125/700\n",
            "28/28 [==============================] - 0s 8ms/step - loss: 0.1254 - accuracy: 0.8627 - val_loss: 0.2345 - val_accuracy: 0.6267\n",
            "Epoch 126/700\n",
            "28/28 [==============================] - 0s 7ms/step - loss: 0.1225 - accuracy: 0.8652 - val_loss: 0.1589 - val_accuracy: 0.8574\n",
            "Epoch 127/700\n",
            "28/28 [==============================] - 0s 7ms/step - loss: 0.1231 - accuracy: 0.8648 - val_loss: 0.1669 - val_accuracy: 0.7849\n",
            "Epoch 128/700\n",
            "28/28 [==============================] - 0s 10ms/step - loss: 0.1280 - accuracy: 0.8602 - val_loss: 0.2896 - val_accuracy: 0.6261\n",
            "Epoch 129/700\n",
            "28/28 [==============================] - 0s 8ms/step - loss: 0.1292 - accuracy: 0.8642 - val_loss: 0.2557 - val_accuracy: 0.6747\n",
            "Epoch 130/700\n",
            "28/28 [==============================] - 0s 9ms/step - loss: 0.1267 - accuracy: 0.8622 - val_loss: 0.1921 - val_accuracy: 0.7344\n",
            "Epoch 131/700\n",
            "28/28 [==============================] - 0s 10ms/step - loss: 0.1267 - accuracy: 0.8618 - val_loss: 0.2001 - val_accuracy: 0.7333\n",
            "Epoch 132/700\n",
            "28/28 [==============================] - 0s 9ms/step - loss: 0.1260 - accuracy: 0.8617 - val_loss: 0.2402 - val_accuracy: 0.6682\n",
            "Epoch 133/700\n",
            "28/28 [==============================] - 0s 9ms/step - loss: 0.1248 - accuracy: 0.8630 - val_loss: 0.1700 - val_accuracy: 0.8242\n",
            "Epoch 134/700\n",
            "28/28 [==============================] - 0s 8ms/step - loss: 0.1239 - accuracy: 0.8626 - val_loss: 0.2291 - val_accuracy: 0.6702\n",
            "Epoch 135/700\n",
            "28/28 [==============================] - 0s 7ms/step - loss: 0.1268 - accuracy: 0.8604 - val_loss: 0.2457 - val_accuracy: 0.7439\n",
            "Epoch 136/700\n",
            "28/28 [==============================] - 0s 9ms/step - loss: 0.1249 - accuracy: 0.8611 - val_loss: 0.2005 - val_accuracy: 0.7852\n",
            "Epoch 137/700\n",
            "28/28 [==============================] - 0s 7ms/step - loss: 0.1243 - accuracy: 0.8620 - val_loss: 0.1828 - val_accuracy: 0.8170\n",
            "Epoch 138/700\n",
            "28/28 [==============================] - 0s 8ms/step - loss: 0.1257 - accuracy: 0.8581 - val_loss: 0.2995 - val_accuracy: 0.6925\n",
            "Epoch 139/700\n",
            "28/28 [==============================] - 0s 9ms/step - loss: 0.1225 - accuracy: 0.8636 - val_loss: 0.3248 - val_accuracy: 0.4891\n",
            "Epoch 140/700\n",
            "28/28 [==============================] - 0s 8ms/step - loss: 0.1255 - accuracy: 0.8589 - val_loss: 0.2295 - val_accuracy: 0.7737\n",
            "Epoch 141/700\n",
            "28/28 [==============================] - 0s 7ms/step - loss: 0.1234 - accuracy: 0.8614 - val_loss: 0.2274 - val_accuracy: 0.7812\n",
            "Epoch 142/700\n",
            "28/28 [==============================] - 0s 8ms/step - loss: 0.1245 - accuracy: 0.8626 - val_loss: 0.1924 - val_accuracy: 0.7974\n",
            "Epoch 143/700\n",
            "28/28 [==============================] - 0s 9ms/step - loss: 0.1230 - accuracy: 0.8638 - val_loss: 0.2018 - val_accuracy: 0.8050\n",
            "Epoch 144/700\n",
            "28/28 [==============================] - 0s 9ms/step - loss: 0.1247 - accuracy: 0.8600 - val_loss: 0.1996 - val_accuracy: 0.8122\n",
            "Epoch 145/700\n",
            "28/28 [==============================] - 0s 10ms/step - loss: 0.1228 - accuracy: 0.8645 - val_loss: 0.1287 - val_accuracy: 0.8563\n",
            "Epoch 146/700\n",
            "28/28 [==============================] - 0s 9ms/step - loss: 0.1235 - accuracy: 0.8628 - val_loss: 0.1282 - val_accuracy: 0.8605\n",
            "Epoch 147/700\n",
            "28/28 [==============================] - 0s 9ms/step - loss: 0.1257 - accuracy: 0.8614 - val_loss: 0.1294 - val_accuracy: 0.8521\n",
            "Epoch 148/700\n",
            "28/28 [==============================] - 0s 8ms/step - loss: 0.1238 - accuracy: 0.8632 - val_loss: 0.1676 - val_accuracy: 0.8382\n",
            "Epoch 149/700\n",
            "28/28 [==============================] - 0s 8ms/step - loss: 0.1224 - accuracy: 0.8640 - val_loss: 0.1670 - val_accuracy: 0.7807\n",
            "Epoch 150/700\n",
            "28/28 [==============================] - 0s 8ms/step - loss: 0.1251 - accuracy: 0.8616 - val_loss: 0.1316 - val_accuracy: 0.8610\n",
            "Epoch 151/700\n",
            "28/28 [==============================] - 0s 8ms/step - loss: 0.1251 - accuracy: 0.8624 - val_loss: 0.1272 - val_accuracy: 0.8608\n",
            "Epoch 152/700\n",
            "28/28 [==============================] - 0s 8ms/step - loss: 0.1222 - accuracy: 0.8627 - val_loss: 0.2009 - val_accuracy: 0.4891\n",
            "Epoch 153/700\n",
            "28/28 [==============================] - 0s 10ms/step - loss: 0.1220 - accuracy: 0.8646 - val_loss: 0.1890 - val_accuracy: 0.8435\n",
            "Epoch 154/700\n",
            "28/28 [==============================] - 0s 8ms/step - loss: 0.1222 - accuracy: 0.8645 - val_loss: 0.2385 - val_accuracy: 0.4891\n",
            "Epoch 155/700\n",
            "28/28 [==============================] - 0s 9ms/step - loss: 0.1220 - accuracy: 0.8645 - val_loss: 0.2089 - val_accuracy: 0.4891\n",
            "Epoch 156/700\n",
            "28/28 [==============================] - 0s 8ms/step - loss: 0.1222 - accuracy: 0.8627 - val_loss: 0.2034 - val_accuracy: 0.7229\n",
            "Epoch 157/700\n",
            "28/28 [==============================] - 0s 10ms/step - loss: 0.1249 - accuracy: 0.8632 - val_loss: 0.2730 - val_accuracy: 0.6247\n",
            "Epoch 158/700\n",
            "28/28 [==============================] - 0s 8ms/step - loss: 0.1239 - accuracy: 0.8627 - val_loss: 0.2579 - val_accuracy: 0.6708\n",
            "Epoch 159/700\n",
            "28/28 [==============================] - 0s 9ms/step - loss: 0.1223 - accuracy: 0.8672 - val_loss: 0.2628 - val_accuracy: 0.6523\n",
            "Epoch 160/700\n",
            "28/28 [==============================] - 0s 8ms/step - loss: 0.1226 - accuracy: 0.8651 - val_loss: 0.1612 - val_accuracy: 0.8418\n",
            "Epoch 161/700\n",
            "28/28 [==============================] - 0s 9ms/step - loss: 0.1233 - accuracy: 0.8638 - val_loss: 0.1960 - val_accuracy: 0.7369\n",
            "Epoch 162/700\n",
            "28/28 [==============================] - 0s 8ms/step - loss: 0.1222 - accuracy: 0.8657 - val_loss: 0.1639 - val_accuracy: 0.8245\n",
            "Epoch 163/700\n",
            "28/28 [==============================] - 0s 9ms/step - loss: 0.1265 - accuracy: 0.8641 - val_loss: 0.1460 - val_accuracy: 0.8278\n",
            "Epoch 164/700\n",
            "28/28 [==============================] - 0s 9ms/step - loss: 0.1257 - accuracy: 0.8606 - val_loss: 0.2877 - val_accuracy: 0.7165\n",
            "Epoch 165/700\n",
            "28/28 [==============================] - 0s 8ms/step - loss: 0.1294 - accuracy: 0.8551 - val_loss: 0.2618 - val_accuracy: 0.7294\n",
            "Epoch 166/700\n",
            "28/28 [==============================] - 0s 9ms/step - loss: 0.1256 - accuracy: 0.8603 - val_loss: 0.2209 - val_accuracy: 0.7698\n",
            "Epoch 167/700\n",
            "28/28 [==============================] - 0s 10ms/step - loss: 0.1256 - accuracy: 0.8630 - val_loss: 0.1995 - val_accuracy: 0.7927\n",
            "Epoch 168/700\n",
            "28/28 [==============================] - 0s 10ms/step - loss: 0.1266 - accuracy: 0.8621 - val_loss: 0.1795 - val_accuracy: 0.8206\n",
            "Epoch 169/700\n",
            "28/28 [==============================] - 0s 8ms/step - loss: 0.1288 - accuracy: 0.8590 - val_loss: 0.1582 - val_accuracy: 0.8276\n",
            "Epoch 170/700\n",
            "28/28 [==============================] - 0s 10ms/step - loss: 0.1268 - accuracy: 0.8618 - val_loss: 0.1673 - val_accuracy: 0.8315\n",
            "Epoch 171/700\n",
            "28/28 [==============================] - 0s 8ms/step - loss: 0.1265 - accuracy: 0.8623 - val_loss: 0.1806 - val_accuracy: 0.8312\n",
            "Epoch 172/700\n",
            "28/28 [==============================] - 0s 9ms/step - loss: 0.1264 - accuracy: 0.8616 - val_loss: 0.1880 - val_accuracy: 0.4891\n",
            "Epoch 173/700\n",
            "28/28 [==============================] - 0s 8ms/step - loss: 0.1232 - accuracy: 0.8628 - val_loss: 0.2428 - val_accuracy: 0.4891\n",
            "Epoch 174/700\n",
            "28/28 [==============================] - 0s 9ms/step - loss: 0.1283 - accuracy: 0.8590 - val_loss: 0.1267 - val_accuracy: 0.8622\n",
            "Epoch 175/700\n",
            "28/28 [==============================] - 0s 8ms/step - loss: 0.1263 - accuracy: 0.8604 - val_loss: 0.1411 - val_accuracy: 0.8432\n",
            "Epoch 176/700\n",
            "28/28 [==============================] - 0s 8ms/step - loss: 0.1267 - accuracy: 0.8640 - val_loss: 0.1375 - val_accuracy: 0.8524\n",
            "Epoch 177/700\n",
            "28/28 [==============================] - 0s 10ms/step - loss: 0.1267 - accuracy: 0.8600 - val_loss: 0.1357 - val_accuracy: 0.8510\n",
            "Epoch 178/700\n",
            "28/28 [==============================] - 0s 9ms/step - loss: 0.1247 - accuracy: 0.8615 - val_loss: 0.1544 - val_accuracy: 0.8502\n",
            "Epoch 179/700\n",
            "28/28 [==============================] - 0s 9ms/step - loss: 0.1241 - accuracy: 0.8641 - val_loss: 0.1436 - val_accuracy: 0.8334\n",
            "Epoch 180/700\n",
            "28/28 [==============================] - 0s 10ms/step - loss: 0.1239 - accuracy: 0.8624 - val_loss: 0.1421 - val_accuracy: 0.8384\n",
            "Epoch 181/700\n",
            "28/28 [==============================] - 0s 10ms/step - loss: 0.1233 - accuracy: 0.8639 - val_loss: 0.1730 - val_accuracy: 0.8530\n",
            "Epoch 182/700\n",
            "28/28 [==============================] - 0s 8ms/step - loss: 0.1249 - accuracy: 0.8618 - val_loss: 0.1449 - val_accuracy: 0.8304\n",
            "Epoch 183/700\n",
            "28/28 [==============================] - 0s 11ms/step - loss: 0.1217 - accuracy: 0.8664 - val_loss: 0.1559 - val_accuracy: 0.8214\n",
            "Epoch 184/700\n",
            "28/28 [==============================] - 0s 8ms/step - loss: 0.1288 - accuracy: 0.8589 - val_loss: 0.1571 - val_accuracy: 0.8220\n",
            "Epoch 185/700\n",
            "28/28 [==============================] - 0s 10ms/step - loss: 0.1314 - accuracy: 0.8603 - val_loss: 0.2037 - val_accuracy: 0.7927\n",
            "Epoch 186/700\n",
            "28/28 [==============================] - 0s 9ms/step - loss: 0.1294 - accuracy: 0.8617 - val_loss: 0.2344 - val_accuracy: 0.7556\n",
            "Epoch 187/700\n",
            "28/28 [==============================] - 0s 8ms/step - loss: 0.1248 - accuracy: 0.8661 - val_loss: 0.1831 - val_accuracy: 0.7595\n",
            "Epoch 188/700\n",
            "28/28 [==============================] - 0s 8ms/step - loss: 0.1229 - accuracy: 0.8663 - val_loss: 0.1909 - val_accuracy: 0.7374\n",
            "Epoch 189/700\n",
            "28/28 [==============================] - 0s 10ms/step - loss: 0.1239 - accuracy: 0.8641 - val_loss: 0.2144 - val_accuracy: 0.6833\n",
            "Epoch 190/700\n",
            "28/28 [==============================] - 0s 9ms/step - loss: 0.1248 - accuracy: 0.8657 - val_loss: 0.2081 - val_accuracy: 0.6959\n",
            "Epoch 191/700\n",
            "28/28 [==============================] - 0s 9ms/step - loss: 0.1250 - accuracy: 0.8621 - val_loss: 0.2841 - val_accuracy: 0.5455\n",
            "Epoch 192/700\n",
            "28/28 [==============================] - 0s 10ms/step - loss: 0.1248 - accuracy: 0.8626 - val_loss: 0.2624 - val_accuracy: 0.6055\n",
            "Epoch 193/700\n",
            "28/28 [==============================] - 0s 8ms/step - loss: 0.1236 - accuracy: 0.8644 - val_loss: 0.2084 - val_accuracy: 0.8002\n",
            "Epoch 194/700\n",
            "28/28 [==============================] - 0s 9ms/step - loss: 0.1254 - accuracy: 0.8587 - val_loss: 0.1939 - val_accuracy: 0.4891\n",
            "Epoch 195/700\n",
            "28/28 [==============================] - 0s 9ms/step - loss: 0.1254 - accuracy: 0.8659 - val_loss: 0.2268 - val_accuracy: 0.7316\n",
            "Epoch 196/700\n",
            "28/28 [==============================] - 0s 8ms/step - loss: 0.1242 - accuracy: 0.8641 - val_loss: 0.2047 - val_accuracy: 0.7229\n",
            "Epoch 197/700\n",
            "28/28 [==============================] - 0s 9ms/step - loss: 0.1242 - accuracy: 0.8628 - val_loss: 0.1948 - val_accuracy: 0.7612\n",
            "Epoch 198/700\n",
            "28/28 [==============================] - 0s 9ms/step - loss: 0.1222 - accuracy: 0.8653 - val_loss: 0.2191 - val_accuracy: 0.4891\n",
            "Epoch 199/700\n",
            "28/28 [==============================] - 0s 8ms/step - loss: 0.1240 - accuracy: 0.8634 - val_loss: 0.1570 - val_accuracy: 0.8301\n",
            "Epoch 200/700\n",
            "28/28 [==============================] - 0s 9ms/step - loss: 0.1223 - accuracy: 0.8676 - val_loss: 0.1569 - val_accuracy: 0.8119\n",
            "Epoch 201/700\n",
            "28/28 [==============================] - 0s 10ms/step - loss: 0.1217 - accuracy: 0.8667 - val_loss: 0.2094 - val_accuracy: 0.4891\n",
            "Epoch 202/700\n",
            "28/28 [==============================] - 0s 14ms/step - loss: 0.1232 - accuracy: 0.8642 - val_loss: 0.1991 - val_accuracy: 0.4891\n",
            "Epoch 203/700\n",
            "28/28 [==============================] - 0s 16ms/step - loss: 0.1221 - accuracy: 0.8647 - val_loss: 0.1675 - val_accuracy: 0.8616\n",
            "Epoch 204/700\n",
            "28/28 [==============================] - 1s 21ms/step - loss: 0.1226 - accuracy: 0.8650 - val_loss: 0.2023 - val_accuracy: 0.7508\n",
            "Epoch 205/700\n",
            "28/28 [==============================] - 1s 19ms/step - loss: 0.1253 - accuracy: 0.8651 - val_loss: 0.1425 - val_accuracy: 0.8312\n",
            "Epoch 206/700\n",
            "28/28 [==============================] - 0s 13ms/step - loss: 0.1247 - accuracy: 0.8644 - val_loss: 0.1674 - val_accuracy: 0.8203\n",
            "Epoch 207/700\n",
            "28/28 [==============================] - 0s 8ms/step - loss: 0.1231 - accuracy: 0.8654 - val_loss: 0.1576 - val_accuracy: 0.8323\n",
            "Epoch 208/700\n",
            "28/28 [==============================] - 0s 11ms/step - loss: 0.1221 - accuracy: 0.8664 - val_loss: 0.1338 - val_accuracy: 0.8616\n",
            "Epoch 209/700\n",
            "28/28 [==============================] - 0s 8ms/step - loss: 0.1234 - accuracy: 0.8639 - val_loss: 0.1608 - val_accuracy: 0.8538\n",
            "Epoch 210/700\n",
            "28/28 [==============================] - 0s 11ms/step - loss: 0.1215 - accuracy: 0.8671 - val_loss: 0.1732 - val_accuracy: 0.8239\n",
            "Epoch 211/700\n",
            "28/28 [==============================] - 0s 8ms/step - loss: 0.1225 - accuracy: 0.8659 - val_loss: 0.1327 - val_accuracy: 0.8597\n",
            "Epoch 212/700\n",
            "28/28 [==============================] - 0s 10ms/step - loss: 0.1238 - accuracy: 0.8642 - val_loss: 0.1478 - val_accuracy: 0.8376\n",
            "Epoch 213/700\n",
            "28/28 [==============================] - 0s 8ms/step - loss: 0.1238 - accuracy: 0.8647 - val_loss: 0.1643 - val_accuracy: 0.8044\n",
            "Epoch 214/700\n",
            "28/28 [==============================] - 0s 10ms/step - loss: 0.1268 - accuracy: 0.8630 - val_loss: 0.1615 - val_accuracy: 0.8270\n",
            "Epoch 215/700\n",
            "28/28 [==============================] - 0s 8ms/step - loss: 0.1273 - accuracy: 0.8622 - val_loss: 0.1574 - val_accuracy: 0.8047\n",
            "Epoch 216/700\n",
            "28/28 [==============================] - 0s 8ms/step - loss: 0.1288 - accuracy: 0.8656 - val_loss: 0.1511 - val_accuracy: 0.8518\n",
            "Epoch 217/700\n",
            "28/28 [==============================] - 0s 8ms/step - loss: 0.1284 - accuracy: 0.8624 - val_loss: 0.1410 - val_accuracy: 0.8429\n",
            "Epoch 218/700\n",
            "28/28 [==============================] - 0s 10ms/step - loss: 0.1256 - accuracy: 0.8642 - val_loss: 0.1461 - val_accuracy: 0.8404\n",
            "Epoch 219/700\n",
            "28/28 [==============================] - 0s 9ms/step - loss: 0.1238 - accuracy: 0.8632 - val_loss: 0.2067 - val_accuracy: 0.7944\n",
            "Epoch 220/700\n",
            "28/28 [==============================] - 0s 8ms/step - loss: 0.1220 - accuracy: 0.8635 - val_loss: 0.2087 - val_accuracy: 0.4891\n",
            "Epoch 221/700\n",
            "28/28 [==============================] - 0s 9ms/step - loss: 0.1212 - accuracy: 0.8658 - val_loss: 0.2372 - val_accuracy: 0.6420\n",
            "Epoch 222/700\n",
            "28/28 [==============================] - 0s 9ms/step - loss: 0.1254 - accuracy: 0.8644 - val_loss: 0.1712 - val_accuracy: 0.8245\n",
            "Epoch 223/700\n",
            "28/28 [==============================] - 0s 8ms/step - loss: 0.1282 - accuracy: 0.8622 - val_loss: 0.1485 - val_accuracy: 0.8557\n",
            "Epoch 224/700\n",
            "28/28 [==============================] - 0s 8ms/step - loss: 0.1252 - accuracy: 0.8652 - val_loss: 0.1462 - val_accuracy: 0.8396\n",
            "Epoch 225/700\n",
            "28/28 [==============================] - 0s 10ms/step - loss: 0.1244 - accuracy: 0.8642 - val_loss: 0.1752 - val_accuracy: 0.7821\n",
            "Epoch 226/700\n",
            "28/28 [==============================] - 0s 9ms/step - loss: 0.1238 - accuracy: 0.8642 - val_loss: 0.1996 - val_accuracy: 0.7009\n",
            "Epoch 227/700\n",
            "28/28 [==============================] - 0s 9ms/step - loss: 0.1209 - accuracy: 0.8651 - val_loss: 0.1674 - val_accuracy: 0.8521\n",
            "Epoch 228/700\n",
            "28/28 [==============================] - 0s 9ms/step - loss: 0.1219 - accuracy: 0.8630 - val_loss: 0.3584 - val_accuracy: 0.4902\n",
            "Epoch 229/700\n",
            "28/28 [==============================] - 0s 8ms/step - loss: 0.1250 - accuracy: 0.8621 - val_loss: 0.2442 - val_accuracy: 0.7503\n",
            "Epoch 230/700\n",
            "28/28 [==============================] - 0s 10ms/step - loss: 0.1252 - accuracy: 0.8626 - val_loss: 0.2405 - val_accuracy: 0.7684\n",
            "Epoch 231/700\n",
            "28/28 [==============================] - 0s 9ms/step - loss: 0.1244 - accuracy: 0.8626 - val_loss: 0.2162 - val_accuracy: 0.7921\n",
            "Epoch 232/700\n",
            "28/28 [==============================] - 0s 11ms/step - loss: 0.1207 - accuracy: 0.8665 - val_loss: 0.2629 - val_accuracy: 0.4891\n",
            "Epoch 233/700\n",
            "28/28 [==============================] - 0s 10ms/step - loss: 0.1273 - accuracy: 0.8611 - val_loss: 0.1395 - val_accuracy: 0.8532\n",
            "Epoch 234/700\n",
            "28/28 [==============================] - 0s 10ms/step - loss: 0.1256 - accuracy: 0.8618 - val_loss: 0.1816 - val_accuracy: 0.8251\n",
            "Epoch 235/700\n",
            "28/28 [==============================] - 0s 9ms/step - loss: 0.1245 - accuracy: 0.8624 - val_loss: 0.1330 - val_accuracy: 0.8491\n",
            "Epoch 236/700\n",
            "28/28 [==============================] - 0s 10ms/step - loss: 0.1289 - accuracy: 0.8554 - val_loss: 0.1502 - val_accuracy: 0.8228\n",
            "Epoch 237/700\n",
            "28/28 [==============================] - 0s 8ms/step - loss: 0.1240 - accuracy: 0.8638 - val_loss: 0.1736 - val_accuracy: 0.7712\n",
            "Epoch 238/700\n",
            "28/28 [==============================] - 0s 8ms/step - loss: 0.1270 - accuracy: 0.8585 - val_loss: 0.2537 - val_accuracy: 0.7051\n",
            "Epoch 239/700\n",
            "28/28 [==============================] - 0s 8ms/step - loss: 0.1263 - accuracy: 0.8620 - val_loss: 0.2341 - val_accuracy: 0.6364\n",
            "Epoch 240/700\n",
            "25/28 [=========================>....] - ETA: 0s - loss: 0.1184 - accuracy: 0.8655"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-83-e59972b4cd49>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmax_trials\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m overwrite=True)\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mtun1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxtrain\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mytrain\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m300\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m700\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras_tuner/engine/base_tuner.py\u001b[0m in \u001b[0;36msearch\u001b[0;34m(self, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_trial_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 183\u001b[0;31m             \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    184\u001b[0m             \u001b[0;31m# `results` is None indicates user updated oracle in `run_trial()`.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresults\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras_tuner/engine/tuner.py\u001b[0m in \u001b[0;36mrun_trial\u001b[0;34m(self, trial, *args, **kwargs)\u001b[0m\n\u001b[1;32m    293\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_checkpoint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0mcopied_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"callbacks\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m             \u001b[0mobj_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_build_and_fit_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcopied_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0mhistories\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras_tuner/engine/tuner.py\u001b[0m in \u001b[0;36m_build_and_fit_model\u001b[0;34m(self, trial, *args, **kwargs)\u001b[0m\n\u001b[1;32m    220\u001b[0m         \u001b[0mhp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhyperparameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_build\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 222\u001b[0;31m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhypermodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    223\u001b[0m         tuner_utils.validate_trial_results(\n\u001b[1;32m    224\u001b[0m             \u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moracle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobjective\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"HyperModel.fit()\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-82-88a13e541116>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, hp, model, x, y, *args, **kwargs)\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mhp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mhp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1454\u001b[0m               \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1455\u001b[0m               \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1456\u001b[0;31m               _use_cached_eval_dataset=True)\n\u001b[0m\u001b[1;32m   1457\u001b[0m           \u001b[0mval_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'val_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mval_logs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1458\u001b[0m           \u001b[0mepoch_logs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_test_counter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massign\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m       \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_test_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1750\u001b[0;31m       \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menumerate_epochs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Single epoch.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcatch_stop_iteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36menumerate_epochs\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1191\u001b[0m     \u001b[0;34m\"\"\"Yields `(epoch, tf.data.Iterator)`.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_truncate_execution_to_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1193\u001b[0;31m       \u001b[0mdata_iterator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1194\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initial_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1195\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_insufficient_data\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Set by `catch_stop_iteration`.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    492\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minside_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolocate_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variant_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 494\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0miterator_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOwnedIterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    495\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    496\u001b[0m       raise RuntimeError(\"`tf.data.Dataset` only supports Python-style \"\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, dataset, components, element_spec)\u001b[0m\n\u001b[1;32m    694\u001b[0m             \u001b[0;34m\"When `dataset` is provided, `element_spec` and `components` must \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    695\u001b[0m             \"not be specified.\")\n\u001b[0;32m--> 696\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    697\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    698\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_next_call_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m_create_iterator\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    719\u001b[0m               \u001b[0moutput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flat_output_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    720\u001b[0m               output_shapes=self._flat_output_shapes))\n\u001b[0;32m--> 721\u001b[0;31m       \u001b[0mgen_dataset_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds_variant\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterator_resource\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    722\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    723\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_dataset_ops.py\u001b[0m in \u001b[0;36mmake_iterator\u001b[0;34m(dataset, iterator, name)\u001b[0m\n\u001b[1;32m   3408\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3409\u001b[0m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[0;32m-> 3410\u001b[0;31m         _ctx, \"MakeIterator\", name, dataset, iterator)\n\u001b[0m\u001b[1;32m   3411\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3412\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "tun1=keras_tuner.RandomSearch(hypermodel=hypermodel3L(),\n",
        "objective=keras_tuner.Objective(\"loss\",\"min\"),\n",
        "max_trials=20,\n",
        "overwrite=True)\n",
        "tun1.search(xtrain,ytrain,batch_size=300, epochs=700, validation_data=(xval, yval))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6CRuapIW3wuP",
        "outputId": "7f29d2db-85ad-4fdf-bcb9-54a3e5fbc9ba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 80 Complete [00h 03m 51s]\n",
            "metric_b: 0.9273374676704407\n",
            "\n",
            "Best metric_b So Far: 0.9415813088417053\n",
            "Total elapsed time: 05h 42m 59s\n"
          ]
        }
      ],
      "source": [
        "tun1L=keras_tuner.BayesianOptimization(hypermodel=hypermodel3Ltwo(),\n",
        "objective=keras_tuner.Objective(\"metric_b\",\"max\"),\n",
        "max_trials=80,\n",
        "overwrite=True)\n",
        "# have to define abitrary xval and yval before\n",
        "xtrain,xval,ytrain,yval=train_test_split(training.drop('churn',axis=1).values,training.churn.values.reshape(-1,1),test_size=0.6)\n",
        "tun1L.search(xtrain,ytrain,30,130,xval,yval)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ps8MC4w1lLnP",
        "outputId": "de62d8fa-bfac-4a2c-e140-f1d5402dbdb0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "Training loss (for one batch) at step 0: 0.6926\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6930\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.10s\n",
            "\n",
            "Start of epoch 172\n",
            "Training loss (for one batch) at step 0: 0.6926\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6930\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 173\n",
            "Training loss (for one batch) at step 0: 0.6926\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6930\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.08s\n",
            "\n",
            "Start of epoch 174\n",
            "Training loss (for one batch) at step 0: 0.6926\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6930\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 175\n",
            "Training loss (for one batch) at step 0: 0.6926\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6930\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 176\n",
            "Training loss (for one batch) at step 0: 0.6926\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6930\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 177\n",
            "Training loss (for one batch) at step 0: 0.6926\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6930\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.12s\n",
            "\n",
            "Start of epoch 178\n",
            "Training loss (for one batch) at step 0: 0.6926\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6930\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 179\n",
            "Training loss (for one batch) at step 0: 0.6926\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6930\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.10s\n",
            "\n",
            "Start of epoch 180\n",
            "Training loss (for one batch) at step 0: 0.6926\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6930\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.12s\n",
            "\n",
            "Start of epoch 181\n",
            "Training loss (for one batch) at step 0: 0.6926\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6930\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 182\n",
            "Training loss (for one batch) at step 0: 0.6926\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6930\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 183\n",
            "Training loss (for one batch) at step 0: 0.6926\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6930\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 184\n",
            "Training loss (for one batch) at step 0: 0.6926\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6930\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 185\n",
            "Training loss (for one batch) at step 0: 0.6926\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6930\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.10s\n",
            "\n",
            "Start of epoch 186\n",
            "Training loss (for one batch) at step 0: 0.6926\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6930\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.07s\n",
            "\n",
            "Start of epoch 187\n",
            "Training loss (for one batch) at step 0: 0.6926\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6930\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.08s\n",
            "\n",
            "Start of epoch 188\n",
            "Training loss (for one batch) at step 0: 0.6926\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6930\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.10s\n",
            "\n",
            "Start of epoch 189\n",
            "Training loss (for one batch) at step 0: 0.6925\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6930\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.10s\n",
            "\n",
            "Start of epoch 190\n",
            "Training loss (for one batch) at step 0: 0.6925\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6929\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.10s\n",
            "\n",
            "Start of epoch 191\n",
            "Training loss (for one batch) at step 0: 0.6925\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6929\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.10s\n",
            "\n",
            "Start of epoch 192\n",
            "Training loss (for one batch) at step 0: 0.6925\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6929\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.10s\n",
            "\n",
            "Start of epoch 193\n",
            "Training loss (for one batch) at step 0: 0.6925\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6929\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.10s\n",
            "\n",
            "Start of epoch 194\n",
            "Training loss (for one batch) at step 0: 0.6925\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6929\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.10s\n",
            "\n",
            "Start of epoch 195\n",
            "Training loss (for one batch) at step 0: 0.6925\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6929\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 196\n",
            "Training loss (for one batch) at step 0: 0.6925\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6929\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.08s\n",
            "\n",
            "Start of epoch 197\n",
            "Training loss (for one batch) at step 0: 0.6925\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6929\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.10s\n",
            "\n",
            "Start of epoch 198\n",
            "Training loss (for one batch) at step 0: 0.6925\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6929\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.10s\n",
            "\n",
            "Start of epoch 199\n",
            "Training loss (for one batch) at step 0: 0.6925\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6929\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 200\n",
            "Training loss (for one batch) at step 0: 0.6925\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6929\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.08s\n",
            "\n",
            "Start of epoch 201\n",
            "Training loss (for one batch) at step 0: 0.6925\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6929\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.08s\n",
            "\n",
            "Start of epoch 202\n",
            "Training loss (for one batch) at step 0: 0.6925\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6929\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 203\n",
            "Training loss (for one batch) at step 0: 0.6925\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6929\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.08s\n",
            "\n",
            "Start of epoch 204\n",
            "Training loss (for one batch) at step 0: 0.6925\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6929\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 205\n",
            "Training loss (for one batch) at step 0: 0.6925\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6929\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.08s\n",
            "\n",
            "Start of epoch 206\n",
            "Training loss (for one batch) at step 0: 0.6925\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6929\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 207\n",
            "Training loss (for one batch) at step 0: 0.6925\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6929\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.10s\n",
            "\n",
            "Start of epoch 208\n",
            "Training loss (for one batch) at step 0: 0.6925\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6929\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.10s\n",
            "\n",
            "Start of epoch 209\n",
            "Training loss (for one batch) at step 0: 0.6925\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6929\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.10s\n",
            "\n",
            "Start of epoch 210\n",
            "Training loss (for one batch) at step 0: 0.6925\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6929\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 211\n",
            "Training loss (for one batch) at step 0: 0.6925\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6929\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 212\n",
            "Training loss (for one batch) at step 0: 0.6925\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6929\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.12s\n",
            "\n",
            "Start of epoch 213\n",
            "Training loss (for one batch) at step 0: 0.6925\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6929\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 214\n",
            "Training loss (for one batch) at step 0: 0.6925\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6929\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.09s\n",
            "\n",
            "Start of epoch 215\n",
            "Training loss (for one batch) at step 0: 0.6925\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6929\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.10s\n",
            "\n",
            "Start of epoch 216\n",
            "Training loss (for one batch) at step 0: 0.6925\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6929\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 217\n",
            "Training loss (for one batch) at step 0: 0.6925\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6929\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.10s\n",
            "\n",
            "Start of epoch 218\n",
            "Training loss (for one batch) at step 0: 0.6925\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6929\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 219\n",
            "Training loss (for one batch) at step 0: 0.6925\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6929\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.10s\n",
            "\n",
            "Start of epoch 220\n",
            "Training loss (for one batch) at step 0: 0.6925\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6929\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 221\n",
            "Training loss (for one batch) at step 0: 0.6925\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6929\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.10s\n",
            "\n",
            "Start of epoch 222\n",
            "Training loss (for one batch) at step 0: 0.6925\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6929\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.08s\n",
            "\n",
            "Start of epoch 223\n",
            "Training loss (for one batch) at step 0: 0.6925\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6929\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 224\n",
            "Training loss (for one batch) at step 0: 0.6925\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6929\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 225\n",
            "Training loss (for one batch) at step 0: 0.6925\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6929\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.10s\n",
            "\n",
            "Start of epoch 226\n",
            "Training loss (for one batch) at step 0: 0.6925\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6929\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.10s\n",
            "\n",
            "Start of epoch 227\n",
            "Training loss (for one batch) at step 0: 0.6925\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6929\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 228\n",
            "Training loss (for one batch) at step 0: 0.6925\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6929\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.10s\n",
            "\n",
            "Start of epoch 229\n",
            "Training loss (for one batch) at step 0: 0.6925\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6930\n",
            "Validation acc: 0.6932\n",
            "Time taken: 0.10s\n",
            "\n",
            "Start of epoch 230\n",
            "Training loss (for one batch) at step 0: 0.6929\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6935\n",
            "Validation acc: 0.6936\n",
            "Time taken: 0.08s\n",
            "\n",
            "Start of epoch 231\n",
            "Training loss (for one batch) at step 0: 0.6920\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6951\n",
            "Validation acc: 0.6951\n",
            "Time taken: 0.10s\n",
            "\n",
            "Start of epoch 232\n",
            "Training loss (for one batch) at step 0: 0.6914\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6943\n",
            "Validation acc: 0.6931\n",
            "Time taken: 0.10s\n",
            "\n",
            "Start of epoch 233\n",
            "Training loss (for one batch) at step 0: 0.6940\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6974\n",
            "Validation acc: 0.6941\n",
            "Time taken: 0.10s\n",
            "\n",
            "Start of epoch 234\n",
            "Training loss (for one batch) at step 0: 0.6976\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6964\n",
            "Validation acc: 0.6948\n",
            "Time taken: 0.08s\n",
            "\n",
            "Start of epoch 235\n",
            "Training loss (for one batch) at step 0: 0.6992\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6960\n",
            "Validation acc: 0.6931\n",
            "Time taken: 0.08s\n",
            "\n",
            "Start of epoch 236\n",
            "Training loss (for one batch) at step 0: 0.6934\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6933\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.07s\n",
            "\n",
            "Start of epoch 237\n",
            "Training loss (for one batch) at step 0: 0.6926\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6933\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.10s\n",
            "\n",
            "Start of epoch 238\n",
            "Training loss (for one batch) at step 0: 0.6923\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6929\n",
            "Validation acc: 0.6932\n",
            "Time taken: 0.07s\n",
            "\n",
            "Start of epoch 239\n",
            "Training loss (for one batch) at step 0: 0.6927\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6930\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.10s\n",
            "\n",
            "Start of epoch 240\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6930\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.10s\n",
            "\n",
            "Start of epoch 241\n",
            "Training loss (for one batch) at step 0: 0.6923\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6929\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.10s\n",
            "\n",
            "Start of epoch 242\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6929\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 243\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6929\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 244\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6929\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 245\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6929\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 246\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6929\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.10s\n",
            "\n",
            "Start of epoch 247\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6929\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.08s\n",
            "\n",
            "Start of epoch 248\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6929\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 249\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6929\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 250\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6929\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.10s\n",
            "\n",
            "Start of epoch 251\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6929\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 252\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6929\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.09s\n",
            "\n",
            "Start of epoch 253\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6929\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.10s\n",
            "\n",
            "Start of epoch 254\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6929\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.08s\n",
            "\n",
            "Start of epoch 255\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6929\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.08s\n",
            "\n",
            "Start of epoch 256\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6929\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 257\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6929\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 258\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6929\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.12s\n",
            "\n",
            "Start of epoch 259\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6929\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.10s\n",
            "\n",
            "Start of epoch 260\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6929\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 261\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6929\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 262\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6929\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 263\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6929\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.12s\n",
            "\n",
            "Start of epoch 264\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6929\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 265\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6929\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.10s\n",
            "\n",
            "Start of epoch 266\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6929\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 267\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6929\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.12s\n",
            "\n",
            "Start of epoch 268\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6929\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 269\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6929\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 270\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6929\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 271\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6929\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.08s\n",
            "\n",
            "Start of epoch 272\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6929\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 273\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6929\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 274\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6929\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.09s\n",
            "\n",
            "Start of epoch 275\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6929\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 276\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6929\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 277\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6929\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.10s\n",
            "\n",
            "Start of epoch 278\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6929\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 279\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6929\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.10s\n",
            "\n",
            "Start of epoch 280\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6929\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.10s\n",
            "\n",
            "Start of epoch 281\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6929\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.10s\n",
            "\n",
            "Start of epoch 282\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6929\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.10s\n",
            "\n",
            "Start of epoch 283\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6929\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 284\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6929\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 285\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6929\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.10s\n",
            "\n",
            "Start of epoch 286\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6929\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.10s\n",
            "\n",
            "Start of epoch 287\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6929\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.08s\n",
            "\n",
            "Start of epoch 288\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6929\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.08s\n",
            "\n",
            "Start of epoch 289\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6929\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.12s\n",
            "\n",
            "Start of epoch 290\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6928\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.08s\n",
            "\n",
            "Start of epoch 291\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6928\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 292\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6928\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.10s\n",
            "\n",
            "Start of epoch 293\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6928\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 294\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6928\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.14s\n",
            "\n",
            "Start of epoch 295\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6928\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 296\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6928\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 297\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6928\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 298\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6928\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 299\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6928\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 300\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6928\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.08s\n",
            "\n",
            "Start of epoch 301\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6928\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 302\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6928\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.09s\n",
            "\n",
            "Start of epoch 303\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6928\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 304\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6928\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.09s\n",
            "\n",
            "Start of epoch 305\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6928\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 306\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6928\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.14s\n",
            "\n",
            "Start of epoch 307\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6928\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 308\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6928\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 309\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6928\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 310\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6928\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 311\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6928\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.07s\n",
            "\n",
            "Start of epoch 312\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6928\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.08s\n",
            "\n",
            "Start of epoch 313\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6928\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.10s\n",
            "\n",
            "Start of epoch 314\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6928\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.07s\n",
            "\n",
            "Start of epoch 315\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6928\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.07s\n",
            "\n",
            "Start of epoch 316\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6928\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 317\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6928\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 318\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6928\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 319\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6928\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.08s\n",
            "\n",
            "Start of epoch 320\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6928\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 321\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6928\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 322\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6928\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 323\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6928\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.10s\n",
            "\n",
            "Start of epoch 324\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6928\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.09s\n",
            "\n",
            "Start of epoch 325\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6928\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 326\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6928\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 327\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6928\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 328\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6928\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 329\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6928\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 330\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6928\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 331\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6928\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 332\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6928\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.10s\n",
            "\n",
            "Start of epoch 333\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6928\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.10s\n",
            "\n",
            "Start of epoch 334\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6928\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.08s\n",
            "\n",
            "Start of epoch 335\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6928\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 336\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6928\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 337\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6928\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 338\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6928\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 339\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6928\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.08s\n",
            "\n",
            "Start of epoch 340\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6928\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 341\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6928\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 342\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6928\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 343\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6928\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.10s\n",
            "\n",
            "Start of epoch 344\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6928\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 345\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6928\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 346\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6928\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 347\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6928\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.09s\n",
            "\n",
            "Start of epoch 348\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6928\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 349\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6928\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 350\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6928\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 351\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6928\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.08s\n",
            "\n",
            "Start of epoch 352\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6928\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 353\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6928\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.08s\n",
            "\n",
            "Start of epoch 354\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6928\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.10s\n",
            "\n",
            "Start of epoch 355\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6928\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.10s\n",
            "\n",
            "Start of epoch 356\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6928\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.10s\n",
            "\n",
            "Start of epoch 357\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6928\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 358\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6928\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.10s\n",
            "\n",
            "Start of epoch 359\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6928\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 360\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6928\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 361\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6928\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 362\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6928\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.10s\n",
            "\n",
            "Start of epoch 363\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6928\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.09s\n",
            "\n",
            "Start of epoch 364\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6928\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 365\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6928\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 366\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6928\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.09s\n",
            "\n",
            "Start of epoch 367\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6928\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.10s\n",
            "\n",
            "Start of epoch 368\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6928\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 369\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6928\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.10s\n",
            "\n",
            "Start of epoch 370\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6928\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.12s\n",
            "\n",
            "Start of epoch 371\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6928\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 372\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6928\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.10s\n",
            "\n",
            "Start of epoch 373\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6928\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.10s\n",
            "\n",
            "Start of epoch 374\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6928\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.08s\n",
            "\n",
            "Start of epoch 375\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6928\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.10s\n",
            "\n",
            "Start of epoch 376\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6928\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 377\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6928\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 378\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6928\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 379\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6927\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.08s\n",
            "\n",
            "Start of epoch 380\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6927\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.10s\n",
            "\n",
            "Start of epoch 381\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6927\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.10s\n",
            "\n",
            "Start of epoch 382\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6927\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 383\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6927\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 384\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6928\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 385\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6928\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 386\n",
            "Training loss (for one batch) at step 0: 0.6925\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6928\n",
            "Validation acc: 0.6932\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 387\n",
            "Training loss (for one batch) at step 0: 0.6928\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6930\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 388\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6931\n",
            "Validation acc: 0.6932\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 389\n",
            "Training loss (for one batch) at step 0: 0.6927\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6930\n",
            "Validation acc: 0.6931\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 390\n",
            "Training loss (for one batch) at step 0: 0.6934\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6930\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.10s\n",
            "\n",
            "Start of epoch 391\n",
            "Training loss (for one batch) at step 0: 0.6925\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6933\n",
            "Validation acc: 0.6946\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 392\n",
            "Training loss (for one batch) at step 0: 0.6914\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6936\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 393\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6950\n",
            "Validation acc: 0.6994\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 394\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6933\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 395\n",
            "Training loss (for one batch) at step 0: 0.6925\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6952\n",
            "Validation acc: 0.6931\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 396\n",
            "Training loss (for one batch) at step 0: 0.6933\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6944\n",
            "Validation acc: 0.6953\n",
            "Time taken: 0.09s\n",
            "\n",
            "Start of epoch 397\n",
            "Training loss (for one batch) at step 0: 0.6913\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6971\n",
            "Validation acc: 0.6937\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 398\n",
            "Training loss (for one batch) at step 0: 0.6919\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6992\n",
            "Validation acc: 0.6932\n",
            "Time taken: 0.10s\n",
            "\n",
            "Start of epoch 399\n",
            "Training loss (for one batch) at step 0: 0.6945\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6991\n",
            "Validation acc: 0.6956\n",
            "Time taken: 0.08s\n",
            "\n",
            "Start of epoch 400\n",
            "Training loss (for one batch) at step 0: 0.7008\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6976\n",
            "Validation acc: 0.6932\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 401\n",
            "Training loss (for one batch) at step 0: 0.6948\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6939\n",
            "Validation acc: 0.6935\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 402\n",
            "Training loss (for one batch) at step 0: 0.6921\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6935\n",
            "Validation acc: 0.6931\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 403\n",
            "Training loss (for one batch) at step 0: 0.6938\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6934\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 404\n",
            "Training loss (for one batch) at step 0: 0.6925\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6932\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.12s\n",
            "\n",
            "Start of epoch 405\n",
            "Training loss (for one batch) at step 0: 0.6925\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6930\n",
            "Validation acc: 0.6932\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 406\n",
            "Training loss (for one batch) at step 0: 0.6927\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6931\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 407\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6930\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.09s\n",
            "\n",
            "Start of epoch 408\n",
            "Training loss (for one batch) at step 0: 0.6925\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6930\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 409\n",
            "Training loss (for one batch) at step 0: 0.6925\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6930\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.14s\n",
            "\n",
            "Start of epoch 410\n",
            "Training loss (for one batch) at step 0: 0.6925\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6930\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.10s\n",
            "\n",
            "Start of epoch 411\n",
            "Training loss (for one batch) at step 0: 0.6925\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6930\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 412\n",
            "Training loss (for one batch) at step 0: 0.6925\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6930\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.09s\n",
            "\n",
            "Start of epoch 413\n",
            "Training loss (for one batch) at step 0: 0.6925\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6930\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 414\n",
            "Training loss (for one batch) at step 0: 0.6925\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6930\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 415\n",
            "Training loss (for one batch) at step 0: 0.6925\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6929\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 416\n",
            "Training loss (for one batch) at step 0: 0.6925\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6929\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 417\n",
            "Training loss (for one batch) at step 0: 0.6925\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6929\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.09s\n",
            "\n",
            "Start of epoch 418\n",
            "Training loss (for one batch) at step 0: 0.6925\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6929\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 419\n",
            "Training loss (for one batch) at step 0: 0.6925\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6929\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 420\n",
            "Training loss (for one batch) at step 0: 0.6925\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6929\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.10s\n",
            "\n",
            "Start of epoch 421\n",
            "Training loss (for one batch) at step 0: 0.6925\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6929\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 422\n",
            "Training loss (for one batch) at step 0: 0.6925\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6929\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.10s\n",
            "\n",
            "Start of epoch 423\n",
            "Training loss (for one batch) at step 0: 0.6925\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6929\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 424\n",
            "Training loss (for one batch) at step 0: 0.6925\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6929\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.08s\n",
            "\n",
            "Start of epoch 425\n",
            "Training loss (for one batch) at step 0: 0.6925\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6929\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.09s\n",
            "\n",
            "Start of epoch 426\n",
            "Training loss (for one batch) at step 0: 0.6925\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6929\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 427\n",
            "Training loss (for one batch) at step 0: 0.6925\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6929\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 428\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6929\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 429\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6929\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 430\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6929\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.12s\n",
            "\n",
            "Start of epoch 431\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6929\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 432\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6929\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.12s\n",
            "\n",
            "Start of epoch 433\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6928\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 434\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6928\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.10s\n",
            "\n",
            "Start of epoch 435\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6928\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.10s\n",
            "\n",
            "Start of epoch 436\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6928\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.10s\n",
            "\n",
            "Start of epoch 437\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6928\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.10s\n",
            "\n",
            "Start of epoch 438\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6928\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.10s\n",
            "\n",
            "Start of epoch 439\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6928\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.10s\n",
            "\n",
            "Start of epoch 440\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6928\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 441\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6928\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 442\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6928\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.07s\n",
            "\n",
            "Start of epoch 443\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6928\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.08s\n",
            "\n",
            "Start of epoch 444\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6928\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.10s\n",
            "\n",
            "Start of epoch 445\n",
            "Training loss (for one batch) at step 0: 0.6923\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6928\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.08s\n",
            "\n",
            "Start of epoch 446\n",
            "Training loss (for one batch) at step 0: 0.6923\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6928\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.10s\n",
            "\n",
            "Start of epoch 447\n",
            "Training loss (for one batch) at step 0: 0.6923\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6928\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.10s\n",
            "\n",
            "Start of epoch 448\n",
            "Training loss (for one batch) at step 0: 0.6923\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6928\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 449\n",
            "Training loss (for one batch) at step 0: 0.6923\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6928\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.10s\n",
            "\n",
            "Start of epoch 450\n",
            "Training loss (for one batch) at step 0: 0.6923\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6928\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 451\n",
            "Training loss (for one batch) at step 0: 0.6923\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6928\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 452\n",
            "Training loss (for one batch) at step 0: 0.6923\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6928\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.10s\n",
            "\n",
            "Start of epoch 453\n",
            "Training loss (for one batch) at step 0: 0.6923\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6928\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.10s\n",
            "\n",
            "Start of epoch 454\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6928\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.10s\n",
            "\n",
            "Start of epoch 455\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6928\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 456\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6928\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 457\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6928\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 458\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6928\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 459\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6928\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 460\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6928\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.12s\n",
            "\n",
            "Start of epoch 461\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6928\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 462\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6928\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 463\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6928\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 464\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6928\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 465\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6928\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.08s\n",
            "\n",
            "Start of epoch 466\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6928\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.10s\n",
            "\n",
            "Start of epoch 467\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6928\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.08s\n",
            "\n",
            "Start of epoch 468\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6928\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 469\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6928\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.10s\n",
            "\n",
            "Start of epoch 470\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6928\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.09s\n",
            "\n",
            "Start of epoch 471\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6928\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 472\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6928\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 473\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6928\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.08s\n",
            "\n",
            "Start of epoch 474\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6928\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.10s\n",
            "\n",
            "Start of epoch 475\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6928\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.10s\n",
            "\n",
            "Start of epoch 476\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6928\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.08s\n",
            "\n",
            "Start of epoch 477\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6928\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.07s\n",
            "\n",
            "Start of epoch 478\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6928\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.10s\n",
            "\n",
            "Start of epoch 479\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6928\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.10s\n",
            "\n",
            "Start of epoch 480\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6928\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 481\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6928\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.10s\n",
            "\n",
            "Start of epoch 482\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6928\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.10s\n",
            "\n",
            "Start of epoch 483\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6928\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 484\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6927\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.10s\n",
            "\n",
            "Start of epoch 485\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6927\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.08s\n",
            "\n",
            "Start of epoch 486\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6927\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 487\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6927\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.10s\n",
            "\n",
            "Start of epoch 488\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6927\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.07s\n",
            "\n",
            "Start of epoch 489\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6927\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.10s\n",
            "\n",
            "Start of epoch 490\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6927\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 491\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6927\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.10s\n",
            "\n",
            "Start of epoch 492\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6927\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 493\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6927\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 494\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6927\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.08s\n",
            "\n",
            "Start of epoch 495\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6927\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.08s\n",
            "\n",
            "Start of epoch 496\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6927\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.07s\n",
            "\n",
            "Start of epoch 497\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6927\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.10s\n",
            "\n",
            "Start of epoch 498\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6927\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 499\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6927\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 500\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6927\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 501\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6927\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.10s\n",
            "\n",
            "Start of epoch 502\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6927\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 503\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6927\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.08s\n",
            "\n",
            "Start of epoch 504\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6927\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.10s\n",
            "\n",
            "Start of epoch 505\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6927\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 506\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6927\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 507\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6927\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 508\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6927\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 509\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6927\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.12s\n",
            "\n",
            "Start of epoch 510\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6927\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.10s\n",
            "\n",
            "Start of epoch 511\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6927\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 512\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6927\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 513\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6927\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.07s\n",
            "\n",
            "Start of epoch 514\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6927\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.07s\n",
            "\n",
            "Start of epoch 515\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6927\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 516\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6927\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 517\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6927\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 518\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6927\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 519\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6927\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.10s\n",
            "\n",
            "Start of epoch 520\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6927\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.10s\n",
            "\n",
            "Start of epoch 521\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6927\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 522\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6927\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 523\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6927\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 524\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6927\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.10s\n",
            "\n",
            "Start of epoch 525\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6927\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 526\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6927\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.10s\n",
            "\n",
            "Start of epoch 527\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6927\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 528\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6927\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.10s\n",
            "\n",
            "Start of epoch 529\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6927\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 530\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6927\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 531\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6927\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 532\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6927\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.10s\n",
            "\n",
            "Start of epoch 533\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6927\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 534\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6927\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.10s\n",
            "\n",
            "Start of epoch 535\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6927\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 536\n",
            "Training loss (for one batch) at step 0: 0.6925\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6928\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 537\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6927\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 538\n",
            "Training loss (for one batch) at step 0: 0.6926\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6928\n",
            "Validation acc: 0.6932\n",
            "Time taken: 0.10s\n",
            "\n",
            "Start of epoch 539\n",
            "Training loss (for one batch) at step 0: 0.6927\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6936\n",
            "Validation acc: 0.6931\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 540\n",
            "Training loss (for one batch) at step 0: 0.6940\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6953\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.08s\n",
            "\n",
            "Start of epoch 541\n",
            "Training loss (for one batch) at step 0: 0.6923\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6935\n",
            "Validation acc: 0.6979\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 542\n",
            "Training loss (for one batch) at step 0: 0.6918\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6955\n",
            "Validation acc: 0.6939\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 543\n",
            "Training loss (for one batch) at step 0: 0.6918\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6966\n",
            "Validation acc: 0.6955\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 544\n",
            "Training loss (for one batch) at step 0: 0.7006\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6968\n",
            "Validation acc: 0.6931\n",
            "Time taken: 0.08s\n",
            "\n",
            "Start of epoch 545\n",
            "Training loss (for one batch) at step 0: 0.6937\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6936\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 546\n",
            "Training loss (for one batch) at step 0: 0.6925\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6934\n",
            "Validation acc: 0.6932\n",
            "Time taken: 0.10s\n",
            "\n",
            "Start of epoch 547\n",
            "Training loss (for one batch) at step 0: 0.6931\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6933\n",
            "Validation acc: 0.6932\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 548\n",
            "Training loss (for one batch) at step 0: 0.6927\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6933\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 549\n",
            "Training loss (for one batch) at step 0: 0.6926\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6932\n",
            "Validation acc: 0.6932\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 550\n",
            "Training loss (for one batch) at step 0: 0.6927\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6932\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.08s\n",
            "\n",
            "Start of epoch 551\n",
            "Training loss (for one batch) at step 0: 0.6925\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6932\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.10s\n",
            "\n",
            "Start of epoch 552\n",
            "Training loss (for one batch) at step 0: 0.6926\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6931\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.10s\n",
            "\n",
            "Start of epoch 553\n",
            "Training loss (for one batch) at step 0: 0.6926\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6931\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.10s\n",
            "\n",
            "Start of epoch 554\n",
            "Training loss (for one batch) at step 0: 0.6925\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6931\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 555\n",
            "Training loss (for one batch) at step 0: 0.6925\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6931\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 556\n",
            "Training loss (for one batch) at step 0: 0.6925\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6931\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 557\n",
            "Training loss (for one batch) at step 0: 0.6925\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6931\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 558\n",
            "Training loss (for one batch) at step 0: 0.6925\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6931\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.08s\n",
            "\n",
            "Start of epoch 559\n",
            "Training loss (for one batch) at step 0: 0.6925\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6931\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 560\n",
            "Training loss (for one batch) at step 0: 0.6925\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6931\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.10s\n",
            "\n",
            "Start of epoch 561\n",
            "Training loss (for one batch) at step 0: 0.6925\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6931\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.08s\n",
            "\n",
            "Start of epoch 562\n",
            "Training loss (for one batch) at step 0: 0.6925\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6930\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.08s\n",
            "\n",
            "Start of epoch 563\n",
            "Training loss (for one batch) at step 0: 0.6925\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6930\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.10s\n",
            "\n",
            "Start of epoch 564\n",
            "Training loss (for one batch) at step 0: 0.6925\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6930\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.10s\n",
            "\n",
            "Start of epoch 565\n",
            "Training loss (for one batch) at step 0: 0.6925\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6930\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 566\n",
            "Training loss (for one batch) at step 0: 0.6925\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6930\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 567\n",
            "Training loss (for one batch) at step 0: 0.6925\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6930\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.10s\n",
            "\n",
            "Start of epoch 568\n",
            "Training loss (for one batch) at step 0: 0.6925\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6930\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 569\n",
            "Training loss (for one batch) at step 0: 0.6925\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6930\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.10s\n",
            "\n",
            "Start of epoch 570\n",
            "Training loss (for one batch) at step 0: 0.6925\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6930\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.10s\n",
            "\n",
            "Start of epoch 571\n",
            "Training loss (for one batch) at step 0: 0.6925\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6929\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 572\n",
            "Training loss (for one batch) at step 0: 0.6925\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6929\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.10s\n",
            "\n",
            "Start of epoch 573\n",
            "Training loss (for one batch) at step 0: 0.6925\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6929\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.08s\n",
            "\n",
            "Start of epoch 574\n",
            "Training loss (for one batch) at step 0: 0.6925\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6929\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 575\n",
            "Training loss (for one batch) at step 0: 0.6925\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6929\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.10s\n",
            "\n",
            "Start of epoch 576\n",
            "Training loss (for one batch) at step 0: 0.6925\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6929\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.10s\n",
            "\n",
            "Start of epoch 577\n",
            "Training loss (for one batch) at step 0: 0.6925\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6929\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 578\n",
            "Training loss (for one batch) at step 0: 0.6925\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6929\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 579\n",
            "Training loss (for one batch) at step 0: 0.6925\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6929\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 580\n",
            "Training loss (for one batch) at step 0: 0.6926\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6929\n",
            "Validation acc: 0.6931\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 581\n",
            "Training loss (for one batch) at step 0: 0.6932\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6933\n",
            "Validation acc: 0.6931\n",
            "Time taken: 0.12s\n",
            "\n",
            "Start of epoch 582\n",
            "Training loss (for one batch) at step 0: 0.6939\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6950\n",
            "Validation acc: 0.6936\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 583\n",
            "Training loss (for one batch) at step 0: 0.6963\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6982\n",
            "Validation acc: 0.6936\n",
            "Time taken: 0.10s\n",
            "\n",
            "Start of epoch 584\n",
            "Training loss (for one batch) at step 0: 0.6962\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6966\n",
            "Validation acc: 0.6932\n",
            "Time taken: 0.10s\n",
            "\n",
            "Start of epoch 585\n",
            "Training loss (for one batch) at step 0: 0.6945\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6955\n",
            "Validation acc: 0.6947\n",
            "Time taken: 0.10s\n",
            "\n",
            "Start of epoch 586\n",
            "Training loss (for one batch) at step 0: 0.6989\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6973\n",
            "Validation acc: 0.6948\n",
            "Time taken: 0.10s\n",
            "\n",
            "Start of epoch 587\n",
            "Training loss (for one batch) at step 0: 0.6992\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6957\n",
            "Validation acc: 0.6937\n",
            "Time taken: 0.09s\n",
            "\n",
            "Start of epoch 588\n",
            "Training loss (for one batch) at step 0: 0.6919\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6930\n",
            "Validation acc: 0.6931\n",
            "Time taken: 0.09s\n",
            "\n",
            "Start of epoch 589\n",
            "Training loss (for one batch) at step 0: 0.6937\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6936\n",
            "Validation acc: 0.6935\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 590\n",
            "Training loss (for one batch) at step 0: 0.6922\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6932\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 591\n",
            "Training loss (for one batch) at step 0: 0.6927\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6932\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 592\n",
            "Training loss (for one batch) at step 0: 0.6926\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6932\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 593\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6931\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 594\n",
            "Training loss (for one batch) at step 0: 0.6925\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6931\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 595\n",
            "Training loss (for one batch) at step 0: 0.6925\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6931\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 596\n",
            "Training loss (for one batch) at step 0: 0.6925\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6931\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 597\n",
            "Training loss (for one batch) at step 0: 0.6925\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6931\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.08s\n",
            "\n",
            "Start of epoch 598\n",
            "Training loss (for one batch) at step 0: 0.6925\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6931\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.10s\n",
            "\n",
            "Start of epoch 599\n",
            "Training loss (for one batch) at step 0: 0.6925\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6931\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.10s\n",
            "\n",
            "Start of epoch 600\n",
            "Training loss (for one batch) at step 0: 0.6925\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6931\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 601\n",
            "Training loss (for one batch) at step 0: 0.6925\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6931\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.08s\n",
            "\n",
            "Start of epoch 602\n",
            "Training loss (for one batch) at step 0: 0.6925\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6931\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.10s\n",
            "\n",
            "Start of epoch 603\n",
            "Training loss (for one batch) at step 0: 0.6925\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6931\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 604\n",
            "Training loss (for one batch) at step 0: 0.6925\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6931\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.10s\n",
            "\n",
            "Start of epoch 605\n",
            "Training loss (for one batch) at step 0: 0.6925\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6931\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 606\n",
            "Training loss (for one batch) at step 0: 0.6925\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6931\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.10s\n",
            "\n",
            "Start of epoch 607\n",
            "Training loss (for one batch) at step 0: 0.6925\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6931\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 608\n",
            "Training loss (for one batch) at step 0: 0.6925\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6931\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.10s\n",
            "\n",
            "Start of epoch 609\n",
            "Training loss (for one batch) at step 0: 0.6925\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6931\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 610\n",
            "Training loss (for one batch) at step 0: 0.6925\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6931\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.10s\n",
            "\n",
            "Start of epoch 611\n",
            "Training loss (for one batch) at step 0: 0.6925\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6931\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 612\n",
            "Training loss (for one batch) at step 0: 0.6925\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6931\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 613\n",
            "Training loss (for one batch) at step 0: 0.6925\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6931\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.10s\n",
            "\n",
            "Start of epoch 614\n",
            "Training loss (for one batch) at step 0: 0.6925\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6931\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 615\n",
            "Training loss (for one batch) at step 0: 0.6925\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6931\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.10s\n",
            "\n",
            "Start of epoch 616\n",
            "Training loss (for one batch) at step 0: 0.6925\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6931\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.08s\n",
            "\n",
            "Start of epoch 617\n",
            "Training loss (for one batch) at step 0: 0.6925\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6931\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 618\n",
            "Training loss (for one batch) at step 0: 0.6925\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6931\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.10s\n",
            "\n",
            "Start of epoch 619\n",
            "Training loss (for one batch) at step 0: 0.6925\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6931\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.10s\n",
            "\n",
            "Start of epoch 620\n",
            "Training loss (for one batch) at step 0: 0.6925\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6931\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.08s\n",
            "\n",
            "Start of epoch 621\n",
            "Training loss (for one batch) at step 0: 0.6925\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6931\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.12s\n",
            "\n",
            "Start of epoch 622\n",
            "Training loss (for one batch) at step 0: 0.6925\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6931\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 623\n",
            "Training loss (for one batch) at step 0: 0.6925\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6931\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 624\n",
            "Training loss (for one batch) at step 0: 0.6925\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6931\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 625\n",
            "Training loss (for one batch) at step 0: 0.6925\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6931\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 626\n",
            "Training loss (for one batch) at step 0: 0.6925\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6931\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 627\n",
            "Training loss (for one batch) at step 0: 0.6925\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6931\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 628\n",
            "Training loss (for one batch) at step 0: 0.6925\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6931\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.10s\n",
            "\n",
            "Start of epoch 629\n",
            "Training loss (for one batch) at step 0: 0.6925\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6931\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 630\n",
            "Training loss (for one batch) at step 0: 0.6925\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6931\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 631\n",
            "Training loss (for one batch) at step 0: 0.6925\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6931\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 632\n",
            "Training loss (for one batch) at step 0: 0.6925\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6931\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.10s\n",
            "\n",
            "Start of epoch 633\n",
            "Training loss (for one batch) at step 0: 0.6925\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6931\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 634\n",
            "Training loss (for one batch) at step 0: 0.6925\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6931\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.08s\n",
            "\n",
            "Start of epoch 635\n",
            "Training loss (for one batch) at step 0: 0.6925\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6931\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 636\n",
            "Training loss (for one batch) at step 0: 0.6925\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6931\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.08s\n",
            "\n",
            "Start of epoch 637\n",
            "Training loss (for one batch) at step 0: 0.6925\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6931\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 638\n",
            "Training loss (for one batch) at step 0: 0.6925\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6931\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 639\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6931\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.10s\n",
            "\n",
            "Start of epoch 640\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6931\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.10s\n",
            "\n",
            "Start of epoch 641\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6931\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 642\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6931\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 643\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6931\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.10s\n",
            "\n",
            "Start of epoch 644\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6931\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 645\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6931\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 646\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6931\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.10s\n",
            "\n",
            "Start of epoch 647\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6931\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.10s\n",
            "\n",
            "Start of epoch 648\n",
            "Training loss (for one batch) at step 0: 0.6925\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6930\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.10s\n",
            "\n",
            "Start of epoch 649\n",
            "Training loss (for one batch) at step 0: 0.6925\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6930\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.10s\n",
            "\n",
            "Start of epoch 650\n",
            "Training loss (for one batch) at step 0: 0.6925\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6930\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.10s\n",
            "\n",
            "Start of epoch 651\n",
            "Training loss (for one batch) at step 0: 0.6925\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6930\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.10s\n",
            "\n",
            "Start of epoch 652\n",
            "Training loss (for one batch) at step 0: 0.6925\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6930\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.10s\n",
            "\n",
            "Start of epoch 653\n",
            "Training loss (for one batch) at step 0: 0.6925\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6930\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.10s\n",
            "\n",
            "Start of epoch 654\n",
            "Training loss (for one batch) at step 0: 0.6925\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6930\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 655\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6930\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 656\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6930\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 657\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6930\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 658\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6930\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 659\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6930\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.10s\n",
            "\n",
            "Start of epoch 660\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6929\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.10s\n",
            "\n",
            "Start of epoch 661\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6929\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 662\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6929\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.10s\n",
            "\n",
            "Start of epoch 663\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6929\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.10s\n",
            "\n",
            "Start of epoch 664\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6929\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 665\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6929\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 666\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6929\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.12s\n",
            "\n",
            "Start of epoch 667\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6929\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.10s\n",
            "\n",
            "Start of epoch 668\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6929\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.08s\n",
            "\n",
            "Start of epoch 669\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6929\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 670\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6928\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 671\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6928\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.10s\n",
            "\n",
            "Start of epoch 672\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6928\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.07s\n",
            "\n",
            "Start of epoch 673\n",
            "Training loss (for one batch) at step 0: 0.6923\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6928\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.08s\n",
            "\n",
            "Start of epoch 674\n",
            "Training loss (for one batch) at step 0: 0.6923\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6928\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 675\n",
            "Training loss (for one batch) at step 0: 0.6923\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6928\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 676\n",
            "Training loss (for one batch) at step 0: 0.6923\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6928\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 677\n",
            "Training loss (for one batch) at step 0: 0.6923\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6928\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.10s\n",
            "\n",
            "Start of epoch 678\n",
            "Training loss (for one batch) at step 0: 0.6923\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6928\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.07s\n",
            "\n",
            "Start of epoch 679\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6928\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.10s\n",
            "\n",
            "Start of epoch 680\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6928\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.10s\n",
            "\n",
            "Start of epoch 681\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6928\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 682\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6928\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.10s\n",
            "\n",
            "Start of epoch 683\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6928\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.08s\n",
            "\n",
            "Start of epoch 684\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6928\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 685\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6928\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.08s\n",
            "\n",
            "Start of epoch 686\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6928\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 687\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6928\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.09s\n",
            "\n",
            "Start of epoch 688\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6928\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 689\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6928\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.10s\n",
            "\n",
            "Start of epoch 690\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6928\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.08s\n",
            "\n",
            "Start of epoch 691\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6928\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.14s\n",
            "\n",
            "Start of epoch 692\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6928\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.10s\n",
            "\n",
            "Start of epoch 693\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6928\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 694\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6928\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 695\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6928\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.09s\n",
            "\n",
            "Start of epoch 696\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6928\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.10s\n",
            "\n",
            "Start of epoch 697\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6928\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 698\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6928\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.09s\n",
            "\n",
            "Start of epoch 699\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6928\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.10s\n",
            "\n",
            "Start of epoch 700\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6928\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.10s\n",
            "\n",
            "Start of epoch 701\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6928\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.10s\n",
            "\n",
            "Start of epoch 702\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6928\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 703\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6928\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.10s\n",
            "\n",
            "Start of epoch 704\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6928\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.08s\n",
            "\n",
            "Start of epoch 705\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6928\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.07s\n",
            "\n",
            "Start of epoch 706\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6928\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 707\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6928\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.10s\n",
            "\n",
            "Start of epoch 708\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6928\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.10s\n",
            "\n",
            "Start of epoch 709\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6928\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.10s\n",
            "\n",
            "Start of epoch 710\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6928\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 711\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6928\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.08s\n",
            "\n",
            "Start of epoch 712\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6928\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.08s\n",
            "\n",
            "Start of epoch 713\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6928\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.10s\n",
            "\n",
            "Start of epoch 714\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6928\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.10s\n",
            "\n",
            "Start of epoch 715\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6928\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.08s\n",
            "\n",
            "Start of epoch 716\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6928\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.10s\n",
            "\n",
            "Start of epoch 717\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6928\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 718\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6928\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.10s\n",
            "\n",
            "Start of epoch 719\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6928\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 720\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6928\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.10s\n",
            "\n",
            "Start of epoch 721\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6928\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.10s\n",
            "\n",
            "Start of epoch 722\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6928\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.10s\n",
            "\n",
            "Start of epoch 723\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6928\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 724\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6928\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.10s\n",
            "\n",
            "Start of epoch 725\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6928\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.10s\n",
            "\n",
            "Start of epoch 726\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6928\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 727\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6928\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 728\n",
            "Training loss (for one batch) at step 0: 0.6925\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6928\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.10s\n",
            "\n",
            "Start of epoch 729\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6928\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 730\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6928\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.10s\n",
            "\n",
            "Start of epoch 731\n",
            "Training loss (for one batch) at step 0: 0.6925\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6928\n",
            "Validation acc: 0.6932\n",
            "Time taken: 0.07s\n",
            "\n",
            "Start of epoch 732\n",
            "Training loss (for one batch) at step 0: 0.6927\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6932\n",
            "Validation acc: 0.6932\n",
            "Time taken: 0.10s\n",
            "\n",
            "Start of epoch 733\n",
            "Training loss (for one batch) at step 0: 0.6928\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6936\n",
            "Validation acc: 0.6947\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 734\n",
            "Training loss (for one batch) at step 0: 0.6914\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6959\n",
            "Validation acc: 0.6931\n",
            "Time taken: 0.10s\n",
            "\n",
            "Start of epoch 735\n",
            "Training loss (for one batch) at step 0: 0.6939\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6987\n",
            "Validation acc: 0.6938\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 736\n",
            "Training loss (for one batch) at step 0: 0.6918\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6969\n",
            "Validation acc: 0.6931\n",
            "Time taken: 0.10s\n",
            "\n",
            "Start of epoch 737\n",
            "Training loss (for one batch) at step 0: 0.6938\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6976\n",
            "Validation acc: 0.6947\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 738\n",
            "Training loss (for one batch) at step 0: 0.6990\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6958\n",
            "Validation acc: 0.6949\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 739\n",
            "Training loss (for one batch) at step 0: 0.6993\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6977\n",
            "Validation acc: 0.6950\n",
            "Time taken: 0.10s\n",
            "\n",
            "Start of epoch 740\n",
            "Training loss (for one batch) at step 0: 0.6997\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6955\n",
            "Validation acc: 0.6935\n",
            "Time taken: 0.08s\n",
            "\n",
            "Start of epoch 741\n",
            "Training loss (for one batch) at step 0: 0.6921\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6930\n",
            "Validation acc: 0.6931\n",
            "Time taken: 0.10s\n",
            "\n",
            "Start of epoch 742\n",
            "Training loss (for one batch) at step 0: 0.6939\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6937\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.08s\n",
            "\n",
            "Start of epoch 743\n",
            "Training loss (for one batch) at step 0: 0.6923\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6930\n",
            "Validation acc: 0.6932\n",
            "Time taken: 0.07s\n",
            "\n",
            "Start of epoch 744\n",
            "Training loss (for one batch) at step 0: 0.6928\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6931\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.10s\n",
            "\n",
            "Start of epoch 745\n",
            "Training loss (for one batch) at step 0: 0.6925\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6931\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.10s\n",
            "\n",
            "Start of epoch 746\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6930\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.14s\n",
            "\n",
            "Start of epoch 747\n",
            "Training loss (for one batch) at step 0: 0.6925\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6930\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 748\n",
            "Training loss (for one batch) at step 0: 0.6925\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6930\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.10s\n",
            "\n",
            "Start of epoch 749\n",
            "Training loss (for one batch) at step 0: 0.6925\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6930\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 750\n",
            "Training loss (for one batch) at step 0: 0.6925\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6930\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.08s\n",
            "\n",
            "Start of epoch 751\n",
            "Training loss (for one batch) at step 0: 0.6925\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6930\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 752\n",
            "Training loss (for one batch) at step 0: 0.6925\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6930\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 753\n",
            "Training loss (for one batch) at step 0: 0.6925\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6930\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.08s\n",
            "\n",
            "Start of epoch 754\n",
            "Training loss (for one batch) at step 0: 0.6925\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6930\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.09s\n",
            "\n",
            "Start of epoch 755\n",
            "Training loss (for one batch) at step 0: 0.6925\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6930\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 756\n",
            "Training loss (for one batch) at step 0: 0.6925\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6930\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.10s\n",
            "\n",
            "Start of epoch 757\n",
            "Training loss (for one batch) at step 0: 0.6925\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6930\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.10s\n",
            "\n",
            "Start of epoch 758\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6930\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 759\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6929\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.10s\n",
            "\n",
            "Start of epoch 760\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6929\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 761\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6929\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.08s\n",
            "\n",
            "Start of epoch 762\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6929\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 763\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6929\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 764\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6929\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.12s\n",
            "\n",
            "Start of epoch 765\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6929\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 766\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6929\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 767\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6929\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.10s\n",
            "\n",
            "Start of epoch 768\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6929\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.08s\n",
            "\n",
            "Start of epoch 769\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6929\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.10s\n",
            "\n",
            "Start of epoch 770\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6929\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.10s\n",
            "\n",
            "Start of epoch 771\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6929\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.08s\n",
            "\n",
            "Start of epoch 772\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6929\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.08s\n",
            "\n",
            "Start of epoch 773\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6929\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.08s\n",
            "\n",
            "Start of epoch 774\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6929\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.08s\n",
            "\n",
            "Start of epoch 775\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6929\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.08s\n",
            "\n",
            "Start of epoch 776\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6929\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.08s\n",
            "\n",
            "Start of epoch 777\n",
            "Training loss (for one batch) at step 0: 0.6923\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6929\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.10s\n",
            "\n",
            "Start of epoch 778\n",
            "Training loss (for one batch) at step 0: 0.6923\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6929\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 779\n",
            "Training loss (for one batch) at step 0: 0.6923\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6929\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.09s\n",
            "\n",
            "Start of epoch 780\n",
            "Training loss (for one batch) at step 0: 0.6923\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6929\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.10s\n",
            "\n",
            "Start of epoch 781\n",
            "Training loss (for one batch) at step 0: 0.6923\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6929\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 782\n",
            "Training loss (for one batch) at step 0: 0.6923\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6928\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 783\n",
            "Training loss (for one batch) at step 0: 0.6923\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6928\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.12s\n",
            "\n",
            "Start of epoch 784\n",
            "Training loss (for one batch) at step 0: 0.6923\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6928\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 785\n",
            "Training loss (for one batch) at step 0: 0.6923\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6928\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.10s\n",
            "\n",
            "Start of epoch 786\n",
            "Training loss (for one batch) at step 0: 0.6923\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6928\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 787\n",
            "Training loss (for one batch) at step 0: 0.6923\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6928\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.09s\n",
            "\n",
            "Start of epoch 788\n",
            "Training loss (for one batch) at step 0: 0.6923\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6928\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 789\n",
            "Training loss (for one batch) at step 0: 0.6923\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6928\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 790\n",
            "Training loss (for one batch) at step 0: 0.6923\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6928\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 791\n",
            "Training loss (for one batch) at step 0: 0.6923\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6928\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 792\n",
            "Training loss (for one batch) at step 0: 0.6923\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6928\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 793\n",
            "Training loss (for one batch) at step 0: 0.6923\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6928\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 794\n",
            "Training loss (for one batch) at step 0: 0.6923\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6928\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.08s\n",
            "\n",
            "Start of epoch 795\n",
            "Training loss (for one batch) at step 0: 0.6923\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6928\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.10s\n",
            "\n",
            "Start of epoch 796\n",
            "Training loss (for one batch) at step 0: 0.6923\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6928\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 797\n",
            "Training loss (for one batch) at step 0: 0.6923\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6928\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 798\n",
            "Training loss (for one batch) at step 0: 0.6923\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6928\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 799\n",
            "Training loss (for one batch) at step 0: 0.6923\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6928\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.07s\n",
            "\n",
            "Start of epoch 800\n",
            "Training loss (for one batch) at step 0: 0.6923\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6928\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.10s\n",
            "\n",
            "Start of epoch 801\n",
            "Training loss (for one batch) at step 0: 0.6923\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6928\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 802\n",
            "Training loss (for one batch) at step 0: 0.6923\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6928\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.07s\n",
            "\n",
            "Start of epoch 803\n",
            "Training loss (for one batch) at step 0: 0.6923\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6928\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 804\n",
            "Training loss (for one batch) at step 0: 0.6923\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6928\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.07s\n",
            "\n",
            "Start of epoch 805\n",
            "Training loss (for one batch) at step 0: 0.6923\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6928\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 806\n",
            "Training loss (for one batch) at step 0: 0.6923\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6928\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.10s\n",
            "\n",
            "Start of epoch 807\n",
            "Training loss (for one batch) at step 0: 0.6923\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6928\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.10s\n",
            "\n",
            "Start of epoch 808\n",
            "Training loss (for one batch) at step 0: 0.6923\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6928\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 809\n",
            "Training loss (for one batch) at step 0: 0.6923\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6928\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.12s\n",
            "\n",
            "Start of epoch 810\n",
            "Training loss (for one batch) at step 0: 0.6923\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6928\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.08s\n",
            "\n",
            "Start of epoch 811\n",
            "Training loss (for one batch) at step 0: 0.6923\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6928\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 812\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6928\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.08s\n",
            "\n",
            "Start of epoch 813\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6928\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 814\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6928\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.08s\n",
            "\n",
            "Start of epoch 815\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6928\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 816\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6928\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 817\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6928\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 818\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6928\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.10s\n",
            "\n",
            "Start of epoch 819\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6928\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.10s\n",
            "\n",
            "Start of epoch 820\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6928\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 821\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6928\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 822\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6928\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 823\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6928\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 824\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6928\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 825\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6928\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.07s\n",
            "\n",
            "Start of epoch 826\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6928\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 827\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6928\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 828\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6928\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 829\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6928\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 830\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6928\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.09s\n",
            "\n",
            "Start of epoch 831\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6928\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.10s\n",
            "\n",
            "Start of epoch 832\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6928\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.09s\n",
            "\n",
            "Start of epoch 833\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6928\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 834\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6928\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 835\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6928\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.10s\n",
            "\n",
            "Start of epoch 836\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6928\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.08s\n",
            "\n",
            "Start of epoch 837\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6928\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.10s\n",
            "\n",
            "Start of epoch 838\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6928\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.10s\n",
            "\n",
            "Start of epoch 839\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6928\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.08s\n",
            "\n",
            "Start of epoch 840\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6928\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 841\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6928\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 842\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6928\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.08s\n",
            "\n",
            "Start of epoch 843\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6928\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 844\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6928\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 845\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6928\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 846\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6928\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.37s\n",
            "\n",
            "Start of epoch 847\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6928\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.14s\n",
            "\n",
            "Start of epoch 848\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6928\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.20s\n",
            "\n",
            "Start of epoch 849\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6928\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.12s\n",
            "\n",
            "Start of epoch 850\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6928\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.15s\n",
            "\n",
            "Start of epoch 851\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6928\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.15s\n",
            "\n",
            "Start of epoch 852\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6928\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 853\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6928\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 854\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6928\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.22s\n",
            "\n",
            "Start of epoch 855\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6928\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.14s\n",
            "\n",
            "Start of epoch 856\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6928\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.14s\n",
            "\n",
            "Start of epoch 857\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6928\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.21s\n",
            "\n",
            "Start of epoch 858\n",
            "Training loss (for one batch) at step 0: 0.6925\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6929\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 859\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6928\n",
            "Validation acc: 0.6932\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 860\n",
            "Training loss (for one batch) at step 0: 0.6929\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6926\n",
            "Validation acc: 0.6942\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 861\n",
            "Training loss (for one batch) at step 0: 0.6916\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6936\n",
            "Validation acc: 0.6986\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 862\n",
            "Training loss (for one batch) at step 0: 0.6920\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6946\n",
            "Validation acc: 0.6932\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 863\n",
            "Training loss (for one batch) at step 0: 0.6947\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6975\n",
            "Validation acc: 0.6936\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 864\n",
            "Training loss (for one batch) at step 0: 0.6920\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6937\n",
            "Validation acc: 0.6940\n",
            "Time taken: 0.10s\n",
            "\n",
            "Start of epoch 865\n",
            "Training loss (for one batch) at step 0: 0.6973\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6953\n",
            "Validation acc: 0.6944\n",
            "Time taken: 0.10s\n",
            "\n",
            "Start of epoch 866\n",
            "Training loss (for one batch) at step 0: 0.6982\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6954\n",
            "Validation acc: 0.6932\n",
            "Time taken: 0.10s\n",
            "\n",
            "Start of epoch 867\n",
            "Training loss (for one batch) at step 0: 0.6946\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6943\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.10s\n",
            "\n",
            "Start of epoch 868\n",
            "Training loss (for one batch) at step 0: 0.6925\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6933\n",
            "Validation acc: 0.6931\n",
            "Time taken: 0.10s\n",
            "\n",
            "Start of epoch 869\n",
            "Training loss (for one batch) at step 0: 0.6932\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6935\n",
            "Validation acc: 0.6934\n",
            "Time taken: 0.10s\n",
            "\n",
            "Start of epoch 870\n",
            "Training loss (for one batch) at step 0: 0.6923\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6932\n",
            "Validation acc: 0.6932\n",
            "Time taken: 0.10s\n",
            "\n",
            "Start of epoch 871\n",
            "Training loss (for one batch) at step 0: 0.6927\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6932\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 872\n",
            "Training loss (for one batch) at step 0: 0.6925\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6932\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.10s\n",
            "\n",
            "Start of epoch 873\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6931\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.07s\n",
            "\n",
            "Start of epoch 874\n",
            "Training loss (for one batch) at step 0: 0.6925\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6931\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 875\n",
            "Training loss (for one batch) at step 0: 0.6925\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6931\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 876\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6931\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 877\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6931\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.10s\n",
            "\n",
            "Start of epoch 878\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6931\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 879\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6931\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 880\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6931\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.10s\n",
            "\n",
            "Start of epoch 881\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6931\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.08s\n",
            "\n",
            "Start of epoch 882\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6931\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.08s\n",
            "\n",
            "Start of epoch 883\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6931\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.10s\n",
            "\n",
            "Start of epoch 884\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n",
            "Training acc over epoch: 0.6931\n",
            "Validation acc: 0.6933\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 885\n",
            "Training loss (for one batch) at step 0: 0.6924\n",
            "Seen so far: 500 samples\n"
          ]
        }
      ],
      "source": [
        "  tun1Le=keras_tuner.RandomSearch(hypermodel=hypermodel3Ltwo(),\n",
        "objective=keras_tuner.Objective(\"metric_b\",\"max\"),\n",
        "max_trials=20,\n",
        "overwrite=True)\n",
        "# have to define abitrary xval and yval before\n",
        "xtrain,xval,ytrain,yval=train_test_split(training.drop('churn',axis=1).values,training.churn.values.reshape(-1,1),test_size=0.6)\n",
        "tun1Le.search(xtrain,ytrain,30,130,xval,yval)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 798
        },
        "id": "Ju2E6BiI2z52",
        "outputId": "a4f1b902-a262-475e-b32d-11e1e1149870"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Search: Running Trial #1\n",
            "\n",
            "Value             |Best Value So Far |Hyperparameter\n",
            "26                |?                 |units_1\n",
            "relu              |?                 |activation_1\n",
            "0.004             |?                 |dropout1\n",
            "34                |?                 |units_2\n",
            "tanh              |?                 |activation_2\n",
            "0.006             |?                 |dropout2\n",
            "6                 |?                 |units_4\n",
            "tanh              |?                 |activation_4\n",
            "0.002             |?                 |dropout4\n",
            "30                |?                 |units_6\n",
            "tanh              |?                 |activation_6\n",
            "26                |?                 |units_7\n",
            "relu              |?                 |activation_7\n",
            "0.016             |?                 |dropout7\n",
            "\n",
            "\n",
            "Start of epoch 0\n",
            "Training loss (for one batch) at step 0: 0.7150\n",
            "Seen so far: 300 samples\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_code\u001b[0;34m(self, code_obj, result, async_)\u001b[0m\n\u001b[1;32m   3325\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3326\u001b[0;31m                     \u001b[0mexec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode_obj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_global_ns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_ns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3327\u001b[0m             \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-12-6e862673b11c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mxtrain\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mxval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mytrain\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0myval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'churn'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchurn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mtwotwo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxtrain\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mytrain\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m130\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mxval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0myval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras_tuner/engine/base_tuner.py\u001b[0m in \u001b[0;36msearch\u001b[0;34m(self, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[1;32m    182\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_trial_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 183\u001b[0;31m             \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    184\u001b[0m             \u001b[0;31m# `results` is None indicates user updated oracle in `run_trial()`.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras_tuner/engine/tuner.py\u001b[0m in \u001b[0;36mrun_trial\u001b[0;34m(self, trial, *args, **kwargs)\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0mcopied_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"callbacks\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m             \u001b[0mobj_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_build_and_fit_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcopied_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras_tuner/engine/tuner.py\u001b[0m in \u001b[0;36m_build_and_fit_model\u001b[0;34m(self, trial, *args, **kwargs)\u001b[0m\n\u001b[1;32m    221\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_build\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 222\u001b[0;31m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhypermodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    223\u001b[0m         tuner_utils.validate_trial_results(\n",
            "\u001b[0;32m<ipython-input-10-8c2a2d0981f9>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, hp, model, x, y, batch_size, epochs, xval, yval, **kwargs)\u001b[0m\n\u001b[1;32m     84\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx_batch_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_batch_train\u001b[0m \u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m                 \u001b[0mloss_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_batch_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    946\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 947\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    948\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2451\u001b[0m       (graph_function,\n\u001b[0;32m-> 2452\u001b[0;31m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0m\u001b[1;32m   2453\u001b[0m     return graph_function._call_flat(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   2710\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2711\u001b[0;31m           \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2712\u001b[0m           self._function_cache.add(cache_key, cache_key_deletion_observer,\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   2635\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2636\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   2637\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, acd_record_initial_resource_uses)\u001b[0m\n\u001b[1;32m   1140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1141\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    676\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompile_with_xla\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 677\u001b[0;31m           \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    678\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mautograph_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1122\u001b[0m                     \u001b[0moptional_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mautograph_options\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1123\u001b[0;31m                     \u001b[0muser_requested\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1124\u001b[0m                 ))\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    438\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 439\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconverted_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0meffective_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    440\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/__autograph_generated_file92bh3c52.py\u001b[0m in \u001b[0;36mtf__train_step\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m     14\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGradientTape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                     \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m                     \u001b[0mloss_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    330\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Allowlisted %s: from cache'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 331\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_call_unconverted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36m_call_unconverted\u001b[0;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[1;32m    457\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 458\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    459\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    489\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 490\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    491\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1013\u001b[0m             self._compute_dtype_object):\n\u001b[0;32m-> 1014\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1015\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     91\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/sequential.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    373\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init_graph_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 374\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSequential\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    375\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/functional.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    458\u001b[0m     return self._run_internal_graph(\n\u001b[0;32m--> 459\u001b[0;31m         inputs, training=training, mask=mask)\n\u001b[0m\u001b[1;32m    460\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/functional.py\u001b[0m in \u001b[0;36m_run_internal_graph\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    595\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_arguments\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 596\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    597\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1013\u001b[0m             self._compute_dtype_object):\n\u001b[0;32m-> 1014\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1015\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     91\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/layers/normalization/batch_normalization.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, training)\u001b[0m\n\u001b[1;32m    811\u001b[0m           \u001b[0mreduction_axes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 812\u001b[0;31m           keep_dims=keep_dims)\n\u001b[0m\u001b[1;32m    813\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/layers/normalization/batch_normalization.py\u001b[0m in \u001b[0;36m_moments\u001b[0;34m(self, inputs, reduction_axes, keep_dims)\u001b[0m\n\u001b[1;32m    704\u001b[0m     mean, variance = self._calculate_mean_and_var(inputs, reduction_axes,\n\u001b[0;32m--> 705\u001b[0;31m                                                   keep_dims)\n\u001b[0m\u001b[1;32m    706\u001b[0m     \u001b[0;31m# TODO(b/129279393): Support zero batch input in non DistributionStrategy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/layers/normalization/batch_normalization.py\u001b[0m in \u001b[0;36m_calculate_mean_and_var\u001b[0;34m(self, inputs, reduction_axes, keep_dims)\u001b[0m\n\u001b[1;32m    700\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_calculate_mean_and_var\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction_axes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeep_dims\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 701\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmoments\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction_axes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkeep_dims\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    702\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mop_dispatch_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1081\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1082\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mdispatch_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1083\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/nn_impl.py\u001b[0m in \u001b[0;36mmoments_v2\u001b[0;34m(x, axes, shift, keepdims, name)\u001b[0m\n\u001b[1;32m   1415\u001b[0m   \"\"\"\n\u001b[0;32m-> 1416\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mmoments\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshift\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshift\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeep_dims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkeepdims\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1417\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mop_dispatch_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1081\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1082\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mdispatch_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1083\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/nn_impl.py\u001b[0m in \u001b[0;36mmoments\u001b[0;34m(x, axes, shift, name, keep_dims, keepdims)\u001b[0m\n\u001b[1;32m   1367\u001b[0m     variance = math_ops.reduce_mean(\n\u001b[0;32m-> 1368\u001b[0;31m         \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msquared_difference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_gradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1369\u001b[0m         \u001b[0maxes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py\u001b[0m in \u001b[0;36msquared_difference\u001b[0;34m(x, y, name)\u001b[0m\n\u001b[1;32m  11035\u001b[0m     _, _, _op, _outputs = _op_def_library._apply_op_helper(\n\u001b[0;32m> 11036\u001b[0;31m         \"SquaredDifference\", x=x, y=y, name=name)\n\u001b[0m\u001b[1;32m  11037\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[0;34m(op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    798\u001b[0m                                  \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 799\u001b[0;31m                                  attrs=attr_protos, op_def=op_def)\n\u001b[0m\u001b[1;32m    800\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36m_create_op_internal\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[1;32m    695\u001b[0m         \u001b[0mop_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_def\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 696\u001b[0;31m         compute_device)\n\u001b[0m\u001b[1;32m    697\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_op_internal\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[1;32m   3761\u001b[0m           \u001b[0moriginal_op\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_default_original_op\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3762\u001b[0;31m           op_def=op_def)\n\u001b[0m\u001b[1;32m   3763\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_op_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompute_device\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompute_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, node_def, g, inputs, output_types, control_inputs, input_types, original_op, op_def)\u001b[0m\n\u001b[1;32m   2129\u001b[0m       self._c_op = _create_c_op(self._graph, node_def, inputs,\n\u001b[0;32m-> 2130\u001b[0;31m                                 control_input_ops, op_def)\n\u001b[0m\u001b[1;32m   2131\u001b[0m       \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[0;34m(graph, node_def, inputs, control_inputs, op_def)\u001b[0m\n\u001b[1;32m   1959\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1960\u001b[0;31m     \u001b[0mc_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpywrap_tf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_FinishOperation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop_desc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1961\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "twotwo=keras_tuner.RandomSearch(hypermodel=hypermodel3Ltwo(),\n",
        "objective=keras_tuner.Objective(\"metric_b\",\"max\"),\n",
        "max_trials=5,\n",
        "overwrite=True)\n",
        "# have to define abitrary xval and yval before\n",
        "xtrain,xval,ytrain,yval=train_test_split(training.drop('churn',axis=1).values,training.churn.values.reshape(-1,1),test_size=0.2)\n",
        "twotwo.search(xtrain,ytrain,30,130,xval,yval)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gvw5gZ-Kpbq7",
        "outputId": "d4f26d85-24d1-46e0-bdcb-b5cd543ab341"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "Validation acc: 0.9296\n",
            "Time taken: 0.12s\n",
            "\n",
            "Start of epoch 1486\n",
            "Training loss (for one batch) at step 0: 0.2893\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2867\n",
            "Validation acc: 0.9289\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 1487\n",
            "Training loss (for one batch) at step 0: 0.2881\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2797\n",
            "Validation acc: 0.9294\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 1488\n",
            "Training loss (for one batch) at step 0: 0.2909\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2857\n",
            "Validation acc: 0.9288\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 1489\n",
            "Training loss (for one batch) at step 0: 0.2860\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2798\n",
            "Validation acc: 0.9295\n",
            "Time taken: 0.12s\n",
            "\n",
            "Start of epoch 1490\n",
            "Training loss (for one batch) at step 0: 0.2910\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2852\n",
            "Validation acc: 0.9288\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 1491\n",
            "Training loss (for one batch) at step 0: 0.2866\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2807\n",
            "Validation acc: 0.9296\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 1492\n",
            "Training loss (for one batch) at step 0: 0.2893\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2833\n",
            "Validation acc: 0.9290\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 1493\n",
            "Training loss (for one batch) at step 0: 0.2865\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2806\n",
            "Validation acc: 0.9296\n",
            "Time taken: 0.08s\n",
            "\n",
            "Start of epoch 1494\n",
            "Training loss (for one batch) at step 0: 0.2896\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2835\n",
            "Validation acc: 0.9294\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 1495\n",
            "Training loss (for one batch) at step 0: 0.2870\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2820\n",
            "Validation acc: 0.9296\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 1496\n",
            "Training loss (for one batch) at step 0: 0.2895\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2830\n",
            "Validation acc: 0.9293\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 1497\n",
            "Training loss (for one batch) at step 0: 0.2872\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2836\n",
            "Validation acc: 0.9295\n",
            "Time taken: 0.12s\n",
            "\n",
            "Start of epoch 1498\n",
            "Training loss (for one batch) at step 0: 0.2894\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2821\n",
            "Validation acc: 0.9292\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 1499\n",
            "Training loss (for one batch) at step 0: 0.2865\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2839\n",
            "Validation acc: 0.9291\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 1500\n",
            "Training loss (for one batch) at step 0: 0.2928\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2847\n",
            "Validation acc: 0.9291\n",
            "Time taken: 0.10s\n",
            "\n",
            "Start of epoch 1501\n",
            "Training loss (for one batch) at step 0: 0.2855\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2849\n",
            "Validation acc: 0.9291\n",
            "Time taken: 0.08s\n",
            "\n",
            "Start of epoch 1502\n",
            "Training loss (for one batch) at step 0: 0.2913\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2829\n",
            "Validation acc: 0.9283\n",
            "Time taken: 0.12s\n",
            "\n",
            "Start of epoch 1503\n",
            "Training loss (for one batch) at step 0: 0.2851\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2886\n",
            "Validation acc: 0.9287\n",
            "Time taken: 0.12s\n",
            "\n",
            "Start of epoch 1504\n",
            "Training loss (for one batch) at step 0: 0.2884\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2795\n",
            "Validation acc: 0.9293\n",
            "Time taken: 0.12s\n",
            "\n",
            "Start of epoch 1505\n",
            "Training loss (for one batch) at step 0: 0.2882\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2913\n",
            "Validation acc: 0.9286\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 1506\n",
            "Training loss (for one batch) at step 0: 0.2891\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2806\n",
            "Validation acc: 0.9288\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 1507\n",
            "Training loss (for one batch) at step 0: 0.2932\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2878\n",
            "Validation acc: 0.9288\n",
            "Time taken: 0.10s\n",
            "\n",
            "Start of epoch 1508\n",
            "Training loss (for one batch) at step 0: 0.2871\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2787\n",
            "Validation acc: 0.9292\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 1509\n",
            "Training loss (for one batch) at step 0: 0.2884\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2842\n",
            "Validation acc: 0.9293\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 1510\n",
            "Training loss (for one batch) at step 0: 0.2885\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2802\n",
            "Validation acc: 0.9294\n",
            "Time taken: 0.09s\n",
            "\n",
            "Start of epoch 1511\n",
            "Training loss (for one batch) at step 0: 0.2875\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2864\n",
            "Validation acc: 0.9292\n",
            "Time taken: 0.10s\n",
            "\n",
            "Start of epoch 1512\n",
            "Training loss (for one batch) at step 0: 0.2894\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2803\n",
            "Validation acc: 0.9295\n",
            "Time taken: 0.14s\n",
            "\n",
            "Start of epoch 1513\n",
            "Training loss (for one batch) at step 0: 0.2879\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2885\n",
            "Validation acc: 0.9287\n",
            "Time taken: 0.21s\n",
            "\n",
            "Start of epoch 1514\n",
            "Training loss (for one batch) at step 0: 0.2891\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2801\n",
            "Validation acc: 0.9294\n",
            "Time taken: 0.30s\n",
            "\n",
            "Start of epoch 1515\n",
            "Training loss (for one batch) at step 0: 0.2894\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2901\n",
            "Validation acc: 0.9285\n",
            "Time taken: 0.30s\n",
            "\n",
            "Start of epoch 1516\n",
            "Training loss (for one batch) at step 0: 0.2900\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2800\n",
            "Validation acc: 0.9284\n",
            "Time taken: 0.23s\n",
            "\n",
            "Start of epoch 1517\n",
            "Training loss (for one batch) at step 0: 0.2965\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2889\n",
            "Validation acc: 0.9286\n",
            "Time taken: 0.23s\n",
            "\n",
            "Start of epoch 1518\n",
            "Training loss (for one batch) at step 0: 0.2874\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2787\n",
            "Validation acc: 0.9294\n",
            "Time taken: 0.15s\n",
            "\n",
            "Start of epoch 1519\n",
            "Training loss (for one batch) at step 0: 0.2873\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2844\n",
            "Validation acc: 0.9289\n",
            "Time taken: 0.15s\n",
            "\n",
            "Start of epoch 1520\n",
            "Training loss (for one batch) at step 0: 0.2877\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2790\n",
            "Validation acc: 0.9295\n",
            "Time taken: 0.23s\n",
            "\n",
            "Start of epoch 1521\n",
            "Training loss (for one batch) at step 0: 0.2887\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2856\n",
            "Validation acc: 0.9290\n",
            "Time taken: 0.30s\n",
            "\n",
            "Start of epoch 1522\n",
            "Training loss (for one batch) at step 0: 0.2889\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2794\n",
            "Validation acc: 0.9296\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 1523\n",
            "Training loss (for one batch) at step 0: 0.2890\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2865\n",
            "Validation acc: 0.9291\n",
            "Time taken: 0.12s\n",
            "\n",
            "Start of epoch 1524\n",
            "Training loss (for one batch) at step 0: 0.2889\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2794\n",
            "Validation acc: 0.9295\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 1525\n",
            "Training loss (for one batch) at step 0: 0.2905\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2873\n",
            "Validation acc: 0.9289\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 1526\n",
            "Training loss (for one batch) at step 0: 0.2901\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2794\n",
            "Validation acc: 0.9296\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 1527\n",
            "Training loss (for one batch) at step 0: 0.2897\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2913\n",
            "Validation acc: 0.9283\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 1528\n",
            "Training loss (for one batch) at step 0: 0.2891\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2789\n",
            "Validation acc: 0.9287\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 1529\n",
            "Training loss (for one batch) at step 0: 0.2970\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2849\n",
            "Validation acc: 0.9292\n",
            "Time taken: 0.09s\n",
            "\n",
            "Start of epoch 1530\n",
            "Training loss (for one batch) at step 0: 0.2873\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2798\n",
            "Validation acc: 0.9292\n",
            "Time taken: 0.09s\n",
            "\n",
            "Start of epoch 1531\n",
            "Training loss (for one batch) at step 0: 0.2854\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2785\n",
            "Validation acc: 0.9297\n",
            "Time taken: 0.08s\n",
            "\n",
            "Start of epoch 1532\n",
            "Training loss (for one batch) at step 0: 0.2877\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2817\n",
            "Validation acc: 0.9294\n",
            "Time taken: 0.12s\n",
            "\n",
            "Start of epoch 1533\n",
            "Training loss (for one batch) at step 0: 0.2855\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2798\n",
            "Validation acc: 0.9298\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 1534\n",
            "Training loss (for one batch) at step 0: 0.2869\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2834\n",
            "Validation acc: 0.9291\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 1535\n",
            "Training loss (for one batch) at step 0: 0.2859\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2795\n",
            "Validation acc: 0.9298\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 1536\n",
            "Training loss (for one batch) at step 0: 0.2877\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2838\n",
            "Validation acc: 0.9293\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 1537\n",
            "Training loss (for one batch) at step 0: 0.2865\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2798\n",
            "Validation acc: 0.9297\n",
            "Time taken: 0.08s\n",
            "\n",
            "Start of epoch 1538\n",
            "Training loss (for one batch) at step 0: 0.2861\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2808\n",
            "Validation acc: 0.9297\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 1539\n",
            "Training loss (for one batch) at step 0: 0.2876\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2813\n",
            "Validation acc: 0.9297\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 1540\n",
            "Training loss (for one batch) at step 0: 0.2854\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2800\n",
            "Validation acc: 0.9297\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 1541\n",
            "Training loss (for one batch) at step 0: 0.2864\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2825\n",
            "Validation acc: 0.9293\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 1542\n",
            "Training loss (for one batch) at step 0: 0.2859\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2798\n",
            "Validation acc: 0.9299\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 1543\n",
            "Training loss (for one batch) at step 0: 0.2889\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2853\n",
            "Validation acc: 0.9291\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 1544\n",
            "Training loss (for one batch) at step 0: 0.2882\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2789\n",
            "Validation acc: 0.9295\n",
            "Time taken: 0.10s\n",
            "\n",
            "Start of epoch 1545\n",
            "Training loss (for one batch) at step 0: 0.2930\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2881\n",
            "Validation acc: 0.9289\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 1546\n",
            "Training loss (for one batch) at step 0: 0.2886\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2797\n",
            "Validation acc: 0.9294\n",
            "Time taken: 0.08s\n",
            "\n",
            "Start of epoch 1547\n",
            "Training loss (for one batch) at step 0: 0.2933\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2859\n",
            "Validation acc: 0.9291\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 1548\n",
            "Training loss (for one batch) at step 0: 0.2870\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2797\n",
            "Validation acc: 0.9296\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 1549\n",
            "Training loss (for one batch) at step 0: 0.2933\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2848\n",
            "Validation acc: 0.9290\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 1550\n",
            "Training loss (for one batch) at step 0: 0.2872\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2801\n",
            "Validation acc: 0.9298\n",
            "Time taken: 0.12s\n",
            "\n",
            "Start of epoch 1551\n",
            "Training loss (for one batch) at step 0: 0.2906\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2820\n",
            "Validation acc: 0.9295\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 1552\n",
            "Training loss (for one batch) at step 0: 0.2869\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2803\n",
            "Validation acc: 0.9297\n",
            "Time taken: 0.10s\n",
            "\n",
            "Start of epoch 1553\n",
            "Training loss (for one batch) at step 0: 0.2908\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2830\n",
            "Validation acc: 0.9295\n",
            "Time taken: 0.08s\n",
            "\n",
            "Start of epoch 1554\n",
            "Training loss (for one batch) at step 0: 0.2869\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2802\n",
            "Validation acc: 0.9297\n",
            "Time taken: 0.10s\n",
            "\n",
            "Start of epoch 1555\n",
            "Training loss (for one batch) at step 0: 0.2902\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2844\n",
            "Validation acc: 0.9294\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 1556\n",
            "Training loss (for one batch) at step 0: 0.2875\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2794\n",
            "Validation acc: 0.9296\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 1557\n",
            "Training loss (for one batch) at step 0: 0.2926\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2847\n",
            "Validation acc: 0.9290\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 1558\n",
            "Training loss (for one batch) at step 0: 0.2864\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2812\n",
            "Validation acc: 0.9296\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 1559\n",
            "Training loss (for one batch) at step 0: 0.2903\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2825\n",
            "Validation acc: 0.9293\n",
            "Time taken: 0.10s\n",
            "\n",
            "Start of epoch 1560\n",
            "Training loss (for one batch) at step 0: 0.2865\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2818\n",
            "Validation acc: 0.9295\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 1561\n",
            "Training loss (for one batch) at step 0: 0.2914\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2820\n",
            "Validation acc: 0.9293\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 1562\n",
            "Training loss (for one batch) at step 0: 0.2867\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2848\n",
            "Validation acc: 0.9295\n",
            "Time taken: 0.10s\n",
            "\n",
            "Start of epoch 1563\n",
            "Training loss (for one batch) at step 0: 0.2907\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2808\n",
            "Validation acc: 0.9295\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 1564\n",
            "Training loss (for one batch) at step 0: 0.2863\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2859\n",
            "Validation acc: 0.9294\n",
            "Time taken: 0.12s\n",
            "\n",
            "Start of epoch 1565\n",
            "Training loss (for one batch) at step 0: 0.2892\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2807\n",
            "Validation acc: 0.9292\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 1566\n",
            "Training loss (for one batch) at step 0: 0.2865\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2878\n",
            "Validation acc: 0.9289\n",
            "Time taken: 0.12s\n",
            "\n",
            "Start of epoch 1567\n",
            "Training loss (for one batch) at step 0: 0.2881\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2787\n",
            "Validation acc: 0.9292\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 1568\n",
            "Training loss (for one batch) at step 0: 0.2921\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2924\n",
            "Validation acc: 0.9285\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 1569\n",
            "Training loss (for one batch) at step 0: 0.2912\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2805\n",
            "Validation acc: 0.9282\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 1570\n",
            "Training loss (for one batch) at step 0: 0.2987\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2866\n",
            "Validation acc: 0.9292\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 1571\n",
            "Training loss (for one batch) at step 0: 0.2869\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2784\n",
            "Validation acc: 0.9294\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 1572\n",
            "Training loss (for one batch) at step 0: 0.2861\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2786\n",
            "Validation acc: 0.9297\n",
            "Time taken: 0.12s\n",
            "\n",
            "Start of epoch 1573\n",
            "Training loss (for one batch) at step 0: 0.2886\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2814\n",
            "Validation acc: 0.9292\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 1574\n",
            "Training loss (for one batch) at step 0: 0.2857\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2783\n",
            "Validation acc: 0.9299\n",
            "Time taken: 0.09s\n",
            "\n",
            "Start of epoch 1575\n",
            "Training loss (for one batch) at step 0: 0.2887\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2836\n",
            "Validation acc: 0.9290\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 1576\n",
            "Training loss (for one batch) at step 0: 0.2860\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2783\n",
            "Validation acc: 0.9298\n",
            "Time taken: 0.14s\n",
            "\n",
            "Start of epoch 1577\n",
            "Training loss (for one batch) at step 0: 0.2893\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2844\n",
            "Validation acc: 0.9292\n",
            "Time taken: 0.08s\n",
            "\n",
            "Start of epoch 1578\n",
            "Training loss (for one batch) at step 0: 0.2860\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2788\n",
            "Validation acc: 0.9297\n",
            "Time taken: 0.08s\n",
            "\n",
            "Start of epoch 1579\n",
            "Training loss (for one batch) at step 0: 0.2898\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2837\n",
            "Validation acc: 0.9291\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 1580\n",
            "Training loss (for one batch) at step 0: 0.2860\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2791\n",
            "Validation acc: 0.9298\n",
            "Time taken: 0.09s\n",
            "\n",
            "Start of epoch 1581\n",
            "Training loss (for one batch) at step 0: 0.2890\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2820\n",
            "Validation acc: 0.9296\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 1582\n",
            "Training loss (for one batch) at step 0: 0.2869\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2797\n",
            "Validation acc: 0.9298\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 1583\n",
            "Training loss (for one batch) at step 0: 0.2890\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2823\n",
            "Validation acc: 0.9296\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 1584\n",
            "Training loss (for one batch) at step 0: 0.2866\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2793\n",
            "Validation acc: 0.9298\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 1585\n",
            "Training loss (for one batch) at step 0: 0.2901\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2826\n",
            "Validation acc: 0.9296\n",
            "Time taken: 0.10s\n",
            "\n",
            "Start of epoch 1586\n",
            "Training loss (for one batch) at step 0: 0.2873\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2819\n",
            "Validation acc: 0.9297\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 1587\n",
            "Training loss (for one batch) at step 0: 0.2886\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2812\n",
            "Validation acc: 0.9298\n",
            "Time taken: 0.12s\n",
            "\n",
            "Start of epoch 1588\n",
            "Training loss (for one batch) at step 0: 0.2878\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2841\n",
            "Validation acc: 0.9296\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 1589\n",
            "Training loss (for one batch) at step 0: 0.2876\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2802\n",
            "Validation acc: 0.9298\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 1590\n",
            "Training loss (for one batch) at step 0: 0.2864\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2845\n",
            "Validation acc: 0.9295\n",
            "Time taken: 0.08s\n",
            "\n",
            "Start of epoch 1591\n",
            "Training loss (for one batch) at step 0: 0.2879\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2801\n",
            "Validation acc: 0.9296\n",
            "Time taken: 0.12s\n",
            "\n",
            "Start of epoch 1592\n",
            "Training loss (for one batch) at step 0: 0.2869\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2821\n",
            "Validation acc: 0.9297\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 1593\n",
            "Training loss (for one batch) at step 0: 0.2890\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2813\n",
            "Validation acc: 0.9293\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 1594\n",
            "Training loss (for one batch) at step 0: 0.2852\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2819\n",
            "Validation acc: 0.9297\n",
            "Time taken: 0.12s\n",
            "\n",
            "Start of epoch 1595\n",
            "Training loss (for one batch) at step 0: 0.2887\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2803\n",
            "Validation acc: 0.9295\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 1596\n",
            "Training loss (for one batch) at step 0: 0.2863\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2832\n",
            "Validation acc: 0.9295\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 1597\n",
            "Training loss (for one batch) at step 0: 0.2897\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2809\n",
            "Validation acc: 0.9296\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 1598\n",
            "Training loss (for one batch) at step 0: 0.2860\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2860\n",
            "Validation acc: 0.9294\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 1599\n",
            "Training loss (for one batch) at step 0: 0.2881\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2789\n",
            "Validation acc: 0.9295\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 1600\n",
            "Training loss (for one batch) at step 0: 0.2858\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2868\n",
            "Validation acc: 0.9290\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 1601\n",
            "Training loss (for one batch) at step 0: 0.2880\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2779\n",
            "Validation acc: 0.9295\n",
            "Time taken: 0.09s\n",
            "\n",
            "Start of epoch 1602\n",
            "Training loss (for one batch) at step 0: 0.2901\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2860\n",
            "Validation acc: 0.9291\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 1603\n",
            "Training loss (for one batch) at step 0: 0.2865\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2775\n",
            "Validation acc: 0.9297\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 1604\n",
            "Training loss (for one batch) at step 0: 0.2870\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2836\n",
            "Validation acc: 0.9293\n",
            "Time taken: 0.14s\n",
            "\n",
            "Start of epoch 1605\n",
            "Training loss (for one batch) at step 0: 0.2863\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2781\n",
            "Validation acc: 0.9298\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 1606\n",
            "Training loss (for one batch) at step 0: 0.2869\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2845\n",
            "Validation acc: 0.9295\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 1607\n",
            "Training loss (for one batch) at step 0: 0.2879\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2777\n",
            "Validation acc: 0.9299\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 1608\n",
            "Training loss (for one batch) at step 0: 0.2885\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2856\n",
            "Validation acc: 0.9292\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 1609\n",
            "Training loss (for one batch) at step 0: 0.2872\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2783\n",
            "Validation acc: 0.9298\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 1610\n",
            "Training loss (for one batch) at step 0: 0.2869\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2842\n",
            "Validation acc: 0.9293\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 1611\n",
            "Training loss (for one batch) at step 0: 0.2892\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2780\n",
            "Validation acc: 0.9299\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 1612\n",
            "Training loss (for one batch) at step 0: 0.2879\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2876\n",
            "Validation acc: 0.9288\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 1613\n",
            "Training loss (for one batch) at step 0: 0.2891\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2770\n",
            "Validation acc: 0.9297\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 1614\n",
            "Training loss (for one batch) at step 0: 0.2887\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2859\n",
            "Validation acc: 0.9289\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 1615\n",
            "Training loss (for one batch) at step 0: 0.2878\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2772\n",
            "Validation acc: 0.9298\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 1616\n",
            "Training loss (for one batch) at step 0: 0.2894\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2854\n",
            "Validation acc: 0.9289\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 1617\n",
            "Training loss (for one batch) at step 0: 0.2874\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2774\n",
            "Validation acc: 0.9297\n",
            "Time taken: 0.12s\n",
            "\n",
            "Start of epoch 1618\n",
            "Training loss (for one batch) at step 0: 0.2906\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2849\n",
            "Validation acc: 0.9289\n",
            "Time taken: 0.08s\n",
            "\n",
            "Start of epoch 1619\n",
            "Training loss (for one batch) at step 0: 0.2863\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2775\n",
            "Validation acc: 0.9299\n",
            "Time taken: 0.09s\n",
            "\n",
            "Start of epoch 1620\n",
            "Training loss (for one batch) at step 0: 0.2888\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2822\n",
            "Validation acc: 0.9290\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 1621\n",
            "Training loss (for one batch) at step 0: 0.2853\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2770\n",
            "Validation acc: 0.9299\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 1622\n",
            "Training loss (for one batch) at step 0: 0.2889\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2819\n",
            "Validation acc: 0.9289\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 1623\n",
            "Training loss (for one batch) at step 0: 0.2851\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2771\n",
            "Validation acc: 0.9295\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 1624\n",
            "Training loss (for one batch) at step 0: 0.2926\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2841\n",
            "Validation acc: 0.9282\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 1625\n",
            "Training loss (for one batch) at step 0: 0.2859\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2834\n",
            "Validation acc: 0.9296\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 1626\n",
            "Training loss (for one batch) at step 0: 0.2864\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2782\n",
            "Validation acc: 0.9298\n",
            "Time taken: 0.08s\n",
            "\n",
            "Start of epoch 1627\n",
            "Training loss (for one batch) at step 0: 0.2860\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2895\n",
            "Validation acc: 0.9289\n",
            "Time taken: 0.10s\n",
            "\n",
            "Start of epoch 1628\n",
            "Training loss (for one batch) at step 0: 0.2874\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2790\n",
            "Validation acc: 0.9290\n",
            "Time taken: 0.14s\n",
            "\n",
            "Start of epoch 1629\n",
            "Training loss (for one batch) at step 0: 0.2957\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2854\n",
            "Validation acc: 0.9289\n",
            "Time taken: 0.08s\n",
            "\n",
            "Start of epoch 1630\n",
            "Training loss (for one batch) at step 0: 0.2863\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2762\n",
            "Validation acc: 0.9297\n",
            "Time taken: 0.12s\n",
            "\n",
            "Start of epoch 1631\n",
            "Training loss (for one batch) at step 0: 0.2863\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2812\n",
            "Validation acc: 0.9291\n",
            "Time taken: 0.14s\n",
            "\n",
            "Start of epoch 1632\n",
            "Training loss (for one batch) at step 0: 0.2855\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2767\n",
            "Validation acc: 0.9299\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 1633\n",
            "Training loss (for one batch) at step 0: 0.2857\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2812\n",
            "Validation acc: 0.9292\n",
            "Time taken: 0.09s\n",
            "\n",
            "Start of epoch 1634\n",
            "Training loss (for one batch) at step 0: 0.2855\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2764\n",
            "Validation acc: 0.9301\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 1635\n",
            "Training loss (for one batch) at step 0: 0.2872\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2838\n",
            "Validation acc: 0.9290\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 1636\n",
            "Training loss (for one batch) at step 0: 0.2859\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2767\n",
            "Validation acc: 0.9299\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 1637\n",
            "Training loss (for one batch) at step 0: 0.2860\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2839\n",
            "Validation acc: 0.9288\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 1638\n",
            "Training loss (for one batch) at step 0: 0.2865\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2767\n",
            "Validation acc: 0.9299\n",
            "Time taken: 0.09s\n",
            "\n",
            "Start of epoch 1639\n",
            "Training loss (for one batch) at step 0: 0.2892\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2849\n",
            "Validation acc: 0.9285\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 1640\n",
            "Training loss (for one batch) at step 0: 0.2868\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2772\n",
            "Validation acc: 0.9297\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 1641\n",
            "Training loss (for one batch) at step 0: 0.2921\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2839\n",
            "Validation acc: 0.9286\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 1642\n",
            "Training loss (for one batch) at step 0: 0.2859\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2795\n",
            "Validation acc: 0.9301\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 1643\n",
            "Training loss (for one batch) at step 0: 0.2897\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2809\n",
            "Validation acc: 0.9296\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 1644\n",
            "Training loss (for one batch) at step 0: 0.2844\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2817\n",
            "Validation acc: 0.9299\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 1645\n",
            "Training loss (for one batch) at step 0: 0.2890\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2798\n",
            "Validation acc: 0.9296\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 1646\n",
            "Training loss (for one batch) at step 0: 0.2848\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2848\n",
            "Validation acc: 0.9292\n",
            "Time taken: 0.08s\n",
            "\n",
            "Start of epoch 1647\n",
            "Training loss (for one batch) at step 0: 0.2857\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2778\n",
            "Validation acc: 0.9300\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 1648\n",
            "Training loss (for one batch) at step 0: 0.2866\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2874\n",
            "Validation acc: 0.9289\n",
            "Time taken: 0.10s\n",
            "\n",
            "Start of epoch 1649\n",
            "Training loss (for one batch) at step 0: 0.2867\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2767\n",
            "Validation acc: 0.9296\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 1650\n",
            "Training loss (for one batch) at step 0: 0.2927\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2840\n",
            "Validation acc: 0.9287\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 1651\n",
            "Training loss (for one batch) at step 0: 0.2861\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2754\n",
            "Validation acc: 0.9301\n",
            "Time taken: 0.09s\n",
            "\n",
            "Start of epoch 1652\n",
            "Training loss (for one batch) at step 0: 0.2871\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2807\n",
            "Validation acc: 0.9293\n",
            "Time taken: 0.09s\n",
            "\n",
            "Start of epoch 1653\n",
            "Training loss (for one batch) at step 0: 0.2854\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2766\n",
            "Validation acc: 0.9301\n",
            "Time taken: 0.10s\n",
            "\n",
            "Start of epoch 1654\n",
            "Training loss (for one batch) at step 0: 0.2874\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2817\n",
            "Validation acc: 0.9290\n",
            "Time taken: 0.08s\n",
            "\n",
            "Start of epoch 1655\n",
            "Training loss (for one batch) at step 0: 0.2851\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2759\n",
            "Validation acc: 0.9301\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 1656\n",
            "Training loss (for one batch) at step 0: 0.2909\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2820\n",
            "Validation acc: 0.9293\n",
            "Time taken: 0.09s\n",
            "\n",
            "Start of epoch 1657\n",
            "Training loss (for one batch) at step 0: 0.2846\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2784\n",
            "Validation acc: 0.9301\n",
            "Time taken: 0.10s\n",
            "\n",
            "Start of epoch 1658\n",
            "Training loss (for one batch) at step 0: 0.2910\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2831\n",
            "Validation acc: 0.9290\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 1659\n",
            "Training loss (for one batch) at step 0: 0.2845\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2838\n",
            "Validation acc: 0.9295\n",
            "Time taken: 0.09s\n",
            "\n",
            "Start of epoch 1660\n",
            "Training loss (for one batch) at step 0: 0.2847\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2773\n",
            "Validation acc: 0.9302\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 1661\n",
            "Training loss (for one batch) at step 0: 0.2866\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2861\n",
            "Validation acc: 0.9290\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 1662\n",
            "Training loss (for one batch) at step 0: 0.2862\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2758\n",
            "Validation acc: 0.9301\n",
            "Time taken: 0.10s\n",
            "\n",
            "Start of epoch 1663\n",
            "Training loss (for one batch) at step 0: 0.2877\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2837\n",
            "Validation acc: 0.9297\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 1664\n",
            "Training loss (for one batch) at step 0: 0.2868\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2769\n",
            "Validation acc: 0.9301\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 1665\n",
            "Training loss (for one batch) at step 0: 0.2868\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2854\n",
            "Validation acc: 0.9291\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 1666\n",
            "Training loss (for one batch) at step 0: 0.2861\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2757\n",
            "Validation acc: 0.9301\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 1667\n",
            "Training loss (for one batch) at step 0: 0.2888\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2836\n",
            "Validation acc: 0.9294\n",
            "Time taken: 0.14s\n",
            "\n",
            "Start of epoch 1668\n",
            "Training loss (for one batch) at step 0: 0.2861\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2760\n",
            "Validation acc: 0.9302\n",
            "Time taken: 0.10s\n",
            "\n",
            "Start of epoch 1669\n",
            "Training loss (for one batch) at step 0: 0.2872\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2813\n",
            "Validation acc: 0.9294\n",
            "Time taken: 0.09s\n",
            "\n",
            "Start of epoch 1670\n",
            "Training loss (for one batch) at step 0: 0.2856\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2761\n",
            "Validation acc: 0.9302\n",
            "Time taken: 0.12s\n",
            "\n",
            "Start of epoch 1671\n",
            "Training loss (for one batch) at step 0: 0.2864\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2802\n",
            "Validation acc: 0.9294\n",
            "Time taken: 0.09s\n",
            "\n",
            "Start of epoch 1672\n",
            "Training loss (for one batch) at step 0: 0.2848\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2769\n",
            "Validation acc: 0.9302\n",
            "Time taken: 0.10s\n",
            "\n",
            "Start of epoch 1673\n",
            "Training loss (for one batch) at step 0: 0.2896\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2803\n",
            "Validation acc: 0.9298\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 1674\n",
            "Training loss (for one batch) at step 0: 0.2846\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2795\n",
            "Validation acc: 0.9301\n",
            "Time taken: 0.10s\n",
            "\n",
            "Start of epoch 1675\n",
            "Training loss (for one batch) at step 0: 0.2881\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2785\n",
            "Validation acc: 0.9297\n",
            "Time taken: 0.12s\n",
            "\n",
            "Start of epoch 1676\n",
            "Training loss (for one batch) at step 0: 0.2845\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2816\n",
            "Validation acc: 0.9300\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 1677\n",
            "Training loss (for one batch) at step 0: 0.2873\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2785\n",
            "Validation acc: 0.9300\n",
            "Time taken: 0.14s\n",
            "\n",
            "Start of epoch 1678\n",
            "Training loss (for one batch) at step 0: 0.2848\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2844\n",
            "Validation acc: 0.9296\n",
            "Time taken: 0.09s\n",
            "\n",
            "Start of epoch 1679\n",
            "Training loss (for one batch) at step 0: 0.2858\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2766\n",
            "Validation acc: 0.9301\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 1680\n",
            "Training loss (for one batch) at step 0: 0.2901\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2844\n",
            "Validation acc: 0.9292\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 1681\n",
            "Training loss (for one batch) at step 0: 0.2858\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2755\n",
            "Validation acc: 0.9302\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 1682\n",
            "Training loss (for one batch) at step 0: 0.2879\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2806\n",
            "Validation acc: 0.9296\n",
            "Time taken: 0.12s\n",
            "\n",
            "Start of epoch 1683\n",
            "Training loss (for one batch) at step 0: 0.2859\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2759\n",
            "Validation acc: 0.9301\n",
            "Time taken: 0.12s\n",
            "\n",
            "Start of epoch 1684\n",
            "Training loss (for one batch) at step 0: 0.2854\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2797\n",
            "Validation acc: 0.9295\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 1685\n",
            "Training loss (for one batch) at step 0: 0.2849\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2759\n",
            "Validation acc: 0.9302\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 1686\n",
            "Training loss (for one batch) at step 0: 0.2880\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2810\n",
            "Validation acc: 0.9295\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 1687\n",
            "Training loss (for one batch) at step 0: 0.2842\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2766\n",
            "Validation acc: 0.9302\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 1688\n",
            "Training loss (for one batch) at step 0: 0.2887\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2792\n",
            "Validation acc: 0.9297\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 1689\n",
            "Training loss (for one batch) at step 0: 0.2839\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2780\n",
            "Validation acc: 0.9302\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 1690\n",
            "Training loss (for one batch) at step 0: 0.2887\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2797\n",
            "Validation acc: 0.9296\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 1691\n",
            "Training loss (for one batch) at step 0: 0.2839\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2766\n",
            "Validation acc: 0.9299\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 1692\n",
            "Training loss (for one batch) at step 0: 0.2913\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2816\n",
            "Validation acc: 0.9296\n",
            "Time taken: 0.08s\n",
            "\n",
            "Start of epoch 1693\n",
            "Training loss (for one batch) at step 0: 0.2839\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2812\n",
            "Validation acc: 0.9300\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 1694\n",
            "Training loss (for one batch) at step 0: 0.2863\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2785\n",
            "Validation acc: 0.9295\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 1695\n",
            "Training loss (for one batch) at step 0: 0.2843\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2837\n",
            "Validation acc: 0.9291\n",
            "Time taken: 0.10s\n",
            "\n",
            "Start of epoch 1696\n",
            "Training loss (for one batch) at step 0: 0.2854\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2755\n",
            "Validation acc: 0.9300\n",
            "Time taken: 0.12s\n",
            "\n",
            "Start of epoch 1697\n",
            "Training loss (for one batch) at step 0: 0.2891\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2820\n",
            "Validation acc: 0.9296\n",
            "Time taken: 0.12s\n",
            "\n",
            "Start of epoch 1698\n",
            "Training loss (for one batch) at step 0: 0.2854\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2761\n",
            "Validation acc: 0.9302\n",
            "Time taken: 0.08s\n",
            "\n",
            "Start of epoch 1699\n",
            "Training loss (for one batch) at step 0: 0.2863\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2793\n",
            "Validation acc: 0.9298\n",
            "Time taken: 0.10s\n",
            "\n",
            "Start of epoch 1700\n",
            "Training loss (for one batch) at step 0: 0.2853\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2759\n",
            "Validation acc: 0.9302\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 1701\n",
            "Training loss (for one batch) at step 0: 0.2863\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2788\n",
            "Validation acc: 0.9298\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 1702\n",
            "Training loss (for one batch) at step 0: 0.2847\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2770\n",
            "Validation acc: 0.9302\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 1703\n",
            "Training loss (for one batch) at step 0: 0.2863\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2783\n",
            "Validation acc: 0.9299\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 1704\n",
            "Training loss (for one batch) at step 0: 0.2841\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2771\n",
            "Validation acc: 0.9302\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 1705\n",
            "Training loss (for one batch) at step 0: 0.2863\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2788\n",
            "Validation acc: 0.9297\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 1706\n",
            "Training loss (for one batch) at step 0: 0.2839\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2763\n",
            "Validation acc: 0.9303\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 1707\n",
            "Training loss (for one batch) at step 0: 0.2880\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2804\n",
            "Validation acc: 0.9295\n",
            "Time taken: 0.10s\n",
            "\n",
            "Start of epoch 1708\n",
            "Training loss (for one batch) at step 0: 0.2840\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2760\n",
            "Validation acc: 0.9301\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 1709\n",
            "Training loss (for one batch) at step 0: 0.2900\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2804\n",
            "Validation acc: 0.9292\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 1710\n",
            "Training loss (for one batch) at step 0: 0.2841\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2786\n",
            "Validation acc: 0.9301\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 1711\n",
            "Training loss (for one batch) at step 0: 0.2873\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2779\n",
            "Validation acc: 0.9298\n",
            "Time taken: 0.14s\n",
            "\n",
            "Start of epoch 1712\n",
            "Training loss (for one batch) at step 0: 0.2840\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2787\n",
            "Validation acc: 0.9299\n",
            "Time taken: 0.12s\n",
            "\n",
            "Start of epoch 1713\n",
            "Training loss (for one batch) at step 0: 0.2889\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2789\n",
            "Validation acc: 0.9297\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 1714\n",
            "Training loss (for one batch) at step 0: 0.2837\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2768\n",
            "Validation acc: 0.9301\n",
            "Time taken: 0.09s\n",
            "\n",
            "Start of epoch 1715\n",
            "Training loss (for one batch) at step 0: 0.2905\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2804\n",
            "Validation acc: 0.9292\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 1716\n",
            "Training loss (for one batch) at step 0: 0.2839\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2806\n",
            "Validation acc: 0.9301\n",
            "Time taken: 0.09s\n",
            "\n",
            "Start of epoch 1717\n",
            "Training loss (for one batch) at step 0: 0.2871\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2768\n",
            "Validation acc: 0.9300\n",
            "Time taken: 0.08s\n",
            "\n",
            "Start of epoch 1718\n",
            "Training loss (for one batch) at step 0: 0.2847\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2828\n",
            "Validation acc: 0.9299\n",
            "Time taken: 0.12s\n",
            "\n",
            "Start of epoch 1719\n",
            "Training loss (for one batch) at step 0: 0.2870\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2782\n",
            "Validation acc: 0.9300\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 1720\n",
            "Training loss (for one batch) at step 0: 0.2846\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2832\n",
            "Validation acc: 0.9292\n",
            "Time taken: 0.12s\n",
            "\n",
            "Start of epoch 1721\n",
            "Training loss (for one batch) at step 0: 0.2852\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2753\n",
            "Validation acc: 0.9301\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 1722\n",
            "Training loss (for one batch) at step 0: 0.2872\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2812\n",
            "Validation acc: 0.9298\n",
            "Time taken: 0.12s\n",
            "\n",
            "Start of epoch 1723\n",
            "Training loss (for one batch) at step 0: 0.2879\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2771\n",
            "Validation acc: 0.9301\n",
            "Time taken: 0.09s\n",
            "\n",
            "Start of epoch 1724\n",
            "Training loss (for one batch) at step 0: 0.2859\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2837\n",
            "Validation acc: 0.9297\n",
            "Time taken: 0.12s\n",
            "\n",
            "Start of epoch 1725\n",
            "Training loss (for one batch) at step 0: 0.2859\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2757\n",
            "Validation acc: 0.9302\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 1726\n",
            "Training loss (for one batch) at step 0: 0.2868\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2824\n",
            "Validation acc: 0.9298\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 1727\n",
            "Training loss (for one batch) at step 0: 0.2873\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2770\n",
            "Validation acc: 0.9301\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 1728\n",
            "Training loss (for one batch) at step 0: 0.2860\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2817\n",
            "Validation acc: 0.9297\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 1729\n",
            "Training loss (for one batch) at step 0: 0.2858\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2760\n",
            "Validation acc: 0.9301\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 1730\n",
            "Training loss (for one batch) at step 0: 0.2862\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2824\n",
            "Validation acc: 0.9298\n",
            "Time taken: 0.14s\n",
            "\n",
            "Start of epoch 1731\n",
            "Training loss (for one batch) at step 0: 0.2857\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2757\n",
            "Validation acc: 0.9301\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 1732\n",
            "Training loss (for one batch) at step 0: 0.2857\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2836\n",
            "Validation acc: 0.9294\n",
            "Time taken: 0.12s\n",
            "\n",
            "Start of epoch 1733\n",
            "Training loss (for one batch) at step 0: 0.2860\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2758\n",
            "Validation acc: 0.9303\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 1734\n",
            "Training loss (for one batch) at step 0: 0.2878\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2833\n",
            "Validation acc: 0.9294\n",
            "Time taken: 0.09s\n",
            "\n",
            "Start of epoch 1735\n",
            "Training loss (for one batch) at step 0: 0.2857\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2749\n",
            "Validation acc: 0.9300\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 1736\n",
            "Training loss (for one batch) at step 0: 0.2901\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2825\n",
            "Validation acc: 0.9292\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 1737\n",
            "Training loss (for one batch) at step 0: 0.2858\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2752\n",
            "Validation acc: 0.9302\n",
            "Time taken: 0.12s\n",
            "\n",
            "Start of epoch 1738\n",
            "Training loss (for one batch) at step 0: 0.2857\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2788\n",
            "Validation acc: 0.9295\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 1739\n",
            "Training loss (for one batch) at step 0: 0.2871\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2761\n",
            "Validation acc: 0.9302\n",
            "Time taken: 0.10s\n",
            "\n",
            "Start of epoch 1740\n",
            "Training loss (for one batch) at step 0: 0.2865\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2781\n",
            "Validation acc: 0.9293\n",
            "Time taken: 0.09s\n",
            "\n",
            "Start of epoch 1741\n",
            "Training loss (for one batch) at step 0: 0.2856\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2762\n",
            "Validation acc: 0.9302\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 1742\n",
            "Training loss (for one batch) at step 0: 0.2883\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2787\n",
            "Validation acc: 0.9296\n",
            "Time taken: 0.12s\n",
            "\n",
            "Start of epoch 1743\n",
            "Training loss (for one batch) at step 0: 0.2839\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2769\n",
            "Validation acc: 0.9301\n",
            "Time taken: 0.12s\n",
            "\n",
            "Start of epoch 1744\n",
            "Training loss (for one batch) at step 0: 0.2899\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2795\n",
            "Validation acc: 0.9297\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 1745\n",
            "Training loss (for one batch) at step 0: 0.2835\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2805\n",
            "Validation acc: 0.9300\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 1746\n",
            "Training loss (for one batch) at step 0: 0.2860\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2775\n",
            "Validation acc: 0.9297\n",
            "Time taken: 0.08s\n",
            "\n",
            "Start of epoch 1747\n",
            "Training loss (for one batch) at step 0: 0.2845\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2820\n",
            "Validation acc: 0.9297\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 1748\n",
            "Training loss (for one batch) at step 0: 0.2853\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2764\n",
            "Validation acc: 0.9300\n",
            "Time taken: 0.14s\n",
            "\n",
            "Start of epoch 1749\n",
            "Training loss (for one batch) at step 0: 0.2859\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2818\n",
            "Validation acc: 0.9299\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 1750\n",
            "Training loss (for one batch) at step 0: 0.2866\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2762\n",
            "Validation acc: 0.9301\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 1751\n",
            "Training loss (for one batch) at step 0: 0.2861\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2817\n",
            "Validation acc: 0.9295\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 1752\n",
            "Training loss (for one batch) at step 0: 0.2855\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2749\n",
            "Validation acc: 0.9300\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 1753\n",
            "Training loss (for one batch) at step 0: 0.2868\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2796\n",
            "Validation acc: 0.9297\n",
            "Time taken: 0.12s\n",
            "\n",
            "Start of epoch 1754\n",
            "Training loss (for one batch) at step 0: 0.2872\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2760\n",
            "Validation acc: 0.9300\n",
            "Time taken: 0.08s\n",
            "\n",
            "Start of epoch 1755\n",
            "Training loss (for one batch) at step 0: 0.2848\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2830\n",
            "Validation acc: 0.9294\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 1756\n",
            "Training loss (for one batch) at step 0: 0.2853\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2755\n",
            "Validation acc: 0.9301\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 1757\n",
            "Training loss (for one batch) at step 0: 0.2877\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2833\n",
            "Validation acc: 0.9293\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 1758\n",
            "Training loss (for one batch) at step 0: 0.2857\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2751\n",
            "Validation acc: 0.9300\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 1759\n",
            "Training loss (for one batch) at step 0: 0.2878\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2800\n",
            "Validation acc: 0.9295\n",
            "Time taken: 0.10s\n",
            "\n",
            "Start of epoch 1760\n",
            "Training loss (for one batch) at step 0: 0.2863\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2750\n",
            "Validation acc: 0.9301\n",
            "Time taken: 0.12s\n",
            "\n",
            "Start of epoch 1761\n",
            "Training loss (for one batch) at step 0: 0.2859\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2779\n",
            "Validation acc: 0.9298\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 1762\n",
            "Training loss (for one batch) at step 0: 0.2858\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2760\n",
            "Validation acc: 0.9298\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 1763\n",
            "Training loss (for one batch) at step 0: 0.2850\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2765\n",
            "Validation acc: 0.9300\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 1764\n",
            "Training loss (for one batch) at step 0: 0.2866\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2773\n",
            "Validation acc: 0.9297\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 1765\n",
            "Training loss (for one batch) at step 0: 0.2847\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2768\n",
            "Validation acc: 0.9299\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 1766\n",
            "Training loss (for one batch) at step 0: 0.2863\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2770\n",
            "Validation acc: 0.9297\n",
            "Time taken: 0.12s\n",
            "\n",
            "Start of epoch 1767\n",
            "Training loss (for one batch) at step 0: 0.2841\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2770\n",
            "Validation acc: 0.9299\n",
            "Time taken: 0.10s\n",
            "\n",
            "Start of epoch 1768\n",
            "Training loss (for one batch) at step 0: 0.2867\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2767\n",
            "Validation acc: 0.9297\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 1769\n",
            "Training loss (for one batch) at step 0: 0.2839\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2768\n",
            "Validation acc: 0.9298\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 1770\n",
            "Training loss (for one batch) at step 0: 0.2864\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2771\n",
            "Validation acc: 0.9296\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 1771\n",
            "Training loss (for one batch) at step 0: 0.2837\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2769\n",
            "Validation acc: 0.9300\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 1772\n",
            "Training loss (for one batch) at step 0: 0.2876\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2777\n",
            "Validation acc: 0.9295\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 1773\n",
            "Training loss (for one batch) at step 0: 0.2837\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2766\n",
            "Validation acc: 0.9299\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 1774\n",
            "Training loss (for one batch) at step 0: 0.2875\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2775\n",
            "Validation acc: 0.9293\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 1775\n",
            "Training loss (for one batch) at step 0: 0.2838\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2756\n",
            "Validation acc: 0.9298\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 1776\n",
            "Training loss (for one batch) at step 0: 0.2898\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2797\n",
            "Validation acc: 0.9291\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 1777\n",
            "Training loss (for one batch) at step 0: 0.2838\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2757\n",
            "Validation acc: 0.9299\n",
            "Time taken: 0.19s\n",
            "\n",
            "Start of epoch 1778\n",
            "Training loss (for one batch) at step 0: 0.2871\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2776\n",
            "Validation acc: 0.9294\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 1779\n",
            "Training loss (for one batch) at step 0: 0.2838\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2758\n",
            "Validation acc: 0.9300\n",
            "Time taken: 0.12s\n",
            "\n",
            "Start of epoch 1780\n",
            "Training loss (for one batch) at step 0: 0.2864\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2770\n",
            "Validation acc: 0.9297\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 1781\n",
            "Training loss (for one batch) at step 0: 0.2847\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2768\n",
            "Validation acc: 0.9300\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 1782\n",
            "Training loss (for one batch) at step 0: 0.2864\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2768\n",
            "Validation acc: 0.9297\n",
            "Time taken: 0.09s\n",
            "\n",
            "Start of epoch 1783\n",
            "Training loss (for one batch) at step 0: 0.2847\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2770\n",
            "Validation acc: 0.9300\n",
            "Time taken: 0.12s\n",
            "\n",
            "Start of epoch 1784\n",
            "Training loss (for one batch) at step 0: 0.2868\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2769\n",
            "Validation acc: 0.9295\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 1785\n",
            "Training loss (for one batch) at step 0: 0.2839\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2761\n",
            "Validation acc: 0.9300\n",
            "Time taken: 0.09s\n",
            "\n",
            "Start of epoch 1786\n",
            "Training loss (for one batch) at step 0: 0.2881\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2775\n",
            "Validation acc: 0.9293\n",
            "Time taken: 0.12s\n",
            "\n",
            "Start of epoch 1787\n",
            "Training loss (for one batch) at step 0: 0.2837\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2754\n",
            "Validation acc: 0.9297\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 1788\n",
            "Training loss (for one batch) at step 0: 0.2902\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2793\n",
            "Validation acc: 0.9291\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 1789\n",
            "Training loss (for one batch) at step 0: 0.2837\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2758\n",
            "Validation acc: 0.9300\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 1790\n",
            "Training loss (for one batch) at step 0: 0.2883\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2773\n",
            "Validation acc: 0.9295\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 1791\n",
            "Training loss (for one batch) at step 0: 0.2842\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2767\n",
            "Validation acc: 0.9299\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 1792\n",
            "Training loss (for one batch) at step 0: 0.2872\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2770\n",
            "Validation acc: 0.9295\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 1793\n",
            "Training loss (for one batch) at step 0: 0.2840\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2766\n",
            "Validation acc: 0.9297\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 1794\n",
            "Training loss (for one batch) at step 0: 0.2876\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2768\n",
            "Validation acc: 0.9296\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 1795\n",
            "Training loss (for one batch) at step 0: 0.2838\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2756\n",
            "Validation acc: 0.9298\n",
            "Time taken: 0.08s\n",
            "\n",
            "Start of epoch 1796\n",
            "Training loss (for one batch) at step 0: 0.2893\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2792\n",
            "Validation acc: 0.9295\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 1797\n",
            "Training loss (for one batch) at step 0: 0.2844\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2757\n",
            "Validation acc: 0.9300\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 1798\n",
            "Training loss (for one batch) at step 0: 0.2863\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2773\n",
            "Validation acc: 0.9296\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 1799\n",
            "Training loss (for one batch) at step 0: 0.2848\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2765\n",
            "Validation acc: 0.9300\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 1800\n",
            "Training loss (for one batch) at step 0: 0.2868\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2770\n",
            "Validation acc: 0.9297\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 1801\n",
            "Training loss (for one batch) at step 0: 0.2847\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2759\n",
            "Validation acc: 0.9300\n",
            "Time taken: 0.08s\n",
            "\n",
            "Start of epoch 1802\n",
            "Training loss (for one batch) at step 0: 0.2875\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2779\n",
            "Validation acc: 0.9296\n",
            "Time taken: 0.12s\n",
            "\n",
            "Start of epoch 1803\n",
            "Training loss (for one batch) at step 0: 0.2852\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2759\n",
            "Validation acc: 0.9300\n",
            "Time taken: 0.12s\n",
            "\n",
            "Start of epoch 1804\n",
            "Training loss (for one batch) at step 0: 0.2861\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2774\n",
            "Validation acc: 0.9297\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 1805\n",
            "Training loss (for one batch) at step 0: 0.2853\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2764\n",
            "Validation acc: 0.9300\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 1806\n",
            "Training loss (for one batch) at step 0: 0.2852\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2764\n",
            "Validation acc: 0.9299\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 1807\n",
            "Training loss (for one batch) at step 0: 0.2857\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2765\n",
            "Validation acc: 0.9297\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 1808\n",
            "Training loss (for one batch) at step 0: 0.2853\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2766\n",
            "Validation acc: 0.9300\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 1809\n",
            "Training loss (for one batch) at step 0: 0.2860\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2766\n",
            "Validation acc: 0.9297\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 1810\n",
            "Training loss (for one batch) at step 0: 0.2845\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2770\n",
            "Validation acc: 0.9298\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 1811\n",
            "Training loss (for one batch) at step 0: 0.2870\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2769\n",
            "Validation acc: 0.9296\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 1812\n",
            "Training loss (for one batch) at step 0: 0.2837\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2758\n",
            "Validation acc: 0.9298\n",
            "Time taken: 0.09s\n",
            "\n",
            "Start of epoch 1813\n",
            "Training loss (for one batch) at step 0: 0.2890\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2793\n",
            "Validation acc: 0.9296\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 1814\n",
            "Training loss (for one batch) at step 0: 0.2837\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2749\n",
            "Validation acc: 0.9301\n",
            "Time taken: 0.14s\n",
            "\n",
            "Start of epoch 1815\n",
            "Training loss (for one batch) at step 0: 0.2873\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2781\n",
            "Validation acc: 0.9296\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 1816\n",
            "Training loss (for one batch) at step 0: 0.2848\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2758\n",
            "Validation acc: 0.9301\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 1817\n",
            "Training loss (for one batch) at step 0: 0.2860\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2770\n",
            "Validation acc: 0.9297\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 1818\n",
            "Training loss (for one batch) at step 0: 0.2852\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2762\n",
            "Validation acc: 0.9297\n",
            "Time taken: 0.09s\n",
            "\n",
            "Start of epoch 1819\n",
            "Training loss (for one batch) at step 0: 0.2853\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2764\n",
            "Validation acc: 0.9299\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 1820\n",
            "Training loss (for one batch) at step 0: 0.2858\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2762\n",
            "Validation acc: 0.9297\n",
            "Time taken: 0.10s\n",
            "\n",
            "Start of epoch 1821\n",
            "Training loss (for one batch) at step 0: 0.2854\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2774\n",
            "Validation acc: 0.9299\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 1822\n",
            "Training loss (for one batch) at step 0: 0.2858\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2763\n",
            "Validation acc: 0.9295\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 1823\n",
            "Training loss (for one batch) at step 0: 0.2843\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2756\n",
            "Validation acc: 0.9296\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 1824\n",
            "Training loss (for one batch) at step 0: 0.2911\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2799\n",
            "Validation acc: 0.9289\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 1825\n",
            "Training loss (for one batch) at step 0: 0.2836\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2773\n",
            "Validation acc: 0.9299\n",
            "Time taken: 0.10s\n",
            "\n",
            "Start of epoch 1826\n",
            "Training loss (for one batch) at step 0: 0.2883\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2782\n",
            "Validation acc: 0.9293\n",
            "Time taken: 0.14s\n",
            "\n",
            "Start of epoch 1827\n",
            "Training loss (for one batch) at step 0: 0.2835\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2747\n",
            "Validation acc: 0.9298\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 1828\n",
            "Training loss (for one batch) at step 0: 0.2895\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2779\n",
            "Validation acc: 0.9292\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 1829\n",
            "Training loss (for one batch) at step 0: 0.2836\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2757\n",
            "Validation acc: 0.9299\n",
            "Time taken: 0.09s\n",
            "\n",
            "Start of epoch 1830\n",
            "Training loss (for one batch) at step 0: 0.2891\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2792\n",
            "Validation acc: 0.9291\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 1831\n",
            "Training loss (for one batch) at step 0: 0.2841\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2750\n",
            "Validation acc: 0.9300\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 1832\n",
            "Training loss (for one batch) at step 0: 0.2886\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2792\n",
            "Validation acc: 0.9290\n",
            "Time taken: 0.08s\n",
            "\n",
            "Start of epoch 1833\n",
            "Training loss (for one batch) at step 0: 0.2845\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2760\n",
            "Validation acc: 0.9299\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 1834\n",
            "Training loss (for one batch) at step 0: 0.2892\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2783\n",
            "Validation acc: 0.9287\n",
            "Time taken: 0.12s\n",
            "\n",
            "Start of epoch 1835\n",
            "Training loss (for one batch) at step 0: 0.2842\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2771\n",
            "Validation acc: 0.9295\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 1836\n",
            "Training loss (for one batch) at step 0: 0.2888\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2766\n",
            "Validation acc: 0.9295\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 1837\n",
            "Training loss (for one batch) at step 0: 0.2832\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2753\n",
            "Validation acc: 0.9297\n",
            "Time taken: 0.09s\n",
            "\n",
            "Start of epoch 1838\n",
            "Training loss (for one batch) at step 0: 0.2895\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2788\n",
            "Validation acc: 0.9288\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 1839\n",
            "Training loss (for one batch) at step 0: 0.2847\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2755\n",
            "Validation acc: 0.9299\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 1840\n",
            "Training loss (for one batch) at step 0: 0.2888\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2783\n",
            "Validation acc: 0.9291\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 1841\n",
            "Training loss (for one batch) at step 0: 0.2836\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2764\n",
            "Validation acc: 0.9299\n",
            "Time taken: 0.09s\n",
            "\n",
            "Start of epoch 1842\n",
            "Training loss (for one batch) at step 0: 0.2890\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2792\n",
            "Validation acc: 0.9288\n",
            "Time taken: 0.12s\n",
            "\n",
            "Start of epoch 1843\n",
            "Training loss (for one batch) at step 0: 0.2837\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2776\n",
            "Validation acc: 0.9297\n",
            "Time taken: 0.08s\n",
            "\n",
            "Start of epoch 1844\n",
            "Training loss (for one batch) at step 0: 0.2867\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2766\n",
            "Validation acc: 0.9292\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 1845\n",
            "Training loss (for one batch) at step 0: 0.2838\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2767\n",
            "Validation acc: 0.9297\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 1846\n",
            "Training loss (for one batch) at step 0: 0.2871\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2768\n",
            "Validation acc: 0.9291\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 1847\n",
            "Training loss (for one batch) at step 0: 0.2839\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2753\n",
            "Validation acc: 0.9296\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 1848\n",
            "Training loss (for one batch) at step 0: 0.2888\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2767\n",
            "Validation acc: 0.9294\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 1849\n",
            "Training loss (for one batch) at step 0: 0.2833\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2745\n",
            "Validation acc: 0.9296\n",
            "Time taken: 0.10s\n",
            "\n",
            "Start of epoch 1850\n",
            "Training loss (for one batch) at step 0: 0.2914\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2795\n",
            "Validation acc: 0.9287\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 1851\n",
            "Training loss (for one batch) at step 0: 0.2842\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2767\n",
            "Validation acc: 0.9298\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 1852\n",
            "Training loss (for one batch) at step 0: 0.2886\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2793\n",
            "Validation acc: 0.9290\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 1853\n",
            "Training loss (for one batch) at step 0: 0.2841\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2753\n",
            "Validation acc: 0.9298\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 1854\n",
            "Training loss (for one batch) at step 0: 0.2884\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2768\n",
            "Validation acc: 0.9293\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 1855\n",
            "Training loss (for one batch) at step 0: 0.2837\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2747\n",
            "Validation acc: 0.9296\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 1856\n",
            "Training loss (for one batch) at step 0: 0.2897\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2784\n",
            "Validation acc: 0.9289\n",
            "Time taken: 0.12s\n",
            "\n",
            "Start of epoch 1857\n",
            "Training loss (for one batch) at step 0: 0.2845\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2752\n",
            "Validation acc: 0.9297\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 1858\n",
            "Training loss (for one batch) at step 0: 0.2904\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2786\n",
            "Validation acc: 0.9289\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 1859\n",
            "Training loss (for one batch) at step 0: 0.2840\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2764\n",
            "Validation acc: 0.9297\n",
            "Time taken: 0.08s\n",
            "\n",
            "Start of epoch 1860\n",
            "Training loss (for one batch) at step 0: 0.2897\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2783\n",
            "Validation acc: 0.9291\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 1861\n",
            "Training loss (for one batch) at step 0: 0.2840\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2742\n",
            "Validation acc: 0.9298\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 1862\n",
            "Training loss (for one batch) at step 0: 0.2899\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2790\n",
            "Validation acc: 0.9291\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 1863\n",
            "Training loss (for one batch) at step 0: 0.2837\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2780\n",
            "Validation acc: 0.9297\n",
            "Time taken: 0.18s\n",
            "\n",
            "Start of epoch 1864\n",
            "Training loss (for one batch) at step 0: 0.2861\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2767\n",
            "Validation acc: 0.9291\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 1865\n",
            "Training loss (for one batch) at step 0: 0.2844\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2799\n",
            "Validation acc: 0.9294\n",
            "Time taken: 0.09s\n",
            "\n",
            "Start of epoch 1866\n",
            "Training loss (for one batch) at step 0: 0.2859\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2771\n",
            "Validation acc: 0.9290\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 1867\n",
            "Training loss (for one batch) at step 0: 0.2837\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2819\n",
            "Validation acc: 0.9287\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 1868\n",
            "Training loss (for one batch) at step 0: 0.2845\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2743\n",
            "Validation acc: 0.9298\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 1869\n",
            "Training loss (for one batch) at step 0: 0.2862\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2787\n",
            "Validation acc: 0.9292\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 1870\n",
            "Training loss (for one batch) at step 0: 0.2864\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2748\n",
            "Validation acc: 0.9297\n",
            "Time taken: 0.10s\n",
            "\n",
            "Start of epoch 1871\n",
            "Training loss (for one batch) at step 0: 0.2840\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2803\n",
            "Validation acc: 0.9296\n",
            "Time taken: 0.09s\n",
            "\n",
            "Start of epoch 1872\n",
            "Training loss (for one batch) at step 0: 0.2859\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2773\n",
            "Validation acc: 0.9292\n",
            "Time taken: 0.14s\n",
            "\n",
            "Start of epoch 1873\n",
            "Training loss (for one batch) at step 0: 0.2839\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2777\n",
            "Validation acc: 0.9290\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 1874\n",
            "Training loss (for one batch) at step 0: 0.2867\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2747\n",
            "Validation acc: 0.9297\n",
            "Time taken: 0.14s\n",
            "\n",
            "Start of epoch 1875\n",
            "Training loss (for one batch) at step 0: 0.2834\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2821\n",
            "Validation acc: 0.9294\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 1876\n",
            "Training loss (for one batch) at step 0: 0.2842\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2756\n",
            "Validation acc: 0.9294\n",
            "Time taken: 0.09s\n",
            "\n",
            "Start of epoch 1877\n",
            "Training loss (for one batch) at step 0: 0.2848\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2819\n",
            "Validation acc: 0.9289\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 1878\n",
            "Training loss (for one batch) at step 0: 0.2851\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2756\n",
            "Validation acc: 0.9299\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 1879\n",
            "Training loss (for one batch) at step 0: 0.2852\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2814\n",
            "Validation acc: 0.9294\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 1880\n",
            "Training loss (for one batch) at step 0: 0.2847\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2748\n",
            "Validation acc: 0.9297\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 1881\n",
            "Training loss (for one batch) at step 0: 0.2872\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2809\n",
            "Validation acc: 0.9285\n",
            "Time taken: 0.12s\n",
            "\n",
            "Start of epoch 1882\n",
            "Training loss (for one batch) at step 0: 0.2849\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2727\n",
            "Validation acc: 0.9299\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 1883\n",
            "Training loss (for one batch) at step 0: 0.2861\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2779\n",
            "Validation acc: 0.9294\n",
            "Time taken: 0.09s\n",
            "\n",
            "Start of epoch 1884\n",
            "Training loss (for one batch) at step 0: 0.2850\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2740\n",
            "Validation acc: 0.9299\n",
            "Time taken: 0.12s\n",
            "\n",
            "Start of epoch 1885\n",
            "Training loss (for one batch) at step 0: 0.2849\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2819\n",
            "Validation acc: 0.9293\n",
            "Time taken: 0.08s\n",
            "\n",
            "Start of epoch 1886\n",
            "Training loss (for one batch) at step 0: 0.2842\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2747\n",
            "Validation acc: 0.9295\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 1887\n",
            "Training loss (for one batch) at step 0: 0.2850\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2800\n",
            "Validation acc: 0.9291\n",
            "Time taken: 0.12s\n",
            "\n",
            "Start of epoch 1888\n",
            "Training loss (for one batch) at step 0: 0.2852\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2744\n",
            "Validation acc: 0.9297\n",
            "Time taken: 0.12s\n",
            "\n",
            "Start of epoch 1889\n",
            "Training loss (for one batch) at step 0: 0.2844\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2798\n",
            "Validation acc: 0.9294\n",
            "Time taken: 0.12s\n",
            "\n",
            "Start of epoch 1890\n",
            "Training loss (for one batch) at step 0: 0.2858\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2753\n",
            "Validation acc: 0.9296\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 1891\n",
            "Training loss (for one batch) at step 0: 0.2840\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2790\n",
            "Validation acc: 0.9295\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 1892\n",
            "Training loss (for one batch) at step 0: 0.2851\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2751\n",
            "Validation acc: 0.9292\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 1893\n",
            "Training loss (for one batch) at step 0: 0.2838\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2748\n",
            "Validation acc: 0.9292\n",
            "Time taken: 0.14s\n",
            "\n",
            "Start of epoch 1894\n",
            "Training loss (for one batch) at step 0: 0.2885\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2748\n",
            "Validation acc: 0.9298\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 1895\n",
            "Training loss (for one batch) at step 0: 0.2837\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2777\n",
            "Validation acc: 0.9297\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 1896\n",
            "Training loss (for one batch) at step 0: 0.2850\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2763\n",
            "Validation acc: 0.9292\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 1897\n",
            "Training loss (for one batch) at step 0: 0.2842\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2746\n",
            "Validation acc: 0.9295\n",
            "Time taken: 0.14s\n",
            "\n",
            "Start of epoch 1898\n",
            "Training loss (for one batch) at step 0: 0.2891\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2776\n",
            "Validation acc: 0.9294\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 1899\n",
            "Training loss (for one batch) at step 0: 0.2839\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2741\n",
            "Validation acc: 0.9299\n",
            "Time taken: 0.10s\n",
            "\n",
            "Start of epoch 1900\n",
            "Training loss (for one batch) at step 0: 0.2884\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2778\n",
            "Validation acc: 0.9292\n",
            "Time taken: 0.09s\n",
            "\n",
            "Start of epoch 1901\n",
            "Training loss (for one batch) at step 0: 0.2843\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2738\n",
            "Validation acc: 0.9297\n",
            "Time taken: 0.09s\n",
            "\n",
            "Start of epoch 1902\n",
            "Training loss (for one batch) at step 0: 0.2911\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2801\n",
            "Validation acc: 0.9288\n",
            "Time taken: 0.12s\n",
            "\n",
            "Start of epoch 1903\n",
            "Training loss (for one batch) at step 0: 0.2832\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2755\n",
            "Validation acc: 0.9297\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 1904\n",
            "Training loss (for one batch) at step 0: 0.2871\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2756\n",
            "Validation acc: 0.9294\n",
            "Time taken: 0.12s\n",
            "\n",
            "Start of epoch 1905\n",
            "Training loss (for one batch) at step 0: 0.2835\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2748\n",
            "Validation acc: 0.9296\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 1906\n",
            "Training loss (for one batch) at step 0: 0.2877\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2757\n",
            "Validation acc: 0.9295\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 1907\n",
            "Training loss (for one batch) at step 0: 0.2837\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2753\n",
            "Validation acc: 0.9297\n",
            "Time taken: 0.12s\n",
            "\n",
            "Start of epoch 1908\n",
            "Training loss (for one batch) at step 0: 0.2866\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2759\n",
            "Validation acc: 0.9297\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 1909\n",
            "Training loss (for one batch) at step 0: 0.2841\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2752\n",
            "Validation acc: 0.9297\n",
            "Time taken: 0.12s\n",
            "\n",
            "Start of epoch 1910\n",
            "Training loss (for one batch) at step 0: 0.2867\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2764\n",
            "Validation acc: 0.9297\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 1911\n",
            "Training loss (for one batch) at step 0: 0.2835\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2746\n",
            "Validation acc: 0.9298\n",
            "Time taken: 0.12s\n",
            "\n",
            "Start of epoch 1912\n",
            "Training loss (for one batch) at step 0: 0.2874\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2778\n",
            "Validation acc: 0.9294\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 1913\n",
            "Training loss (for one batch) at step 0: 0.2845\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2747\n",
            "Validation acc: 0.9299\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 1914\n",
            "Training loss (for one batch) at step 0: 0.2854\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2760\n",
            "Validation acc: 0.9294\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 1915\n",
            "Training loss (for one batch) at step 0: 0.2840\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2746\n",
            "Validation acc: 0.9298\n",
            "Time taken: 0.10s\n",
            "\n",
            "Start of epoch 1916\n",
            "Training loss (for one batch) at step 0: 0.2865\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2768\n",
            "Validation acc: 0.9295\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 1917\n",
            "Training loss (for one batch) at step 0: 0.2835\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2743\n",
            "Validation acc: 0.9298\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 1918\n",
            "Training loss (for one batch) at step 0: 0.2856\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2759\n",
            "Validation acc: 0.9297\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 1919\n",
            "Training loss (for one batch) at step 0: 0.2847\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2762\n",
            "Validation acc: 0.9297\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 1920\n",
            "Training loss (for one batch) at step 0: 0.2837\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2749\n",
            "Validation acc: 0.9297\n",
            "Time taken: 0.08s\n",
            "\n",
            "Start of epoch 1921\n",
            "Training loss (for one batch) at step 0: 0.2864\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2762\n",
            "Validation acc: 0.9296\n",
            "Time taken: 0.08s\n",
            "\n",
            "Start of epoch 1922\n",
            "Training loss (for one batch) at step 0: 0.2837\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2743\n",
            "Validation acc: 0.9297\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 1923\n",
            "Training loss (for one batch) at step 0: 0.2856\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2760\n",
            "Validation acc: 0.9298\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 1924\n",
            "Training loss (for one batch) at step 0: 0.2845\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2765\n",
            "Validation acc: 0.9297\n",
            "Time taken: 0.22s\n",
            "\n",
            "Start of epoch 1925\n",
            "Training loss (for one batch) at step 0: 0.2846\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2751\n",
            "Validation acc: 0.9297\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 1926\n",
            "Training loss (for one batch) at step 0: 0.2849\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2759\n",
            "Validation acc: 0.9297\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 1927\n",
            "Training loss (for one batch) at step 0: 0.2846\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2752\n",
            "Validation acc: 0.9297\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 1928\n",
            "Training loss (for one batch) at step 0: 0.2845\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2757\n",
            "Validation acc: 0.9298\n",
            "Time taken: 0.12s\n",
            "\n",
            "Start of epoch 1929\n",
            "Training loss (for one batch) at step 0: 0.2853\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2763\n",
            "Validation acc: 0.9295\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 1930\n",
            "Training loss (for one batch) at step 0: 0.2833\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2742\n",
            "Validation acc: 0.9298\n",
            "Time taken: 0.10s\n",
            "\n",
            "Start of epoch 1931\n",
            "Training loss (for one batch) at step 0: 0.2859\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2763\n",
            "Validation acc: 0.9296\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 1932\n",
            "Training loss (for one batch) at step 0: 0.2837\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2749\n",
            "Validation acc: 0.9297\n",
            "Time taken: 0.14s\n",
            "\n",
            "Start of epoch 1933\n",
            "Training loss (for one batch) at step 0: 0.2848\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2758\n",
            "Validation acc: 0.9298\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 1934\n",
            "Training loss (for one batch) at step 0: 0.2846\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2752\n",
            "Validation acc: 0.9297\n",
            "Time taken: 0.10s\n",
            "\n",
            "Start of epoch 1935\n",
            "Training loss (for one batch) at step 0: 0.2841\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2748\n",
            "Validation acc: 0.9296\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 1936\n",
            "Training loss (for one batch) at step 0: 0.2852\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2757\n",
            "Validation acc: 0.9299\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 1937\n",
            "Training loss (for one batch) at step 0: 0.2846\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2764\n",
            "Validation acc: 0.9297\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 1938\n",
            "Training loss (for one batch) at step 0: 0.2845\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2753\n",
            "Validation acc: 0.9297\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 1939\n",
            "Training loss (for one batch) at step 0: 0.2842\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2751\n",
            "Validation acc: 0.9297\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 1940\n",
            "Training loss (for one batch) at step 0: 0.2856\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2762\n",
            "Validation acc: 0.9298\n",
            "Time taken: 0.09s\n",
            "\n",
            "Start of epoch 1941\n",
            "Training loss (for one batch) at step 0: 0.2842\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2756\n",
            "Validation acc: 0.9296\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 1942\n",
            "Training loss (for one batch) at step 0: 0.2843\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2740\n",
            "Validation acc: 0.9298\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 1943\n",
            "Training loss (for one batch) at step 0: 0.2855\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2760\n",
            "Validation acc: 0.9298\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 1944\n",
            "Training loss (for one batch) at step 0: 0.2846\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2765\n",
            "Validation acc: 0.9297\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 1945\n",
            "Training loss (for one batch) at step 0: 0.2843\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2752\n",
            "Validation acc: 0.9297\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 1946\n",
            "Training loss (for one batch) at step 0: 0.2843\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2747\n",
            "Validation acc: 0.9298\n",
            "Time taken: 0.10s\n",
            "\n",
            "Start of epoch 1947\n",
            "Training loss (for one batch) at step 0: 0.2848\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2754\n",
            "Validation acc: 0.9295\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 1948\n",
            "Training loss (for one batch) at step 0: 0.2840\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2751\n",
            "Validation acc: 0.9297\n",
            "Time taken: 0.12s\n",
            "\n",
            "Start of epoch 1949\n",
            "Training loss (for one batch) at step 0: 0.2841\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2755\n",
            "Validation acc: 0.9297\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 1950\n",
            "Training loss (for one batch) at step 0: 0.2844\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2758\n",
            "Validation acc: 0.9297\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 1951\n",
            "Training loss (for one batch) at step 0: 0.2846\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2758\n",
            "Validation acc: 0.9297\n",
            "Time taken: 0.12s\n",
            "\n",
            "Start of epoch 1952\n",
            "Training loss (for one batch) at step 0: 0.2844\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2753\n",
            "Validation acc: 0.9297\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 1953\n",
            "Training loss (for one batch) at step 0: 0.2844\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2760\n",
            "Validation acc: 0.9297\n",
            "Time taken: 0.09s\n",
            "\n",
            "Start of epoch 1954\n",
            "Training loss (for one batch) at step 0: 0.2846\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2750\n",
            "Validation acc: 0.9296\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 1955\n",
            "Training loss (for one batch) at step 0: 0.2843\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2741\n",
            "Validation acc: 0.9298\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 1956\n",
            "Training loss (for one batch) at step 0: 0.2847\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2752\n",
            "Validation acc: 0.9298\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 1957\n",
            "Training loss (for one batch) at step 0: 0.2851\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2762\n",
            "Validation acc: 0.9298\n",
            "Time taken: 0.15s\n",
            "\n",
            "Start of epoch 1958\n",
            "Training loss (for one batch) at step 0: 0.2844\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2752\n",
            "Validation acc: 0.9297\n",
            "Time taken: 0.12s\n",
            "\n",
            "Start of epoch 1959\n",
            "Training loss (for one batch) at step 0: 0.2840\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2742\n",
            "Validation acc: 0.9296\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 1960\n",
            "Training loss (for one batch) at step 0: 0.2847\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2753\n",
            "Validation acc: 0.9298\n",
            "Time taken: 0.12s\n",
            "\n",
            "Start of epoch 1961\n",
            "Training loss (for one batch) at step 0: 0.2844\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2765\n",
            "Validation acc: 0.9297\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 1962\n",
            "Training loss (for one batch) at step 0: 0.2847\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2753\n",
            "Validation acc: 0.9297\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 1963\n",
            "Training loss (for one batch) at step 0: 0.2838\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2741\n",
            "Validation acc: 0.9297\n",
            "Time taken: 0.10s\n",
            "\n",
            "Start of epoch 1964\n",
            "Training loss (for one batch) at step 0: 0.2853\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2755\n",
            "Validation acc: 0.9298\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 1965\n",
            "Training loss (for one batch) at step 0: 0.2846\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2759\n",
            "Validation acc: 0.9297\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 1966\n",
            "Training loss (for one batch) at step 0: 0.2849\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2758\n",
            "Validation acc: 0.9297\n",
            "Time taken: 0.14s\n",
            "\n",
            "Start of epoch 1967\n",
            "Training loss (for one batch) at step 0: 0.2843\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2747\n",
            "Validation acc: 0.9296\n",
            "Time taken: 0.14s\n",
            "\n",
            "Start of epoch 1968\n",
            "Training loss (for one batch) at step 0: 0.2841\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2739\n",
            "Validation acc: 0.9297\n",
            "Time taken: 0.14s\n",
            "\n",
            "Start of epoch 1969\n",
            "Training loss (for one batch) at step 0: 0.2851\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2757\n",
            "Validation acc: 0.9298\n",
            "Time taken: 0.12s\n",
            "\n",
            "Start of epoch 1970\n",
            "Training loss (for one batch) at step 0: 0.2851\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2762\n",
            "Validation acc: 0.9294\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 1971\n",
            "Training loss (for one batch) at step 0: 0.2840\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2741\n",
            "Validation acc: 0.9298\n",
            "Time taken: 0.12s\n",
            "\n",
            "Start of epoch 1972\n",
            "Training loss (for one batch) at step 0: 0.2844\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2749\n",
            "Validation acc: 0.9297\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 1973\n",
            "Training loss (for one batch) at step 0: 0.2851\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2756\n",
            "Validation acc: 0.9297\n",
            "Time taken: 0.12s\n",
            "\n",
            "Start of epoch 1974\n",
            "Training loss (for one batch) at step 0: 0.2848\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2764\n",
            "Validation acc: 0.9296\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 1975\n",
            "Training loss (for one batch) at step 0: 0.2839\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2738\n",
            "Validation acc: 0.9298\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 1976\n",
            "Training loss (for one batch) at step 0: 0.2853\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2763\n",
            "Validation acc: 0.9295\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 1977\n",
            "Training loss (for one batch) at step 0: 0.2839\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2748\n",
            "Validation acc: 0.9296\n",
            "Time taken: 0.09s\n",
            "\n",
            "Start of epoch 1978\n",
            "Training loss (for one batch) at step 0: 0.2843\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2742\n",
            "Validation acc: 0.9297\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 1979\n",
            "Training loss (for one batch) at step 0: 0.2862\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2763\n",
            "Validation acc: 0.9295\n",
            "Time taken: 0.14s\n",
            "\n",
            "Start of epoch 1980\n",
            "Training loss (for one batch) at step 0: 0.2835\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2738\n",
            "Validation acc: 0.9297\n",
            "Time taken: 0.08s\n",
            "\n",
            "Start of epoch 1981\n",
            "Training loss (for one batch) at step 0: 0.2857\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2758\n",
            "Validation acc: 0.9297\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 1982\n",
            "Training loss (for one batch) at step 0: 0.2847\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2754\n",
            "Validation acc: 0.9296\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 1983\n",
            "Training loss (for one batch) at step 0: 0.2843\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2737\n",
            "Validation acc: 0.9297\n",
            "Time taken: 0.12s\n",
            "\n",
            "Start of epoch 1984\n",
            "Training loss (for one batch) at step 0: 0.2858\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2756\n",
            "Validation acc: 0.9297\n",
            "Time taken: 0.12s\n",
            "\n",
            "Start of epoch 1985\n",
            "Training loss (for one batch) at step 0: 0.2846\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2750\n",
            "Validation acc: 0.9296\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 1986\n",
            "Training loss (for one batch) at step 0: 0.2845\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2739\n",
            "Validation acc: 0.9297\n",
            "Time taken: 0.14s\n",
            "\n",
            "Start of epoch 1987\n",
            "Training loss (for one batch) at step 0: 0.2861\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2767\n",
            "Validation acc: 0.9297\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 1988\n",
            "Training loss (for one batch) at step 0: 0.2837\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2751\n",
            "Validation acc: 0.9296\n",
            "Time taken: 0.12s\n",
            "\n",
            "Start of epoch 1989\n",
            "Training loss (for one batch) at step 0: 0.2839\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2747\n",
            "Validation acc: 0.9296\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 1990\n",
            "Training loss (for one batch) at step 0: 0.2850\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2755\n",
            "Validation acc: 0.9295\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 1991\n",
            "Training loss (for one batch) at step 0: 0.2830\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2735\n",
            "Validation acc: 0.9297\n",
            "Time taken: 0.09s\n",
            "\n",
            "Start of epoch 1992\n",
            "Training loss (for one batch) at step 0: 0.2855\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2750\n",
            "Validation acc: 0.9297\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 1993\n",
            "Training loss (for one batch) at step 0: 0.2850\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2766\n",
            "Validation acc: 0.9296\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 1994\n",
            "Training loss (for one batch) at step 0: 0.2844\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2753\n",
            "Validation acc: 0.9296\n",
            "Time taken: 0.12s\n",
            "\n",
            "Start of epoch 1995\n",
            "Training loss (for one batch) at step 0: 0.2840\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2744\n",
            "Validation acc: 0.9296\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 1996\n",
            "Training loss (for one batch) at step 0: 0.2849\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2755\n",
            "Validation acc: 0.9295\n",
            "Time taken: 0.14s\n",
            "\n",
            "Start of epoch 1997\n",
            "Training loss (for one batch) at step 0: 0.2830\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2733\n",
            "Validation acc: 0.9297\n",
            "Time taken: 0.09s\n",
            "\n",
            "Start of epoch 1998\n",
            "Training loss (for one batch) at step 0: 0.2865\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2770\n",
            "Validation acc: 0.9293\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 1999\n",
            "Training loss (for one batch) at step 0: 0.2836\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2737\n",
            "Validation acc: 0.9298\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 2000\n",
            "Training loss (for one batch) at step 0: 0.2850\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2758\n",
            "Validation acc: 0.9295\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 2001\n",
            "Training loss (for one batch) at step 0: 0.2840\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2750\n",
            "Validation acc: 0.9296\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 2002\n",
            "Training loss (for one batch) at step 0: 0.2841\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2747\n",
            "Validation acc: 0.9296\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 2003\n",
            "Training loss (for one batch) at step 0: 0.2857\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2749\n",
            "Validation acc: 0.9296\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 2004\n",
            "Training loss (for one batch) at step 0: 0.2835\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2738\n",
            "Validation acc: 0.9296\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 2005\n",
            "Training loss (for one batch) at step 0: 0.2870\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2765\n",
            "Validation acc: 0.9297\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 2006\n",
            "Training loss (for one batch) at step 0: 0.2833\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2757\n",
            "Validation acc: 0.9295\n",
            "Time taken: 0.12s\n",
            "\n",
            "Start of epoch 2007\n",
            "Training loss (for one batch) at step 0: 0.2843\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2744\n",
            "Validation acc: 0.9296\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 2008\n",
            "Training loss (for one batch) at step 0: 0.2841\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2742\n",
            "Validation acc: 0.9296\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 2009\n",
            "Training loss (for one batch) at step 0: 0.2851\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2757\n",
            "Validation acc: 0.9297\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 2010\n",
            "Training loss (for one batch) at step 0: 0.2840\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2757\n",
            "Validation acc: 0.9296\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 2011\n",
            "Training loss (for one batch) at step 0: 0.2840\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2741\n",
            "Validation acc: 0.9296\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 2012\n",
            "Training loss (for one batch) at step 0: 0.2846\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2749\n",
            "Validation acc: 0.9296\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 2013\n",
            "Training loss (for one batch) at step 0: 0.2842\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2750\n",
            "Validation acc: 0.9295\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 2014\n",
            "Training loss (for one batch) at step 0: 0.2842\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2736\n",
            "Validation acc: 0.9297\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 2015\n",
            "Training loss (for one batch) at step 0: 0.2842\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2750\n",
            "Validation acc: 0.9296\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 2016\n",
            "Training loss (for one batch) at step 0: 0.2844\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2759\n",
            "Validation acc: 0.9296\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 2017\n",
            "Training loss (for one batch) at step 0: 0.2838\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2750\n",
            "Validation acc: 0.9295\n",
            "Time taken: 0.08s\n",
            "\n",
            "Start of epoch 2018\n",
            "Training loss (for one batch) at step 0: 0.2835\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2735\n",
            "Validation acc: 0.9296\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 2019\n",
            "Training loss (for one batch) at step 0: 0.2847\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2747\n",
            "Validation acc: 0.9296\n",
            "Time taken: 0.10s\n",
            "\n",
            "Start of epoch 2020\n",
            "Training loss (for one batch) at step 0: 0.2845\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2759\n",
            "Validation acc: 0.9296\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 2021\n",
            "Training loss (for one batch) at step 0: 0.2838\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2748\n",
            "Validation acc: 0.9295\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 2022\n",
            "Training loss (for one batch) at step 0: 0.2837\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2730\n",
            "Validation acc: 0.9297\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 2023\n",
            "Training loss (for one batch) at step 0: 0.2852\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2763\n",
            "Validation acc: 0.9296\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 2024\n",
            "Training loss (for one batch) at step 0: 0.2839\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2748\n",
            "Validation acc: 0.9295\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 2025\n",
            "Training loss (for one batch) at step 0: 0.2828\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2734\n",
            "Validation acc: 0.9296\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 2026\n",
            "Training loss (for one batch) at step 0: 0.2865\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2767\n",
            "Validation acc: 0.9291\n",
            "Time taken: 0.09s\n",
            "\n",
            "Start of epoch 2027\n",
            "Training loss (for one batch) at step 0: 0.2827\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2730\n",
            "Validation acc: 0.9296\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 2028\n",
            "Training loss (for one batch) at step 0: 0.2878\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2766\n",
            "Validation acc: 0.9291\n",
            "Time taken: 0.12s\n",
            "\n",
            "Start of epoch 2029\n",
            "Training loss (for one batch) at step 0: 0.2824\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2722\n",
            "Validation acc: 0.9292\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 2030\n",
            "Training loss (for one batch) at step 0: 0.2913\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2820\n",
            "Validation acc: 0.9280\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 2031\n",
            "Training loss (for one batch) at step 0: 0.2831\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2736\n",
            "Validation acc: 0.9294\n",
            "Time taken: 0.12s\n",
            "\n",
            "Start of epoch 2032\n",
            "Training loss (for one batch) at step 0: 0.2893\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2779\n",
            "Validation acc: 0.9285\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 2033\n",
            "Training loss (for one batch) at step 0: 0.2820\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2751\n",
            "Validation acc: 0.9295\n",
            "Time taken: 0.10s\n",
            "\n",
            "Start of epoch 2034\n",
            "Training loss (for one batch) at step 0: 0.2873\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2751\n",
            "Validation acc: 0.9291\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 2035\n",
            "Training loss (for one batch) at step 0: 0.2819\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2720\n",
            "Validation acc: 0.9292\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 2036\n",
            "Training loss (for one batch) at step 0: 0.2917\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2802\n",
            "Validation acc: 0.9282\n",
            "Time taken: 0.14s\n",
            "\n",
            "Start of epoch 2037\n",
            "Training loss (for one batch) at step 0: 0.2826\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2739\n",
            "Validation acc: 0.9294\n",
            "Time taken: 0.10s\n",
            "\n",
            "Start of epoch 2038\n",
            "Training loss (for one batch) at step 0: 0.2888\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2789\n",
            "Validation acc: 0.9277\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 2039\n",
            "Training loss (for one batch) at step 0: 0.2835\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2756\n",
            "Validation acc: 0.9290\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 2040\n",
            "Training loss (for one batch) at step 0: 0.2872\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2748\n",
            "Validation acc: 0.9289\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 2041\n",
            "Training loss (for one batch) at step 0: 0.2817\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2811\n",
            "Validation acc: 0.9286\n",
            "Time taken: 0.12s\n",
            "\n",
            "Start of epoch 2042\n",
            "Training loss (for one batch) at step 0: 0.2829\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2736\n",
            "Validation acc: 0.9292\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 2043\n",
            "Training loss (for one batch) at step 0: 0.2825\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2762\n",
            "Validation acc: 0.9289\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 2044\n",
            "Training loss (for one batch) at step 0: 0.2852\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2737\n",
            "Validation acc: 0.9293\n",
            "Time taken: 0.22s\n",
            "\n",
            "Start of epoch 2045\n",
            "Training loss (for one batch) at step 0: 0.2816\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2753\n",
            "Validation acc: 0.9294\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 2046\n",
            "Training loss (for one batch) at step 0: 0.2861\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2762\n",
            "Validation acc: 0.9291\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 2047\n",
            "Training loss (for one batch) at step 0: 0.2826\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2735\n",
            "Validation acc: 0.9296\n",
            "Time taken: 0.08s\n",
            "\n",
            "Start of epoch 2048\n",
            "Training loss (for one batch) at step 0: 0.2861\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2753\n",
            "Validation acc: 0.9291\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 2049\n",
            "Training loss (for one batch) at step 0: 0.2825\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2737\n",
            "Validation acc: 0.9295\n",
            "Time taken: 0.09s\n",
            "\n",
            "Start of epoch 2050\n",
            "Training loss (for one batch) at step 0: 0.2885\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2771\n",
            "Validation acc: 0.9284\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 2051\n",
            "Training loss (for one batch) at step 0: 0.2821\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2732\n",
            "Validation acc: 0.9295\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 2052\n",
            "Training loss (for one batch) at step 0: 0.2875\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2758\n",
            "Validation acc: 0.9291\n",
            "Time taken: 0.08s\n",
            "\n",
            "Start of epoch 2053\n",
            "Training loss (for one batch) at step 0: 0.2818\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2734\n",
            "Validation acc: 0.9293\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 2054\n",
            "Training loss (for one batch) at step 0: 0.2895\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2802\n",
            "Validation acc: 0.9274\n",
            "Time taken: 0.12s\n",
            "\n",
            "Start of epoch 2055\n",
            "Training loss (for one batch) at step 0: 0.2843\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2761\n",
            "Validation acc: 0.9290\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 2056\n",
            "Training loss (for one batch) at step 0: 0.2878\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2746\n",
            "Validation acc: 0.9289\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 2057\n",
            "Training loss (for one batch) at step 0: 0.2814\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2833\n",
            "Validation acc: 0.9284\n",
            "Time taken: 0.08s\n",
            "\n",
            "Start of epoch 2058\n",
            "Training loss (for one batch) at step 0: 0.2826\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2732\n",
            "Validation acc: 0.9288\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 2059\n",
            "Training loss (for one batch) at step 0: 0.2952\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2786\n",
            "Validation acc: 0.9281\n",
            "Time taken: 0.09s\n",
            "\n",
            "Start of epoch 2060\n",
            "Training loss (for one batch) at step 0: 0.2840\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2753\n",
            "Validation acc: 0.9292\n",
            "Time taken: 0.09s\n",
            "\n",
            "Start of epoch 2061\n",
            "Training loss (for one batch) at step 0: 0.2819\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2716\n",
            "Validation acc: 0.9293\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 2062\n",
            "Training loss (for one batch) at step 0: 0.2827\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2773\n",
            "Validation acc: 0.9291\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 2063\n",
            "Training loss (for one batch) at step 0: 0.2831\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2739\n",
            "Validation acc: 0.9293\n",
            "Time taken: 0.14s\n",
            "\n",
            "Start of epoch 2064\n",
            "Training loss (for one batch) at step 0: 0.2812\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2793\n",
            "Validation acc: 0.9289\n",
            "Time taken: 0.12s\n",
            "\n",
            "Start of epoch 2065\n",
            "Training loss (for one batch) at step 0: 0.2828\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2725\n",
            "Validation acc: 0.9293\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 2066\n",
            "Training loss (for one batch) at step 0: 0.2830\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2810\n",
            "Validation acc: 0.9285\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 2067\n",
            "Training loss (for one batch) at step 0: 0.2821\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2733\n",
            "Validation acc: 0.9293\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 2068\n",
            "Training loss (for one batch) at step 0: 0.2828\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2751\n",
            "Validation acc: 0.9288\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 2069\n",
            "Training loss (for one batch) at step 0: 0.2843\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2723\n",
            "Validation acc: 0.9295\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 2070\n",
            "Training loss (for one batch) at step 0: 0.2816\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2749\n",
            "Validation acc: 0.9294\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 2071\n",
            "Training loss (for one batch) at step 0: 0.2856\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2753\n",
            "Validation acc: 0.9291\n",
            "Time taken: 0.14s\n",
            "\n",
            "Start of epoch 2072\n",
            "Training loss (for one batch) at step 0: 0.2816\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2739\n",
            "Validation acc: 0.9295\n",
            "Time taken: 0.12s\n",
            "\n",
            "Start of epoch 2073\n",
            "Training loss (for one batch) at step 0: 0.2870\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2762\n",
            "Validation acc: 0.9290\n",
            "Time taken: 0.12s\n",
            "\n",
            "Start of epoch 2074\n",
            "Training loss (for one batch) at step 0: 0.2822\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2738\n",
            "Validation acc: 0.9294\n",
            "Time taken: 0.09s\n",
            "\n",
            "Start of epoch 2075\n",
            "Training loss (for one batch) at step 0: 0.2876\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2763\n",
            "Validation acc: 0.9284\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 2076\n",
            "Training loss (for one batch) at step 0: 0.2816\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2741\n",
            "Validation acc: 0.9293\n",
            "Time taken: 0.09s\n",
            "\n",
            "Start of epoch 2077\n",
            "Training loss (for one batch) at step 0: 0.2870\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2749\n",
            "Validation acc: 0.9287\n",
            "Time taken: 0.09s\n",
            "\n",
            "Start of epoch 2078\n",
            "Training loss (for one batch) at step 0: 0.2811\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2750\n",
            "Validation acc: 0.9293\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 2079\n",
            "Training loss (for one batch) at step 0: 0.2840\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2746\n",
            "Validation acc: 0.9288\n",
            "Time taken: 0.08s\n",
            "\n",
            "Start of epoch 2080\n",
            "Training loss (for one batch) at step 0: 0.2813\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2752\n",
            "Validation acc: 0.9292\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 2081\n",
            "Training loss (for one batch) at step 0: 0.2830\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2736\n",
            "Validation acc: 0.9288\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 2082\n",
            "Training loss (for one batch) at step 0: 0.2815\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2761\n",
            "Validation acc: 0.9293\n",
            "Time taken: 0.12s\n",
            "\n",
            "Start of epoch 2083\n",
            "Training loss (for one batch) at step 0: 0.2839\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2760\n",
            "Validation acc: 0.9287\n",
            "Time taken: 0.09s\n",
            "\n",
            "Start of epoch 2084\n",
            "Training loss (for one batch) at step 0: 0.2820\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2763\n",
            "Validation acc: 0.9292\n",
            "Time taken: 0.09s\n",
            "\n",
            "Start of epoch 2085\n",
            "Training loss (for one batch) at step 0: 0.2822\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2727\n",
            "Validation acc: 0.9291\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 2086\n",
            "Training loss (for one batch) at step 0: 0.2820\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2736\n",
            "Validation acc: 0.9293\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 2087\n",
            "Training loss (for one batch) at step 0: 0.2867\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2748\n",
            "Validation acc: 0.9291\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 2088\n",
            "Training loss (for one batch) at step 0: 0.2814\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2737\n",
            "Validation acc: 0.9294\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 2089\n",
            "Training loss (for one batch) at step 0: 0.2856\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2755\n",
            "Validation acc: 0.9290\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 2090\n",
            "Training loss (for one batch) at step 0: 0.2819\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2737\n",
            "Validation acc: 0.9293\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 2091\n",
            "Training loss (for one batch) at step 0: 0.2885\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2794\n",
            "Validation acc: 0.9275\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 2092\n",
            "Training loss (for one batch) at step 0: 0.2832\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2786\n",
            "Validation acc: 0.9287\n",
            "Time taken: 0.12s\n",
            "\n",
            "Start of epoch 2093\n",
            "Training loss (for one batch) at step 0: 0.2826\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2726\n",
            "Validation acc: 0.9291\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 2094\n",
            "Training loss (for one batch) at step 0: 0.2812\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2799\n",
            "Validation acc: 0.9279\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 2095\n",
            "Training loss (for one batch) at step 0: 0.2822\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2715\n",
            "Validation acc: 0.9295\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 2096\n",
            "Training loss (for one batch) at step 0: 0.2834\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2774\n",
            "Validation acc: 0.9285\n",
            "Time taken: 0.12s\n",
            "\n",
            "Start of epoch 2097\n",
            "Training loss (for one batch) at step 0: 0.2829\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2713\n",
            "Validation acc: 0.9295\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 2098\n",
            "Training loss (for one batch) at step 0: 0.2826\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2769\n",
            "Validation acc: 0.9293\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 2099\n",
            "Training loss (for one batch) at step 0: 0.2831\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2743\n",
            "Validation acc: 0.9286\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 2100\n",
            "Training loss (for one batch) at step 0: 0.2817\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2797\n",
            "Validation acc: 0.9284\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 2101\n",
            "Training loss (for one batch) at step 0: 0.2817\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2717\n",
            "Validation acc: 0.9291\n",
            "Time taken: 0.09s\n",
            "\n",
            "Start of epoch 2102\n",
            "Training loss (for one batch) at step 0: 0.2822\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2807\n",
            "Validation acc: 0.9283\n",
            "Time taken: 0.12s\n",
            "\n",
            "Start of epoch 2103\n",
            "Training loss (for one batch) at step 0: 0.2825\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2724\n",
            "Validation acc: 0.9294\n",
            "Time taken: 0.10s\n",
            "\n",
            "Start of epoch 2104\n",
            "Training loss (for one batch) at step 0: 0.2820\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2788\n",
            "Validation acc: 0.9281\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 2105\n",
            "Training loss (for one batch) at step 0: 0.2821\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2713\n",
            "Validation acc: 0.9295\n",
            "Time taken: 0.10s\n",
            "\n",
            "Start of epoch 2106\n",
            "Training loss (for one batch) at step 0: 0.2828\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2742\n",
            "Validation acc: 0.9294\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 2107\n",
            "Training loss (for one batch) at step 0: 0.2839\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2730\n",
            "Validation acc: 0.9292\n",
            "Time taken: 0.09s\n",
            "\n",
            "Start of epoch 2108\n",
            "Training loss (for one batch) at step 0: 0.2816\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2738\n",
            "Validation acc: 0.9292\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 2109\n",
            "Training loss (for one batch) at step 0: 0.2841\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2733\n",
            "Validation acc: 0.9291\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 2110\n",
            "Training loss (for one batch) at step 0: 0.2806\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2736\n",
            "Validation acc: 0.9295\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 2111\n",
            "Training loss (for one batch) at step 0: 0.2850\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2763\n",
            "Validation acc: 0.9283\n",
            "Time taken: 0.12s\n",
            "\n",
            "Start of epoch 2112\n",
            "Training loss (for one batch) at step 0: 0.2818\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2790\n",
            "Validation acc: 0.9288\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 2113\n",
            "Training loss (for one batch) at step 0: 0.2817\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2732\n",
            "Validation acc: 0.9285\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 2114\n",
            "Training loss (for one batch) at step 0: 0.2814\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2782\n",
            "Validation acc: 0.9287\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 2115\n",
            "Training loss (for one batch) at step 0: 0.2822\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2725\n",
            "Validation acc: 0.9290\n",
            "Time taken: 0.08s\n",
            "\n",
            "Start of epoch 2116\n",
            "Training loss (for one batch) at step 0: 0.2809\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2789\n",
            "Validation acc: 0.9286\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 2117\n",
            "Training loss (for one batch) at step 0: 0.2814\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2720\n",
            "Validation acc: 0.9292\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 2118\n",
            "Training loss (for one batch) at step 0: 0.2813\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2743\n",
            "Validation acc: 0.9292\n",
            "Time taken: 0.10s\n",
            "\n",
            "Start of epoch 2119\n",
            "Training loss (for one batch) at step 0: 0.2823\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2725\n",
            "Validation acc: 0.9290\n",
            "Time taken: 0.12s\n",
            "\n",
            "Start of epoch 2120\n",
            "Training loss (for one batch) at step 0: 0.2811\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2761\n",
            "Validation acc: 0.9289\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 2121\n",
            "Training loss (for one batch) at step 0: 0.2820\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2726\n",
            "Validation acc: 0.9291\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 2122\n",
            "Training loss (for one batch) at step 0: 0.2810\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2788\n",
            "Validation acc: 0.9285\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 2123\n",
            "Training loss (for one batch) at step 0: 0.2823\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2719\n",
            "Validation acc: 0.9293\n",
            "Time taken: 0.12s\n",
            "\n",
            "Start of epoch 2124\n",
            "Training loss (for one batch) at step 0: 0.2815\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2833\n",
            "Validation acc: 0.9282\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 2125\n",
            "Training loss (for one batch) at step 0: 0.2814\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2726\n",
            "Validation acc: 0.9294\n",
            "Time taken: 0.09s\n",
            "\n",
            "Start of epoch 2126\n",
            "Training loss (for one batch) at step 0: 0.2889\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2767\n",
            "Validation acc: 0.9279\n",
            "Time taken: 0.12s\n",
            "\n",
            "Start of epoch 2127\n",
            "Training loss (for one batch) at step 0: 0.2892\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2719\n",
            "Validation acc: 0.9293\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 2128\n",
            "Training loss (for one batch) at step 0: 0.2820\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2751\n",
            "Validation acc: 0.9294\n",
            "Time taken: 0.22s\n",
            "\n",
            "Start of epoch 2129\n",
            "Training loss (for one batch) at step 0: 0.2826\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2737\n",
            "Validation acc: 0.9290\n",
            "Time taken: 0.15s\n",
            "\n",
            "Start of epoch 2130\n",
            "Training loss (for one batch) at step 0: 0.2823\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2738\n",
            "Validation acc: 0.9294\n",
            "Time taken: 0.15s\n",
            "\n",
            "Start of epoch 2131\n",
            "Training loss (for one batch) at step 0: 0.2825\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2728\n",
            "Validation acc: 0.9293\n",
            "Time taken: 0.15s\n",
            "\n",
            "Start of epoch 2132\n",
            "Training loss (for one batch) at step 0: 0.2820\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2730\n",
            "Validation acc: 0.9293\n",
            "Time taken: 0.14s\n",
            "\n",
            "Start of epoch 2133\n",
            "Training loss (for one batch) at step 0: 0.2847\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2733\n",
            "Validation acc: 0.9294\n",
            "Time taken: 0.15s\n",
            "\n",
            "Start of epoch 2134\n",
            "Training loss (for one batch) at step 0: 0.2819\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2744\n",
            "Validation acc: 0.9293\n",
            "Time taken: 0.22s\n",
            "\n",
            "Start of epoch 2135\n",
            "Training loss (for one batch) at step 0: 0.2835\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2735\n",
            "Validation acc: 0.9293\n",
            "Time taken: 0.15s\n",
            "\n",
            "Start of epoch 2136\n",
            "Training loss (for one batch) at step 0: 0.2820\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2741\n",
            "Validation acc: 0.9294\n",
            "Time taken: 0.22s\n",
            "\n",
            "Start of epoch 2137\n",
            "Training loss (for one batch) at step 0: 0.2843\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2749\n",
            "Validation acc: 0.9290\n",
            "Time taken: 0.14s\n",
            "\n",
            "Start of epoch 2138\n",
            "Training loss (for one batch) at step 0: 0.2821\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2733\n",
            "Validation acc: 0.9292\n",
            "Time taken: 0.16s\n",
            "\n",
            "Start of epoch 2139\n",
            "Training loss (for one batch) at step 0: 0.2839\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2720\n",
            "Validation acc: 0.9294\n",
            "Time taken: 0.22s\n",
            "\n",
            "Start of epoch 2140\n",
            "Training loss (for one batch) at step 0: 0.2804\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2743\n",
            "Validation acc: 0.9293\n",
            "Time taken: 0.22s\n",
            "\n",
            "Start of epoch 2141\n",
            "Training loss (for one batch) at step 0: 0.2836\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2751\n",
            "Validation acc: 0.9287\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 2142\n",
            "Training loss (for one batch) at step 0: 0.2811\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2745\n",
            "Validation acc: 0.9295\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 2143\n",
            "Training loss (for one batch) at step 0: 0.2834\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2746\n",
            "Validation acc: 0.9289\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 2144\n",
            "Training loss (for one batch) at step 0: 0.2811\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2740\n",
            "Validation acc: 0.9293\n",
            "Time taken: 0.12s\n",
            "\n",
            "Start of epoch 2145\n",
            "Training loss (for one batch) at step 0: 0.2835\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2731\n",
            "Validation acc: 0.9290\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 2146\n",
            "Training loss (for one batch) at step 0: 0.2807\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2726\n",
            "Validation acc: 0.9292\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 2147\n",
            "Training loss (for one batch) at step 0: 0.2884\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2792\n",
            "Validation acc: 0.9274\n",
            "Time taken: 0.10s\n",
            "\n",
            "Start of epoch 2148\n",
            "Training loss (for one batch) at step 0: 0.2828\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2743\n",
            "Validation acc: 0.9288\n",
            "Time taken: 0.08s\n",
            "\n",
            "Start of epoch 2149\n",
            "Training loss (for one batch) at step 0: 0.2897\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2799\n",
            "Validation acc: 0.9275\n",
            "Time taken: 0.12s\n",
            "\n",
            "Start of epoch 2150\n",
            "Training loss (for one batch) at step 0: 0.2826\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2799\n",
            "Validation acc: 0.9281\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 2151\n",
            "Training loss (for one batch) at step 0: 0.2823\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2708\n",
            "Validation acc: 0.9294\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 2152\n",
            "Training loss (for one batch) at step 0: 0.2812\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2834\n",
            "Validation acc: 0.9275\n",
            "Time taken: 0.15s\n",
            "\n",
            "Start of epoch 2153\n",
            "Training loss (for one batch) at step 0: 0.2816\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2727\n",
            "Validation acc: 0.9286\n",
            "Time taken: 0.10s\n",
            "\n",
            "Start of epoch 2154\n",
            "Training loss (for one batch) at step 0: 0.2948\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2775\n",
            "Validation acc: 0.9277\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 2155\n",
            "Training loss (for one batch) at step 0: 0.2825\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2775\n",
            "Validation acc: 0.9287\n",
            "Time taken: 0.08s\n",
            "\n",
            "Start of epoch 2156\n",
            "Training loss (for one batch) at step 0: 0.2805\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2705\n",
            "Validation acc: 0.9293\n",
            "Time taken: 0.08s\n",
            "\n",
            "Start of epoch 2157\n",
            "Training loss (for one batch) at step 0: 0.2826\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2745\n",
            "Validation acc: 0.9286\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 2158\n",
            "Training loss (for one batch) at step 0: 0.2825\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2704\n",
            "Validation acc: 0.9294\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 2159\n",
            "Training loss (for one batch) at step 0: 0.2816\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2749\n",
            "Validation acc: 0.9291\n",
            "Time taken: 0.10s\n",
            "\n",
            "Start of epoch 2160\n",
            "Training loss (for one batch) at step 0: 0.2832\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2731\n",
            "Validation acc: 0.9293\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 2161\n",
            "Training loss (for one batch) at step 0: 0.2825\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2731\n",
            "Validation acc: 0.9293\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 2162\n",
            "Training loss (for one batch) at step 0: 0.2838\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2725\n",
            "Validation acc: 0.9294\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 2163\n",
            "Training loss (for one batch) at step 0: 0.2827\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2735\n",
            "Validation acc: 0.9293\n",
            "Time taken: 0.08s\n",
            "\n",
            "Start of epoch 2164\n",
            "Training loss (for one batch) at step 0: 0.2844\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2733\n",
            "Validation acc: 0.9294\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 2165\n",
            "Training loss (for one batch) at step 0: 0.2822\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2728\n",
            "Validation acc: 0.9295\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 2166\n",
            "Training loss (for one batch) at step 0: 0.2846\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2735\n",
            "Validation acc: 0.9295\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 2167\n",
            "Training loss (for one batch) at step 0: 0.2829\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2736\n",
            "Validation acc: 0.9294\n",
            "Time taken: 0.08s\n",
            "\n",
            "Start of epoch 2168\n",
            "Training loss (for one batch) at step 0: 0.2828\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2721\n",
            "Validation acc: 0.9296\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 2169\n",
            "Training loss (for one batch) at step 0: 0.2835\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2745\n",
            "Validation acc: 0.9293\n",
            "Time taken: 0.10s\n",
            "\n",
            "Start of epoch 2170\n",
            "Training loss (for one batch) at step 0: 0.2827\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2736\n",
            "Validation acc: 0.9293\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 2171\n",
            "Training loss (for one batch) at step 0: 0.2825\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2737\n",
            "Validation acc: 0.9294\n",
            "Time taken: 0.09s\n",
            "\n",
            "Start of epoch 2172\n",
            "Training loss (for one batch) at step 0: 0.2821\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2725\n",
            "Validation acc: 0.9293\n",
            "Time taken: 0.08s\n",
            "\n",
            "Start of epoch 2173\n",
            "Training loss (for one batch) at step 0: 0.2827\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2724\n",
            "Validation acc: 0.9294\n",
            "Time taken: 0.09s\n",
            "\n",
            "Start of epoch 2174\n",
            "Training loss (for one batch) at step 0: 0.2839\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2746\n",
            "Validation acc: 0.9293\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 2175\n",
            "Training loss (for one batch) at step 0: 0.2812\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2724\n",
            "Validation acc: 0.9293\n",
            "Time taken: 0.10s\n",
            "\n",
            "Start of epoch 2176\n",
            "Training loss (for one batch) at step 0: 0.2836\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2728\n",
            "Validation acc: 0.9293\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 2177\n",
            "Training loss (for one batch) at step 0: 0.2823\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2730\n",
            "Validation acc: 0.9295\n",
            "Time taken: 0.09s\n",
            "\n",
            "Start of epoch 2178\n",
            "Training loss (for one batch) at step 0: 0.2834\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2747\n",
            "Validation acc: 0.9290\n",
            "Time taken: 0.10s\n",
            "\n",
            "Start of epoch 2179\n",
            "Training loss (for one batch) at step 0: 0.2813\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2705\n",
            "Validation acc: 0.9295\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 2180\n",
            "Training loss (for one batch) at step 0: 0.2847\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2752\n",
            "Validation acc: 0.9292\n",
            "Time taken: 0.12s\n",
            "\n",
            "Start of epoch 2181\n",
            "Training loss (for one batch) at step 0: 0.2825\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2723\n",
            "Validation acc: 0.9296\n",
            "Time taken: 0.12s\n",
            "\n",
            "Start of epoch 2182\n",
            "Training loss (for one batch) at step 0: 0.2838\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2747\n",
            "Validation acc: 0.9288\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 2183\n",
            "Training loss (for one batch) at step 0: 0.2810\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2723\n",
            "Validation acc: 0.9292\n",
            "Time taken: 0.12s\n",
            "\n",
            "Start of epoch 2184\n",
            "Training loss (for one batch) at step 0: 0.2881\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2792\n",
            "Validation acc: 0.9279\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 2185\n",
            "Training loss (for one batch) at step 0: 0.2807\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2724\n",
            "Validation acc: 0.9292\n",
            "Time taken: 0.10s\n",
            "\n",
            "Start of epoch 2186\n",
            "Training loss (for one batch) at step 0: 0.2882\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2808\n",
            "Validation acc: 0.9261\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 2187\n",
            "Training loss (for one batch) at step 0: 0.2866\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2746\n",
            "Validation acc: 0.9292\n",
            "Time taken: 0.10s\n",
            "\n",
            "Start of epoch 2188\n",
            "Training loss (for one batch) at step 0: 0.2868\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2765\n",
            "Validation acc: 0.9282\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 2189\n",
            "Training loss (for one batch) at step 0: 0.2803\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2831\n",
            "Validation acc: 0.9274\n",
            "Time taken: 0.10s\n",
            "\n",
            "Start of epoch 2190\n",
            "Training loss (for one batch) at step 0: 0.2813\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2730\n",
            "Validation acc: 0.9282\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 2191\n",
            "Training loss (for one batch) at step 0: 0.2959\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2778\n",
            "Validation acc: 0.9272\n",
            "Time taken: 0.08s\n",
            "\n",
            "Start of epoch 2192\n",
            "Training loss (for one batch) at step 0: 0.2821\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2802\n",
            "Validation acc: 0.9277\n",
            "Time taken: 0.11s\n",
            "\n",
            "Start of epoch 2193\n",
            "Training loss (for one batch) at step 0: 0.2809\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2700\n",
            "Validation acc: 0.9295\n",
            "Time taken: 0.13s\n",
            "\n",
            "Start of epoch 2194\n",
            "Training loss (for one batch) at step 0: 0.2863\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2740\n",
            "Validation acc: 0.9284\n",
            "Time taken: 0.10s\n",
            "\n",
            "Start of epoch 2195\n",
            "Training loss (for one batch) at step 0: 0.2818\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2723\n",
            "Validation acc: 0.9296\n",
            "Time taken: 0.09s\n",
            "\n",
            "Start of epoch 2196\n",
            "Training loss (for one batch) at step 0: 0.2829\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2733\n",
            "Validation acc: 0.9290\n",
            "Time taken: 0.08s\n",
            "\n",
            "Start of epoch 2197\n",
            "Training loss (for one batch) at step 0: 0.2805\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2731\n",
            "Validation acc: 0.9292\n",
            "Time taken: 0.14s\n",
            "\n",
            "Start of epoch 2198\n",
            "Training loss (for one batch) at step 0: 0.2850\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2751\n",
            "Validation acc: 0.9278\n",
            "Time taken: 0.10s\n",
            "\n",
            "Start of epoch 2199\n",
            "Training loss (for one batch) at step 0: 0.2808\n",
            "Seen so far: 540 samples\n",
            "Training acc over epoch: 0.2768\n",
            "Validation acc: 0.9290\n",
            "Time taken: 0.08s\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'metric_a': <tf.Tensor: shape=(), dtype=float32, numpy=0.28797024>,\n",
              " 'metric_b': <tf.Tensor: shape=(), dtype=float32, numpy=0.92899394>}"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "hypermodelu = hypermodel3Ltwo()\n",
        "best_hp2l = tun1L.get_best_hyperparameters()[0]\n",
        "model2l = hypermodelu.build(best_hp2l)\n",
        "#xtrain,xval,ytrain,yval=train_test_split(training.drop('churn',axis=1).values,training.churn.values.reshape(-1,1),test_size=0.1)\n",
        "hypermodelu.fit(best_hp2l, model2l,xtrain,\n",
        "               ytrain,100,120,xval,yval)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G1XKxjocuXYb",
        "outputId": "8c854f77-342a-4035-ac3a-860da571fab5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Results summary\n",
            "Results in ./untitled_project\n",
            "Showing 10 best trials\n",
            "<keras_tuner.engine.objective.Objective object at 0x7f6f4c047910>\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "units_1: 30\n",
            "activation_1: relu\n",
            "units_2: 26\n",
            "activation_2: relu\n",
            "units_3: 20\n",
            "activation_3: relu\n",
            "units_4: 10\n",
            "activation_4: relu\n",
            "units_6: 30\n",
            "activation_6: relu\n",
            "units_7: 18\n",
            "activation_7: relu\n",
            "epochs: 2200\n",
            "batch_size: 540\n",
            "learning_rate: 0.029609999999999997\n",
            "Score: 0.2909510135650635\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "units_1: 46\n",
            "activation_1: relu\n",
            "units_2: 30\n",
            "activation_2: tanh\n",
            "units_3: 36\n",
            "activation_3: tanh\n",
            "units_4: 10\n",
            "activation_4: tanh\n",
            "units_6: 30\n",
            "activation_6: tanh\n",
            "units_7: 26\n",
            "activation_7: tanh\n",
            "epochs: 2000\n",
            "batch_size: 380\n",
            "learning_rate: 0.016309999999999998\n",
            "Score: 0.6924212574958801\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "units_1: 30\n",
            "activation_1: relu\n",
            "units_2: 34\n",
            "activation_2: relu\n",
            "units_3: 44\n",
            "activation_3: relu\n",
            "units_4: 2\n",
            "activation_4: relu\n",
            "units_6: 30\n",
            "activation_6: relu\n",
            "units_7: 22\n",
            "activation_7: tanh\n",
            "epochs: 2100\n",
            "batch_size: 340\n",
            "learning_rate: 0.017369999999999997\n",
            "Score: 0.6927826404571533\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "units_1: 42\n",
            "activation_1: relu\n",
            "units_2: 14\n",
            "activation_2: relu\n",
            "units_3: 28\n",
            "activation_3: tanh\n",
            "units_4: 6\n",
            "activation_4: relu\n",
            "units_6: 22\n",
            "activation_6: tanh\n",
            "units_7: 30\n",
            "activation_7: relu\n",
            "epochs: 2100\n",
            "batch_size: 340\n",
            "learning_rate: 0.013789999999999998\n",
            "Score: 0.6927968263626099\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "units_1: 34\n",
            "activation_1: relu\n",
            "units_2: 18\n",
            "activation_2: tanh\n",
            "units_3: 28\n",
            "activation_3: relu\n",
            "units_4: 2\n",
            "activation_4: tanh\n",
            "units_6: 22\n",
            "activation_6: tanh\n",
            "units_7: 34\n",
            "activation_7: relu\n",
            "epochs: 2100\n",
            "batch_size: 340\n",
            "learning_rate: 0.00985\n",
            "Score: 0.6927976608276367\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "units_1: 18\n",
            "activation_1: tanh\n",
            "units_2: 30\n",
            "activation_2: relu\n",
            "units_3: 40\n",
            "activation_3: relu\n",
            "units_4: 2\n",
            "activation_4: relu\n",
            "units_6: 26\n",
            "activation_6: relu\n",
            "units_7: 30\n",
            "activation_7: relu\n",
            "epochs: 2200\n",
            "batch_size: 460\n",
            "learning_rate: 0.009789999999999998\n",
            "Score: 0.692807674407959\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "units_1: 42\n",
            "activation_1: tanh\n",
            "units_2: 26\n",
            "activation_2: relu\n",
            "units_3: 32\n",
            "activation_3: relu\n",
            "units_4: 10\n",
            "activation_4: tanh\n",
            "units_6: 22\n",
            "activation_6: relu\n",
            "units_7: 34\n",
            "activation_7: relu\n",
            "epochs: 2100\n",
            "batch_size: 340\n",
            "learning_rate: 0.007149999999999999\n",
            "Score: 0.6928085684776306\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "units_1: 38\n",
            "activation_1: relu\n",
            "units_2: 30\n",
            "activation_2: tanh\n",
            "units_3: 24\n",
            "activation_3: tanh\n",
            "units_4: 10\n",
            "activation_4: relu\n",
            "units_6: 14\n",
            "activation_6: tanh\n",
            "units_7: 34\n",
            "activation_7: tanh\n",
            "epochs: 2200\n",
            "batch_size: 420\n",
            "learning_rate: 0.015609999999999999\n",
            "Score: 0.6928164958953857\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "units_1: 22\n",
            "activation_1: relu\n",
            "units_2: 22\n",
            "activation_2: relu\n",
            "units_3: 40\n",
            "activation_3: relu\n",
            "units_4: 6\n",
            "activation_4: tanh\n",
            "units_6: 30\n",
            "activation_6: tanh\n",
            "units_7: 30\n",
            "activation_7: relu\n",
            "epochs: 2200\n",
            "batch_size: 460\n",
            "learning_rate: 0.014869999999999998\n",
            "Score: 0.6928285956382751\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "units_1: 34\n",
            "activation_1: tanh\n",
            "units_2: 42\n",
            "activation_2: tanh\n",
            "units_3: 36\n",
            "activation_3: relu\n",
            "units_4: 2\n",
            "activation_4: tanh\n",
            "units_6: 22\n",
            "activation_6: relu\n",
            "units_7: 30\n",
            "activation_7: relu\n",
            "epochs: 2100\n",
            "batch_size: 460\n",
            "learning_rate: 0.02175\n",
            "Score: 0.6928292512893677\n"
          ]
        }
      ],
      "source": [
        "\n",
        "tun1L.results_summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XUpL8KStbQMn"
      },
      "outputs": [],
      "source": [
        "## epoch 2000 batch_size=380"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 314
        },
        "id": "ddfRmFwaw23Z",
        "outputId": "a81aa0a6-18d3-43f3-ad27-8be9ce807460"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "150/150 [==============================] - 1s 5ms/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEGCAYAAABo25JHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAZmklEQVR4nO3de3TU533n8fd3ZnRHF0DiJgkLOxCDsYltBXubHset7RTTLJw0TmpSn1yOT+gm67S7yXbXbfa4WWfTJk2ans3GG4ck3lxOE8dxz2m0a3zIJiGx6xgbuYnBgC8CgxFXgUAgodvMfPePGSuDkECAfjMaPZ/XOTqe3/N7NPN9DMzn9/yu5u6IiEi4YoUuQERECktBICISOAWBiEjgFAQiIoFTEIiIBC5R6AIuVn19vbe0tBS6DBGRovLCCy8cc/eGsdYVXRC0tLTQ3t5e6DJERIqKme0bb512DYmIBE5BICISOAWBiEjgFAQiIoFTEIiIBC6yIDCzR8zsqJm9NM56M7OvmFmHmW0zsxuiqkVERMYX5Yzg28Cq86y/E1ic/VkPfC3CWkREZByRXUfg7k+ZWct5uqwFvuuZ+2BvMbM6M5vv7oeiqklEJEqptNM/nKLr9CB9g0nS7qTSv/3p6OplcDiNA+6OOzhO2sEd0tnHArif3fZm/9uXzmVFc92k113IC8oagf05y53ZtnOCwMzWk5k1sHDhwrwUJyLFrX8oxb7uPoaSaZJpJ512kmknmXL2dfdREosxkEyx69BpaioSpFKZ9WeGkuzu6mNmZQnJnC/xvsEke7r6qKsqyXyBe+aLP+WOuzM4nOb0YDKy8ZjBvNryaRcEE+buG4ANAK2trXqSjkgRcncGhtOkslvJ6bRntpjdSaehu2+IwWSKZNoZTqU5emqQ4VQ6u1UNqXTmC/3VI70c6uknZsZwKk0y5ew6fIqq0gRpd4ZTzrHewYuur7I0TiJmmBlDyTQ1FQnm1ZQTixmJmFFeEufKOTOoLkswp7qMWMyIGcRjRswyP8l0mpqKEhpmlFFXWUpdRQnxuBE3G+nXNLOCmvISLAYGxMwwy/wXGHmdu86y66JSyCA4ADTnLDdl20SkQM4MJekbTHGop5+Oo72kcza73J2te7upLi8hlXaS6TSpNLx25DSVZQmSqTS9g0lePXKauopSnN9+gafSzqmByd9afltzHSVxY9n8Grr7hri2sZaSRIySmHFmKMVVc2awqL6K0kSMROy3X8hmxoK6ckoTMSpLE8woK4pt4sgUcvRtwH1m9ihwE9Cj4wMik6unf5i+wST7u8+w/UAPrx3p5bWjp6kqS4xsTb98+DTlJTGO9Q5N+H1ryhMk4rHsVi6c6BtmRXMtM8oSLF9Qy4zyBHOry8/ZGu4bTHLVnCpiOW2x7Bd0Mp2mfkYZNeUlxGNGSTyzFT6zqjTzJf7mF3ncqC5LRL6VHJLIgsDMfgDcCtSbWSfw10AJgLs/DGwEVgMdwBngI1HVIlLs0mlnKJXmyKkB+odTDCXT7Dt+Bgd2HOhh3/EzxGPGUCpN+95uzIzuvrG/2KvLEjiwbEENZSUxbrxiJif7h3n3dQvoHUyyoqkWM6N5ViXza8upKImP/G5JPMa82vL8DFryJsqzhtZdYL0D/z6qzxeZigaTKY73DrH3WB8dXb0Mp5wX95/MHKwc2Y2SOVNkW+dJZlaW0r7vxITee2ZlCfNqK2ieVUnfYJL3XN/IYDLFNQtqcYe3zpvBgroK5tdWRDxKKTZh7xgTmURDyTTH+wbp7hvieO8Qu7t6aXvxIIlY5uDjrsOnGUqmx/39+hllv90FEsvs9jhwsp/fv3oOaXdWLprFwHCaq+dVUxqPYQZNMyupLI0ztyazv1vkUigIRCboyKkBXjvSy1AqxVDS2XGwh1/tPk5f9gBpepzz2apK47x90SzeuaSBoWSaFU21NM2sZMm8appmVlBbUUJJXF/iUjgKAglSOu2cGU6x91gfu7t6R841T6adPV29lMZjPPd6N7/Zf5LSRIzhVBo/z4nLv3PVbGZWlrKgrpxrFtSSiBsts6torKtgZlVp/gYmcgkUBDKtvXlKY+eJzOmQL3aeZOP2Qxw5deHzzGvKM/88rm2s5aZFsyhNxJg9o4zrGmspiccoTRhXzK7S1rwUPQWBFL2hZJqDJ/s5enqQlw+f4hevdJFMZw7C9vQPj/k7ZnDXDU1c11TLgroKlsytJhE3ErHM+eY1FSUj++lFpjsFgUxJA8Mpdh46xRvHzzCYTJF2MhczlSUYSqXZ1tnDoZ4BgHFPk1y5aBY4XH9FHfNrynnLnGqumF1J08wKnYMukkNBIFPCa0dO89zr3Wzv7OEnOw9z4szYW/IADdVllGQv+2+eVcmaFQuorShhbk05zbMqWNFcR015SR6rFyluCgLJu2Qqzf/ddojXj/Wx73gfz+w+Ttfps/fZV5XGuefmK7ht6VxqKhJUl5dQlohRP6OsQFWLTF8KApk07s7zr3dz+NQAQ8n0yC13Xzt6mmOnh+gfTtF54sxZp1nGDNIOS+fXcPfbm7nrxiYqS+PadSOSRwoCuWiptPNMxzFeOtjD6119vHq0F4AX958cs39J3JhTXU5J3Fj7tszVrkvmVrP2bY0sqq/KZ+kiMgYFgZwjnXaOnB7g4MkBXj1yGgOe2H6IjqO9HD41MOb59HNryrh96VwGkyk+8fuLmV+budK1fkaZzr4RmeIUBIE6eWaIAyf7OXRygKFUms0vH+XHvzlIbWXJOfvrc920aBZL59fg7qy7aSEts6soz7kpmYgUHwXBNLe7q5fv/GovR08Nsv1AD/UzSnmxs2fc/vNqylm9fB6JeIzFc2bQUl/FwlmZ+9nUVeoKWZHpSEEwjaTSTnffED96YT+PPr+fN7rPnLW+ZXYlPf3DvHNJAwdP9nP3yoXUzyjlrfOqKU/EWTirkph244gER0FQ5NJpZ8+xXj73xC42v9J11rrq8gS3L53LHcvm8o631FNboXPrReRcCoIi9sOtb/Bf/mn7WW3XLKhh/S1X8gfXzNO+exGZEAVBEekbTPLkS4f5+ctHeGHfiZEbp109r5pP3rGEO5bN1fn3InLRFART3DMdx/jxbw7Qvu8Ee7r6zlrXWFfBw/fcyLVNtQWqTkSmAwXBFLR1bzdf/+Vufrrr6FntjXUVvPeGRv545UIa6/S4QRGZHAqCAhsYTrGnq4+/fXIXT7927Jz1dyyby1+tXkrL7Ert9hGRSCgI8mgomabzxBk6T/Tz/3Ye4fEXOukfTp3V55YlDdywsI7brp7L8sYaffmLSOQUBBFLp51NOw7zd5te4fVjfeesv6qhive1NrOiqY6br5ylL34RyTsFQUSSqTSrv/I0rx7pPav9P9y+mGXza5g9o5Trmur0mEMRKTgFQQS++vPX+NJPXh1ZvuvGJv7Tu97KvNryAlYlIjI2BcEk+cZTe/jJzsNs3XtipO2Prm/kS+9bods2iMiUpiC4TA//cjeff/LlkeXGugqWzq/hb/5oOXOqNQMQkalPQXAJtnf2sOHpPfyfFw+OtC2bX8MP1t+s+/mISNFREFyEQz393PW1Zzlwsn+krbwkxuP/7ndY3qire0WkOCkIJuDZ3cdZ940tZ7V9+yNv59a3zilQRSIik0dBcB4/3XmE//xP2+juGxpp++oHrucPr52v8/1FZNpQEIzhhX3dfPwf/3Xk7p6zq0r5X39yAzddObvAlYmITL5Ig8DMVgH/A4gD33T3z49avxD4DlCX7XO/u2+MsqYL+ebTe/jvT+waWf7Wh1q5bencAlYkIhKtyILAzOLAQ8AdQCew1cza3H1nTrf/Cjzm7l8zs2XARqAlqpou5KlXu0ZC4JsfbOX2ZQoAEZn+ory/wUqgw933uPsQ8CiwdlQfB2qyr2uBgxTI9s4ePvjI8wD86S1XKgREJBhRBkEjsD9nuTPbluszwD1m1klmNvCJsd7IzNabWbuZtXd1dY3V5bIMp9L826/+CwDvvm4+f7l66aR/hojIVFXoO56tA77t7k3AauB7ZnZOTe6+wd1b3b21oaFhUgs4cmqAxZ9+EoB4zPjqB26Y1PcXEZnqogyCA0BzznJTti3XvcBjAO7+LFAO1EdY01m6Tg9y09/8bGS543N35uujRUSmjCiDYCuw2MwWmVkpcDfQNqrPG8BtAGa2lEwQTP6+nzGk0s7bP/dTAKrLEuz9/B/q2gARCVJkQeDuSeA+YBOwi8zZQTvM7EEzW5Pt9ingo2b2IvAD4MPu7lHVlOuqv8qcpRqPGdv/2x/k4yNFRKakSK8jyF4TsHFU2wM5r3cC74iyhrHkPils14Or8v3xIiJTSqEPFufdG8fP8Htf+gUAn3vPckoTwf0vEBE5S1Dfgsd7B7nli5tHltesWFDAakREpoag7jX04f+9Fcg8OezLf/y2AlcjIjI1BDUjONQzAMDfv39FgSsREZk6ggmC3sEkx3oHaagu02miIiI5ggmCHQd6APjdt+TtejURkaIQTBAcPpXZLfTu6+YXuBIRkaklmCAYTmWuU2uaWVngSkREppZgguCN45mLyCpK4gWuRERkagkmCKrKMmfK1leXFrgSEZGpJZggEBGRsSkIREQCpyAQEQmcgkBEJHAKAhGRwCkIREQCpyAQEQmcgkBEJHAKAhGRwCkIREQCpyAQEQmcgkBEJHAKAhGRwCkIREQCpyAQEQmcgkBEJHAKAhGRwCkIREQCpyAQEQmcgkBEJHCRBoGZrTKzV8ysw8zuH6fP+81sp5ntMLPvR1mPiIicKxHVG5tZHHgIuAPoBLaaWZu778zpsxj4S+Ad7n7CzOZEVY+IiIwtyhnBSqDD3fe4+xDwKLB2VJ+PAg+5+wkAdz8aYT0iIjKGKIOgEdifs9yZbcu1BFhiZs+Y2RYzWzXWG5nZejNrN7P2rq6uiMoVEQlToQ8WJ4DFwK3AOuAbZlY3upO7b3D3VndvbWhoyHOJIiLTW5RBcABozlluyrbl6gTa3H3Y3V8HXiUTDCIikidRBsFWYLGZLTKzUuBuoG1Un38mMxvAzOrJ7CraE2FNIiIySmRB4O5J4D5gE7ALeMzdd5jZg2a2JtttE3DczHYCm4G/cPfjUdUkIiLniuz0UQB33whsHNX2QM5rBz6Z/RERkQIo9MFiEREpMAWBiEjgFAQiIoFTEIiIBE5BICISOAWBiEjgFAQiIoFTEIiIBE5BICISOAWBiEjgLniLCTMrBz4O/C7gwL8AX3P3gYhrExGRPJjIvYa+C5wG/md2+QPA94D3RVWUiIjkz0SCYLm7L8tZ3py9W6iIiEwDEzlG8K9mdvObC2Z2E9AeXUkiIpJPE5kR3Aj8yszeyC4vBF4xs+1k7iR9XWTViYhI5CYSBGM+UF5ERKaH8waBmcWBTe5+dZ7qERGRPDvvMQJ3T5HZDbQwT/WIiEieTWTX0Exgh5k9D/S92ejua8b/FRERKRYTCYJy4N05ywZ8IZpyREQk3yYSBAl3/2Vug5lVRFSPiIjk2bhBYGYfI3NriSvNbFvOqmrgmagLExGR/DjfjOD7wJPA3wL357SfdvfuSKsSEZG8GTcI3L0H6AHW5a8cERHJN92GWkQkcAoCEZHAKQhERAKnIBARCZyCQEQkcAoCEZHAKQhERAIXaRCY2Soze8XMOszs/vP0e6+ZuZm1RlmPiIicK7IgyD7L4CHgTmAZsM7Mlo3Rrxr4c+C5qGoREZHxRTkjWAl0uPsedx8CHgXWjtHvs2TuZjoQYS0iIjKOKIOgEdifs9yZbRthZjcAze7+xPneyMzWm1m7mbV3dXVNfqUiIgEr2MFiM4sBXwY+daG+7r7B3VvdvbWhoSH64kREAhJlEBwAmnOWm7Jtb6oGlgO/MLO9wM1Amw4Yi4jkV5RBsBVYbGaLzKwUuBtoe3Olu/e4e727t7h7C7AFWOPu7RHWJCIio0QWBO6eBO4DNgG7gMfcfYeZPWhmet6xiMgUMZFHVV4yd98IbBzV9sA4fW+NshYRERmbriwWEQmcgkBEJHAKAhGRwCkIREQCpyAQEQmcgkBEJHAKAhGRwCkIREQCpyAQEQmcgkBEJHAKAhGRwCkIREQCpyAQEQmcgkBEJHAKAhGRwCkIREQCpyAQEQmcgkBEJHAKAhGRwCkIREQCpyAQEQmcgkBEJHAKAhGRwCkIREQCpyAQEQmcgkBEJHAKAhGRwCkIREQCpyAQEQmcgkBEJHCRBoGZrTKzV8ysw8zuH2P9J81sp5ltM7OfmdkVUdYjIiLniiwIzCwOPATcCSwD1pnZslHdfg20uvt1wOPA30VVj4iIjC3KGcFKoMPd97j7EPAosDa3g7tvdvcz2cUtQFOE9YiIyBiiDIJGYH/Ocme2bTz3Ak+OtcLM1ptZu5m1d3V1TWKJIiIyJQ4Wm9k9QCvwxbHWu/sGd29199aGhob8FiciMs0lInzvA0BzznJTtu0sZnY78Gngne4+GGE9IiIyhihnBFuBxWa2yMxKgbuBttwOZnY98HVgjbsfjbAWEREZR2RB4O5J4D5gE7ALeMzdd5jZg2a2Jtvti8AM4Edm9hszaxvn7UREJCJR7hrC3TcCG0e1PZDz+vYoP19ERC5sShwsFhGRwlEQiIgETkEgIhI4BYGISOAUBCIigVMQiIgETkEgIhI4BYGISOAUBCIigVMQiIgETkEgIhI4BYGISOAUBCIigVMQiIgETkEgIhI4BYGISOAUBCIigVMQiIgETkEgIhI4BYGISOAUBCIigVMQiIgETkEgIhI4BYGISOAUBCIigVMQiIgETkEgIhI4BYGISOAUBCIigVMQiIgETkEgIhK4SIPAzFaZ2Stm1mFm94+xvszMfphd/5yZtURZj4iInCuyIDCzOPAQcCewDFhnZstGdbsXOOHubwH+AfhCVPWIiMjYopwRrAQ63H2Puw8BjwJrR/VZC3wn+/px4DYzswhrEhGRUaIMgkZgf85yZ7ZtzD7ungR6gNmj38jM1ptZu5m1d3V1XVIxi+qrWH3tPGLKGRGRsyQKXcBEuPsGYANAa2urX8p7vOuaebzrmnmTWpeIyHQQ5YzgANCcs9yUbRuzj5klgFrgeIQ1iYjIKFEGwVZgsZktMrNS4G6gbVSfNuBD2dd3AT9390va4hcRkUsT2a4hd0+a2X3AJiAOPOLuO8zsQaDd3duAbwHfM7MOoJtMWIiISB5FeozA3TcCG0e1PZDzegB4X5Q1iIjI+enKYhGRwCkIREQCpyAQEQmcgkBEJHBWbGdrmlkXsO8Sf70eODaJ5RQDjTkMGnMYLmfMV7h7w1grii4ILoeZtbt7a6HryCeNOQwacxiiGrN2DYmIBE5BICISuNCCYEOhCygAjTkMGnMYIhlzUMcIRETkXKHNCEREZBQFgYhI4KZlEJjZKjN7xcw6zOz+MdaXmdkPs+ufM7OW/Fc5uSYw5k+a2U4z22ZmPzOzKwpR52S60Jhz+r3XzNzMiv5Uw4mM2czen/2z3mFm3893jZNtAn+3F5rZZjP7dfbv9+pC1DlZzOwRMztqZi+Ns97M7CvZ/x/bzOyGy/5Qd59WP2Rueb0buBIoBV4Elo3q83Hg4ezru4EfFrruPIz594DK7OuPhTDmbL9q4ClgC9Ba6Lrz8Oe8GPg1MDO7PKfQdedhzBuAj2VfLwP2FrruyxzzLcANwEvjrF8NPAkYcDPw3OV+5nScEawEOtx9j7sPAY8Ca0f1WQt8J/v6ceA2s6J+mPEFx+zum939THZxC5knxhWzifw5A3wW+AIwkM/iIjKRMX8UeMjdTwC4+9E81zjZJjJmB2qyr2uBg3msb9K5+1Nkns8ynrXAdz1jC1BnZvMv5zOnYxA0AvtzljuzbWP2cfck0APMzkt10ZjImHPdS2aLophdcMzZKXOzuz+Rz8IiNJE/5yXAEjN7xsy2mNmqvFUXjYmM+TPAPWbWSeb5J5/IT2kFc7H/3i+oKB5eL5PHzO4BWoF3FrqWKJlZDPgy8OECl5JvCTK7h24lM+t7ysyudfeTBa0qWuuAb7v735vZvyHz1MPl7p4udGHFYjrOCA4AzTnLTdm2MfuYWYLMdPJ4XqqLxkTGjJndDnwaWOPug3mqLSoXGnM1sBz4hZntJbMvta3IDxhP5M+5E2hz92F3fx14lUwwFKuJjPle4DEAd38WKCdzc7bpakL/3i/GdAyCrcBiM1tkZqVkDga3jerTBnwo+/ou4OeePQpTpC44ZjO7Hvg6mRAo9v3GcIExu3uPu9e7e4u7t5A5LrLG3dsLU+6kmMjf7X8mMxvAzOrJ7Crak88iJ9lExvwGcBuAmS0lEwRdea0yv9qAD2bPHroZ6HH3Q5fzhtNu15C7J83sPmATmTMOHnH3HWb2INDu7m3At8hMHzvIHJS5u3AVX74JjvmLwAzgR9nj4m+4+5qCFX2ZJjjmaWWCY94EvMvMdgIp4C/cvWhnuxMc86eAb5jZfyRz4PjDxbxhZ2Y/IBPm9dnjHn8NlAC4+8NkjoOsBjqAM8BHLvszi/j/l4iITILpuGtIREQugoJARCRwCgIRkcApCEREAqcgEBEJnIJA5BKY2Z+Z2S4z+8dC1yJyuXT6qMglMLOXgdvdvXMCfRPZe1qJTEmaEYhcJDN7mMxtkZ80sx4z+56ZPWtmr5nZR7N9bjWzp82sDdhZ0IJFLkAzApFLkL1/UStwH/AeMvcyqiLzLICbyNza4QlgefaePyJTlmYEIpfvx+7e7+7HgM1k7qEP8LxCQIqBgkDk8o2eVr+53JfvQkQuhYJA5PKtNbNyM5tN5mZhWwtcj8hFURCIXL5tZHYJbQE+6+5F/ahECY8OFotcBjP7DNDr7l8qdC0il0ozAhGRwGlGICISOM0IREQCpyAQEQmcgkBEJHAKAhGRwCkIREQC9/8ByxUKng48E9oAAAAASUVORK5CYII=\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.942350031376756"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "#xtrain,xval,ytrain,yval=train_test_split(training.drop('churn',axis=1).values,training.churn.values.reshape(-1,1),test_size=0.1)\n",
        "fpr, tpr, threshold = roc_curve(ytrain,hypermodelu.predict(best_hp2l,model2l,xtrain).reshape(-1,1))\n",
        "plt.plot(fpr,tpr)\n",
        "plt.xlabel('fpr')\n",
        "plt.ylabel('trp')\n",
        "plt.show()\n",
        "auc(fpr,tpr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 314
        },
        "id": "ICCYyDpsyLVq",
        "outputId": "21d511ed-1d0e-4cd0-fab6-debca38b60a9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "125/125 [==============================] - 1s 4ms/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9363349340356747"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "fpr, tpr, threshold = roc_curve(testing.churn.values.reshape(-1,1),hypermodelu.predict(best_hp2l,model2l,testing.drop(\"churn\",axis=1).values))\n",
        "plt.plot(fpr,tpr)\n",
        "plt.xlabel('fpr')\n",
        "plt.ylabel('trp')\n",
        "plt.show()\n",
        "auc(fpr,tpr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 314
        },
        "id": "rjlMLZAfqRRV",
        "outputId": "3d17a710-82c9-47e4-823b-97e0cd4837c8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "187/187 [==============================] - 1s 4ms/step\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "0.8751868510682588"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#xtrain,xval,ytrain,yval=train_test_split(training.drop('churn',axis=1).values,training.churn.values.reshape(-1,1),test_size=0.1)\n",
        "fpr, tpr, threshold = roc_curve(ytrain,hypermodelu.predict(best_hp2l,model2l,xtrain).reshape(-1,1))\n",
        "plt.plot(fpr,tpr)\n",
        "plt.xlabel('fpr')\n",
        "plt.ylabel('trp')\n",
        "plt.show()\n",
        "auc(fpr,tpr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 314
        },
        "id": "1ePPTbQxqYov",
        "outputId": "d3756675-3965-4958-b8f0-0bc6cee56e47"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "125/125 [==============================] - 0s 2ms/step\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "0.8797772891998632"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "fpr, tpr, threshold = roc_curve(testing.churn.values.reshape(-1,1),hypermodelu.predict(best_hp2l,model2l,testing.drop(\"churn\",axis=1).values))\n",
        "plt.plot(fpr,tpr)\n",
        "plt.xlabel('fpr')\n",
        "plt.ylabel('trp')\n",
        "plt.show()\n",
        "auc(fpr,tpr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        },
        "id": "PKSU7Yl61XEw",
        "outputId": "47ae77e5-69d6-4b47-f06f-bd0269207dfb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "299/299 [==============================] - 1s 2ms/step\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "0.8799634172137567"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "fpr, tpr, threshold = roc_curve(ytrain,hypermodelu.predict(best_hp2l,model2l,xtrain))\n",
        "plt.plot(tpr,fpr)\n",
        "plt.xlabel('fpr')\n",
        "plt.ylabel('trp')\n",
        "plt.show()\n",
        "auc(fpr,tpr)\n",
        "#0.8711"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 314
        },
        "id": "hJHjEZfO1ckd",
        "outputId": "a3e38f89-d71b-499c-9cc2-917fb69c9223"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "125/125 [==============================] - 0s 2ms/step\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "0.8712568603781391"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "fpr, tpr, threshold = roc_curve(testing.churn.values.reshape(-1,1),hypermodelu.predict(best_hp2,model2,testing.drop(\"churn\",axis=1).values))\n",
        "plt.plot(tpr,fpr)\n",
        "plt.xlabel('fpr')\n",
        "plt.ylabel('trp')\n",
        "plt.show()\n",
        "auc(fpr,tpr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 314
        },
        "id": "16nPjVn_oI0B",
        "outputId": "e97d5c54-1f53-4fdb-ca4d-273d00b5a0bf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "370/370 [==============================] - 1s 2ms/step\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "0.53819874759002"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "fpr, tpr, threshold = roc_curve(ytrain,hypermodelu.predict(best_hp2,model2,xtrain))\n",
        "plt.plot(tpr,fpr)\n",
        "plt.xlabel('fpr')\n",
        "plt.ylabel('trp')\n",
        "plt.show()\n",
        "auc(fpr,tpr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 314
        },
        "id": "zt7vA5gYoNSs",
        "outputId": "0c384110-45e4-4f5b-f0c6-cc2419c48349"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "125/125 [==============================] - 0s 2ms/step\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "0.5590391749508373"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "fpr, tpr, threshold = roc_curve(testing.churn.values.reshape(-1,1),hypermodelu.predict(best_hp2,model2,testing.drop(\"churn\",axis=1).values))\n",
        "plt.plot(tpr,fpr)\n",
        "plt.xlabel('fpr')\n",
        "plt.ylabel('trp')\n",
        "plt.show()\n",
        "auc(fpr,tpr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gRO5Xvfq3Dra",
        "outputId": "89936947-e436-42f1-9c65-3c50e1e5c0d6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Results summary\n",
            "Results in ./untitled_project\n",
            "Showing 10 best trials\n",
            "<keras_tuner.engine.objective.Objective object at 0x7fa6cb84a390>\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "units_1: 40\n",
            "activation_1: relu\n",
            "units_2: 40\n",
            "activation_2: tanh\n",
            "units_4: 22\n",
            "activation_4: tanh\n",
            "units_6: 28\n",
            "activation_6: tanh\n",
            "units_7: 36\n",
            "activation_7: tanh\n",
            "Score: 0.11228405684232712\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "units_1: 32\n",
            "activation_1: relu\n",
            "units_2: 36\n",
            "activation_2: relu\n",
            "units_4: 14\n",
            "activation_4: relu\n",
            "units_6: 48\n",
            "activation_6: tanh\n",
            "units_7: 32\n",
            "activation_7: tanh\n",
            "Score: 0.1124117374420166\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "units_1: 56\n",
            "activation_1: relu\n",
            "units_2: 32\n",
            "activation_2: tanh\n",
            "units_4: 10\n",
            "activation_4: tanh\n",
            "units_6: 32\n",
            "activation_6: relu\n",
            "units_7: 48\n",
            "activation_7: tanh\n",
            "Score: 0.11246307939291\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "units_1: 36\n",
            "activation_1: relu\n",
            "units_2: 40\n",
            "activation_2: tanh\n",
            "units_4: 18\n",
            "activation_4: relu\n",
            "units_6: 28\n",
            "activation_6: relu\n",
            "units_7: 28\n",
            "activation_7: relu\n",
            "Score: 0.11313115060329437\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "units_1: 32\n",
            "activation_1: relu\n",
            "units_2: 28\n",
            "activation_2: relu\n",
            "units_4: 14\n",
            "activation_4: tanh\n",
            "units_6: 52\n",
            "activation_6: relu\n",
            "units_7: 44\n",
            "activation_7: tanh\n",
            "Score: 0.1151130273938179\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "units_1: 44\n",
            "activation_1: tanh\n",
            "units_2: 48\n",
            "activation_2: tanh\n",
            "units_4: 6\n",
            "activation_4: relu\n",
            "units_6: 48\n",
            "activation_6: tanh\n",
            "units_7: 32\n",
            "activation_7: relu\n",
            "Score: 0.24961501359939575\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "units_1: 32\n",
            "activation_1: tanh\n",
            "units_2: 44\n",
            "activation_2: tanh\n",
            "units_4: 18\n",
            "activation_4: relu\n",
            "units_6: 24\n",
            "activation_6: tanh\n",
            "units_7: 52\n",
            "activation_7: relu\n",
            "Score: 0.24990229308605194\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "units_1: 44\n",
            "activation_1: tanh\n",
            "units_2: 24\n",
            "activation_2: tanh\n",
            "units_4: 14\n",
            "activation_4: tanh\n",
            "units_6: 36\n",
            "activation_6: tanh\n",
            "units_7: 44\n",
            "activation_7: tanh\n",
            "Score: 0.2499535083770752\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "units_1: 32\n",
            "activation_1: tanh\n",
            "units_2: 28\n",
            "activation_2: relu\n",
            "units_4: 18\n",
            "activation_4: relu\n",
            "units_6: 48\n",
            "activation_6: tanh\n",
            "units_7: 32\n",
            "activation_7: tanh\n",
            "Score: 0.24999377131462097\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "units_1: 52\n",
            "activation_1: tanh\n",
            "units_2: 48\n",
            "activation_2: relu\n",
            "units_4: 22\n",
            "activation_4: relu\n",
            "units_6: 40\n",
            "activation_6: tanh\n",
            "units_7: 36\n",
            "activation_7: relu\n",
            "Score: 0.2500130832195282\n"
          ]
        }
      ],
      "source": [
        "tun1.results_summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fZprKi59q-gy",
        "outputId": "93de6d8d-88a5-4a94-90cc-70475c2e4294"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Results summary\n",
            "Results in ./untitled_project\n",
            "Showing 10 best trials\n",
            "<keras_tuner.engine.objective.Objective object at 0x7f5c2de375d0>\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "units_1: 52\n",
            "activation_1: relu\n",
            "units_2: 32\n",
            "activation_2: tanh\n",
            "units_4: 18\n",
            "activation_4: tanh\n",
            "units_6: 32\n",
            "activation_6: relu\n",
            "units_7: 44\n",
            "activation_7: relu\n",
            "learning_rate: 0.0006929396347746626\n",
            "Score: 0.1442972719669342\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "units_1: 52\n",
            "activation_1: relu\n",
            "units_2: 48\n",
            "activation_2: relu\n",
            "units_4: 10\n",
            "activation_4: relu\n",
            "units_6: 36\n",
            "activation_6: relu\n",
            "units_7: 36\n",
            "activation_7: tanh\n",
            "learning_rate: 0.001187322060360933\n",
            "Score: 0.1738615483045578\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "units_1: 52\n",
            "activation_1: relu\n",
            "units_2: 28\n",
            "activation_2: relu\n",
            "units_4: 14\n",
            "activation_4: relu\n",
            "units_6: 44\n",
            "activation_6: relu\n",
            "units_7: 32\n",
            "activation_7: relu\n",
            "learning_rate: 0.0004247686756839466\n",
            "Score: 0.17447614669799805\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "units_1: 48\n",
            "activation_1: relu\n",
            "units_2: 48\n",
            "activation_2: relu\n",
            "units_4: 2\n",
            "activation_4: relu\n",
            "units_6: 32\n",
            "activation_6: tanh\n",
            "units_7: 32\n",
            "activation_7: relu\n",
            "learning_rate: 0.0010195867676497958\n",
            "Score: 0.18200859427452087\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "units_1: 32\n",
            "activation_1: relu\n",
            "units_2: 40\n",
            "activation_2: relu\n",
            "units_4: 18\n",
            "activation_4: tanh\n",
            "units_6: 52\n",
            "activation_6: relu\n",
            "units_7: 52\n",
            "activation_7: relu\n",
            "learning_rate: 0.004509672398897384\n",
            "Score: 0.21461760997772217\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "units_1: 40\n",
            "activation_1: tanh\n",
            "units_2: 44\n",
            "activation_2: tanh\n",
            "units_4: 30\n",
            "activation_4: relu\n",
            "units_6: 44\n",
            "activation_6: tanh\n",
            "units_7: 36\n",
            "activation_7: tanh\n",
            "learning_rate: 0.00012019804157669328\n",
            "Score: 0.22181108593940735\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "units_1: 32\n",
            "activation_1: tanh\n",
            "units_2: 44\n",
            "activation_2: relu\n",
            "units_4: 6\n",
            "activation_4: tanh\n",
            "units_6: 40\n",
            "activation_6: tanh\n",
            "units_7: 48\n",
            "activation_7: tanh\n",
            "learning_rate: 0.00015594455412571505\n",
            "Score: 0.2412596195936203\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "units_1: 44\n",
            "activation_1: tanh\n",
            "units_2: 32\n",
            "activation_2: tanh\n",
            "units_4: 30\n",
            "activation_4: tanh\n",
            "units_6: 48\n",
            "activation_6: relu\n",
            "units_7: 40\n",
            "activation_7: relu\n",
            "learning_rate: 0.000972451322511578\n",
            "Score: 0.2497463971376419\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "units_1: 44\n",
            "activation_1: tanh\n",
            "units_2: 28\n",
            "activation_2: tanh\n",
            "units_4: 26\n",
            "activation_4: tanh\n",
            "units_6: 32\n",
            "activation_6: tanh\n",
            "units_7: 32\n",
            "activation_7: relu\n",
            "learning_rate: 0.0003905971785546966\n",
            "Score: 0.25352194905281067\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "units_1: 28\n",
            "activation_1: tanh\n",
            "units_2: 52\n",
            "activation_2: relu\n",
            "units_4: 26\n",
            "activation_4: relu\n",
            "units_6: 24\n",
            "activation_6: tanh\n",
            "units_7: 52\n",
            "activation_7: tanh\n",
            "learning_rate: 0.0004442210821656491\n",
            "Score: 0.25626295804977417\n"
          ]
        }
      ],
      "source": [
        "tun1L.results_summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NCC3GQ6N4D8w",
        "outputId": "d23f0c96-82f2-4cde-ac81-05c5d6f0b991"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_6 (Dense)             (None, 40)                480       \n",
            "                                                                 \n",
            " batch_normalization_7 (Batc  (None, 40)               160       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " dropout_5 (Dropout)         (None, 40)                0         \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 44)                1804      \n",
            "                                                                 \n",
            " batch_normalization_8 (Batc  (None, 44)               176       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " dropout_6 (Dropout)         (None, 44)                0         \n",
            "                                                                 \n",
            " batch_normalization_9 (Batc  (None, 44)               176       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " dropout_7 (Dropout)         (None, 44)                0         \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 18)                810       \n",
            "                                                                 \n",
            " batch_normalization_10 (Bat  (None, 18)               72        \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " dropout_8 (Dropout)         (None, 18)                0         \n",
            "                                                                 \n",
            " batch_normalization_11 (Bat  (None, 18)               72        \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 24)                456       \n",
            "                                                                 \n",
            " batch_normalization_12 (Bat  (None, 24)               96        \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 36)                900       \n",
            "                                                                 \n",
            " batch_normalization_13 (Bat  (None, 36)               144       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " dropout_9 (Dropout)         (None, 36)                0         \n",
            "                                                                 \n",
            " dense_11 (Dense)            (None, 1)                 37        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,383\n",
            "Trainable params: 4,935\n",
            "Non-trainable params: 448\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model2.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JPY1e2LaGfWz"
      },
      "outputs": [],
      "source": [
        "loss_fn=keras.losses.MeanSquaredError()\n",
        "optimizer=keras.optimizers.Adam(learning_rate=0.01)\n",
        "train_acc_metric=keras.metrics.MeanSquaredError()\n",
        "val_acc_metric=keras.metrics.MeanSquaredError()\n",
        "\n",
        "@tf.function\n",
        "def train_step(x,y):\n",
        "    with tf.GradientTape() as tape:\n",
        "        logits=model2(x,training=True)\n",
        "        loss_value=loss_fn(y,logits)\n",
        "    grads=tape.gradient(loss_value,model2.trainable_weights )\n",
        "    train_acc_metric.update_state(y,logits)\n",
        "    return loss_value\n",
        "@tf.function\n",
        "def test_step(x, y):\n",
        "    val_logits = model2(x, training=False)\n",
        "    val_acc_metric.update_state(y, val_logits)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zTx-r7i2a0er",
        "outputId": "6678f927-0e91-4dc2-9964-825c4f269f03"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Start of epoch 0\n",
            "Training loss (for one batch) at step 0: 0.3339\n",
            "Seen so far: 164 samples\n",
            "Training acc over epoch: 0.3163\n",
            "Validation acc: 0.2866\n",
            "Time taken: 4.49s\n",
            "\n",
            "Start of epoch 1\n",
            "Training loss (for one batch) at step 0: 0.2991\n",
            "Seen so far: 164 samples\n",
            "Training acc over epoch: 0.3175\n",
            "Validation acc: 0.2862\n",
            "Time taken: 0.24s\n",
            "\n",
            "Start of epoch 2\n",
            "Training loss (for one batch) at step 0: 0.3142\n",
            "Seen so far: 164 samples\n",
            "Training acc over epoch: 0.3177\n",
            "Validation acc: 0.2853\n",
            "Time taken: 0.24s\n",
            "\n",
            "Start of epoch 3\n",
            "Training loss (for one batch) at step 0: 0.2942\n",
            "Seen so far: 164 samples\n",
            "Training acc over epoch: 0.3152\n",
            "Validation acc: 0.2860\n",
            "Time taken: 0.31s\n",
            "\n",
            "Start of epoch 4\n",
            "Training loss (for one batch) at step 0: 0.3575\n",
            "Seen so far: 164 samples\n",
            "Training acc over epoch: 0.3179\n",
            "Validation acc: 0.2860\n",
            "Time taken: 0.31s\n",
            "\n",
            "Start of epoch 5\n",
            "Training loss (for one batch) at step 0: 0.3052\n",
            "Seen so far: 164 samples\n",
            "Training acc over epoch: 0.3207\n",
            "Validation acc: 0.2855\n",
            "Time taken: 0.31s\n",
            "\n",
            "Start of epoch 6\n",
            "Training loss (for one batch) at step 0: 0.3520\n",
            "Seen so far: 164 samples\n",
            "Training acc over epoch: 0.3190\n",
            "Validation acc: 0.2858\n",
            "Time taken: 0.24s\n",
            "\n",
            "Start of epoch 7\n",
            "Training loss (for one batch) at step 0: 0.2898\n",
            "Seen so far: 164 samples\n",
            "Training acc over epoch: 0.3146\n",
            "Validation acc: 0.2859\n",
            "Time taken: 0.24s\n",
            "\n",
            "Start of epoch 8\n",
            "Training loss (for one batch) at step 0: 0.3461\n",
            "Seen so far: 164 samples\n",
            "Training acc over epoch: 0.3179\n",
            "Validation acc: 0.2861\n",
            "Time taken: 0.24s\n",
            "\n",
            "Start of epoch 9\n",
            "Training loss (for one batch) at step 0: 0.3288\n",
            "Seen so far: 164 samples\n",
            "Training acc over epoch: 0.3168\n",
            "Validation acc: 0.2856\n",
            "Time taken: 0.33s\n",
            "\n",
            "Start of epoch 10\n",
            "Training loss (for one batch) at step 0: 0.2989\n",
            "Seen so far: 164 samples\n",
            "Training acc over epoch: 0.3181\n",
            "Validation acc: 0.2857\n",
            "Time taken: 0.31s\n",
            "\n",
            "Start of epoch 11\n",
            "Training loss (for one batch) at step 0: 0.3542\n",
            "Seen so far: 164 samples\n",
            "Training acc over epoch: 0.3235\n",
            "Validation acc: 0.2859\n",
            "Time taken: 0.33s\n",
            "\n",
            "Start of epoch 12\n",
            "Training loss (for one batch) at step 0: 0.3043\n",
            "Seen so far: 164 samples\n",
            "Training acc over epoch: 0.3189\n",
            "Validation acc: 0.2855\n",
            "Time taken: 0.31s\n",
            "\n",
            "Start of epoch 13\n",
            "Training loss (for one batch) at step 0: 0.3000\n",
            "Seen so far: 164 samples\n",
            "Training acc over epoch: 0.3189\n",
            "Validation acc: 0.2850\n",
            "Time taken: 0.26s\n",
            "\n",
            "Start of epoch 14\n",
            "Training loss (for one batch) at step 0: 0.2928\n",
            "Seen so far: 164 samples\n",
            "Training acc over epoch: 0.3227\n",
            "Validation acc: 0.2852\n",
            "Time taken: 0.31s\n",
            "\n",
            "Start of epoch 15\n",
            "Training loss (for one batch) at step 0: 0.2920\n",
            "Seen so far: 164 samples\n",
            "Training acc over epoch: 0.3193\n",
            "Validation acc: 0.2856\n",
            "Time taken: 0.31s\n",
            "\n",
            "Start of epoch 16\n",
            "Training loss (for one batch) at step 0: 0.3143\n",
            "Seen so far: 164 samples\n",
            "Training acc over epoch: 0.3200\n",
            "Validation acc: 0.2854\n",
            "Time taken: 0.23s\n",
            "\n",
            "Start of epoch 17\n",
            "Training loss (for one batch) at step 0: 0.3041\n",
            "Seen so far: 164 samples\n",
            "Training acc over epoch: 0.3210\n",
            "Validation acc: 0.2856\n",
            "Time taken: 0.25s\n",
            "\n",
            "Start of epoch 18\n",
            "Training loss (for one batch) at step 0: 0.3090\n",
            "Seen so far: 164 samples\n",
            "Training acc over epoch: 0.3199\n",
            "Validation acc: 0.2849\n",
            "Time taken: 0.24s\n",
            "\n",
            "Start of epoch 19\n",
            "Training loss (for one batch) at step 0: 0.3119\n",
            "Seen so far: 164 samples\n",
            "Training acc over epoch: 0.3165\n",
            "Validation acc: 0.2845\n",
            "Time taken: 0.31s\n",
            "\n",
            "Start of epoch 20\n",
            "Training loss (for one batch) at step 0: 0.3332\n",
            "Seen so far: 164 samples\n",
            "Training acc over epoch: 0.3200\n",
            "Validation acc: 0.2850\n",
            "Time taken: 0.31s\n",
            "\n",
            "Start of epoch 21\n",
            "Training loss (for one batch) at step 0: 0.3139\n",
            "Seen so far: 164 samples\n",
            "Training acc over epoch: 0.3168\n",
            "Validation acc: 0.2855\n",
            "Time taken: 0.26s\n",
            "\n",
            "Start of epoch 22\n",
            "Training loss (for one batch) at step 0: 0.3182\n",
            "Seen so far: 164 samples\n",
            "Training acc over epoch: 0.3150\n",
            "Validation acc: 0.2855\n",
            "Time taken: 0.24s\n",
            "\n",
            "Start of epoch 23\n",
            "Training loss (for one batch) at step 0: 0.3117\n",
            "Seen so far: 164 samples\n",
            "Training acc over epoch: 0.3165\n",
            "Validation acc: 0.2856\n",
            "Time taken: 0.31s\n",
            "\n",
            "Start of epoch 24\n",
            "Training loss (for one batch) at step 0: 0.3433\n",
            "Seen so far: 164 samples\n",
            "Training acc over epoch: 0.3219\n",
            "Validation acc: 0.2859\n",
            "Time taken: 0.25s\n",
            "\n",
            "Start of epoch 25\n",
            "Training loss (for one batch) at step 0: 0.2994\n",
            "Seen so far: 164 samples\n",
            "Training acc over epoch: 0.3186\n",
            "Validation acc: 0.2859\n",
            "Time taken: 0.31s\n",
            "\n",
            "Start of epoch 26\n",
            "Training loss (for one batch) at step 0: 0.2965\n",
            "Seen so far: 164 samples\n",
            "Training acc over epoch: 0.3182\n",
            "Validation acc: 0.2862\n",
            "Time taken: 0.31s\n",
            "\n",
            "Start of epoch 27\n",
            "Training loss (for one batch) at step 0: 0.3263\n",
            "Seen so far: 164 samples\n",
            "Training acc over epoch: 0.3136\n",
            "Validation acc: 0.2854\n",
            "Time taken: 0.31s\n",
            "\n",
            "Start of epoch 28\n",
            "Training loss (for one batch) at step 0: 0.3289\n",
            "Seen so far: 164 samples\n",
            "Training acc over epoch: 0.3178\n",
            "Validation acc: 0.2859\n",
            "Time taken: 0.31s\n",
            "\n",
            "Start of epoch 29\n",
            "Training loss (for one batch) at step 0: 0.3045\n",
            "Seen so far: 164 samples\n",
            "Training acc over epoch: 0.3169\n",
            "Validation acc: 0.2855\n",
            "Time taken: 0.31s\n",
            "\n",
            "Start of epoch 30\n",
            "Training loss (for one batch) at step 0: 0.3362\n",
            "Seen so far: 164 samples\n",
            "Training acc over epoch: 0.3153\n",
            "Validation acc: 0.2853\n",
            "Time taken: 0.26s\n",
            "\n",
            "Start of epoch 31\n",
            "Training loss (for one batch) at step 0: 0.3317\n",
            "Seen so far: 164 samples\n",
            "Training acc over epoch: 0.3180\n",
            "Validation acc: 0.2855\n",
            "Time taken: 0.25s\n",
            "\n",
            "Start of epoch 32\n",
            "Training loss (for one batch) at step 0: 0.3053\n",
            "Seen so far: 164 samples\n",
            "Training acc over epoch: 0.3160\n",
            "Validation acc: 0.2852\n",
            "Time taken: 0.24s\n",
            "\n",
            "Start of epoch 33\n",
            "Training loss (for one batch) at step 0: 0.3453\n",
            "Seen so far: 164 samples\n",
            "Training acc over epoch: 0.3203\n",
            "Validation acc: 0.2852\n",
            "Time taken: 0.31s\n",
            "\n",
            "Start of epoch 34\n",
            "Training loss (for one batch) at step 0: 0.3221\n",
            "Seen so far: 164 samples\n",
            "Training acc over epoch: 0.3176\n",
            "Validation acc: 0.2861\n",
            "Time taken: 0.33s\n",
            "\n",
            "Start of epoch 35\n",
            "Training loss (for one batch) at step 0: 0.3131\n",
            "Seen so far: 164 samples\n",
            "Training acc over epoch: 0.3173\n",
            "Validation acc: 0.2858\n",
            "Time taken: 0.31s\n",
            "\n",
            "Start of epoch 36\n",
            "Training loss (for one batch) at step 0: 0.3283\n",
            "Seen so far: 164 samples\n",
            "Training acc over epoch: 0.3177\n",
            "Validation acc: 0.2861\n",
            "Time taken: 0.24s\n",
            "\n",
            "Start of epoch 37\n",
            "Training loss (for one batch) at step 0: 0.3354\n",
            "Seen so far: 164 samples\n",
            "Training acc over epoch: 0.3207\n",
            "Validation acc: 0.2861\n",
            "Time taken: 0.23s\n",
            "\n",
            "Start of epoch 38\n",
            "Training loss (for one batch) at step 0: 0.2940\n",
            "Seen so far: 164 samples\n",
            "Training acc over epoch: 0.3141\n",
            "Validation acc: 0.2862\n",
            "Time taken: 0.24s\n",
            "\n",
            "Start of epoch 39\n",
            "Training loss (for one batch) at step 0: 0.3215\n",
            "Seen so far: 164 samples\n",
            "Training acc over epoch: 0.3199\n",
            "Validation acc: 0.2860\n",
            "Time taken: 0.31s\n",
            "\n",
            "Start of epoch 40\n",
            "Training loss (for one batch) at step 0: 0.2946\n",
            "Seen so far: 164 samples\n",
            "Training acc over epoch: 0.3198\n",
            "Validation acc: 0.2853\n",
            "Time taken: 0.31s\n",
            "\n",
            "Start of epoch 41\n",
            "Training loss (for one batch) at step 0: 0.3435\n",
            "Seen so far: 164 samples\n",
            "Training acc over epoch: 0.3198\n",
            "Validation acc: 0.2856\n",
            "Time taken: 0.23s\n",
            "\n",
            "Start of epoch 42\n",
            "Training loss (for one batch) at step 0: 0.3213\n",
            "Seen so far: 164 samples\n",
            "Training acc over epoch: 0.3191\n",
            "Validation acc: 0.2851\n",
            "Time taken: 0.31s\n",
            "\n",
            "Start of epoch 43\n",
            "Training loss (for one batch) at step 0: 0.3104\n",
            "Seen so far: 164 samples\n",
            "Training acc over epoch: 0.3184\n",
            "Validation acc: 0.2843\n",
            "Time taken: 0.24s\n",
            "\n",
            "Start of epoch 44\n",
            "Training loss (for one batch) at step 0: 0.3514\n",
            "Seen so far: 164 samples\n",
            "Training acc over epoch: 0.3155\n",
            "Validation acc: 0.2848\n",
            "Time taken: 0.31s\n",
            "\n",
            "Start of epoch 45\n",
            "Training loss (for one batch) at step 0: 0.3372\n",
            "Seen so far: 164 samples\n",
            "Training acc over epoch: 0.3210\n",
            "Validation acc: 0.2856\n",
            "Time taken: 0.31s\n",
            "\n",
            "Start of epoch 46\n",
            "Training loss (for one batch) at step 0: 0.3125\n",
            "Seen so far: 164 samples\n",
            "Training acc over epoch: 0.3148\n",
            "Validation acc: 0.2860\n",
            "Time taken: 0.31s\n",
            "\n",
            "Start of epoch 47\n",
            "Training loss (for one batch) at step 0: 0.3226\n",
            "Seen so far: 164 samples\n",
            "Training acc over epoch: 0.3152\n",
            "Validation acc: 0.2857\n",
            "Time taken: 0.23s\n",
            "\n",
            "Start of epoch 48\n",
            "Training loss (for one batch) at step 0: 0.3681\n",
            "Seen so far: 164 samples\n",
            "Training acc over epoch: 0.3171\n",
            "Validation acc: 0.2849\n",
            "Time taken: 0.24s\n",
            "\n",
            "Start of epoch 49\n",
            "Training loss (for one batch) at step 0: 0.2949\n",
            "Seen so far: 164 samples\n",
            "Training acc over epoch: 0.3164\n",
            "Validation acc: 0.2855\n",
            "Time taken: 0.24s\n",
            "\n",
            "Start of epoch 50\n",
            "Training loss (for one batch) at step 0: 0.3236\n",
            "Seen so far: 164 samples\n",
            "Training acc over epoch: 0.3193\n",
            "Validation acc: 0.2859\n",
            "Time taken: 0.27s\n",
            "\n",
            "Start of epoch 51\n",
            "Training loss (for one batch) at step 0: 0.3139\n",
            "Seen so far: 164 samples\n",
            "Training acc over epoch: 0.3205\n",
            "Validation acc: 0.2860\n",
            "Time taken: 0.31s\n",
            "\n",
            "Start of epoch 52\n",
            "Training loss (for one batch) at step 0: 0.3530\n",
            "Seen so far: 164 samples\n",
            "Training acc over epoch: 0.3189\n",
            "Validation acc: 0.2862\n",
            "Time taken: 0.31s\n",
            "\n",
            "Start of epoch 53\n",
            "Training loss (for one batch) at step 0: 0.3092\n",
            "Seen so far: 164 samples\n",
            "Training acc over epoch: 0.3214\n",
            "Validation acc: 0.2860\n",
            "Time taken: 0.31s\n",
            "\n",
            "Start of epoch 54\n",
            "Training loss (for one batch) at step 0: 0.3448\n",
            "Seen so far: 164 samples\n",
            "Training acc over epoch: 0.3164\n",
            "Validation acc: 0.2857\n",
            "Time taken: 0.31s\n",
            "\n",
            "Start of epoch 55\n",
            "Training loss (for one batch) at step 0: 0.3031\n",
            "Seen so far: 164 samples\n",
            "Training acc over epoch: 0.3187\n",
            "Validation acc: 0.2852\n",
            "Time taken: 0.31s\n",
            "\n",
            "Start of epoch 56\n",
            "Training loss (for one batch) at step 0: 0.3272\n",
            "Seen so far: 164 samples\n",
            "Training acc over epoch: 0.3200\n",
            "Validation acc: 0.2843\n",
            "Time taken: 0.31s\n",
            "\n",
            "Start of epoch 57\n",
            "Training loss (for one batch) at step 0: 0.3022\n",
            "Seen so far: 164 samples\n",
            "Training acc over epoch: 0.3159\n",
            "Validation acc: 0.2849\n",
            "Time taken: 0.24s\n",
            "\n",
            "Start of epoch 58\n",
            "Training loss (for one batch) at step 0: 0.3276\n",
            "Seen so far: 164 samples\n",
            "Training acc over epoch: 0.3176\n",
            "Validation acc: 0.2856\n",
            "Time taken: 0.24s\n",
            "\n",
            "Start of epoch 59\n",
            "Training loss (for one batch) at step 0: 0.2974\n",
            "Seen so far: 164 samples\n",
            "Training acc over epoch: 0.3179\n",
            "Validation acc: 0.2855\n",
            "Time taken: 0.31s\n",
            "\n",
            "Start of epoch 60\n",
            "Training loss (for one batch) at step 0: 0.3054\n",
            "Seen so far: 164 samples\n",
            "Training acc over epoch: 0.3175\n",
            "Validation acc: 0.2855\n",
            "Time taken: 0.31s\n",
            "\n",
            "Start of epoch 61\n",
            "Training loss (for one batch) at step 0: 0.3034\n",
            "Seen so far: 164 samples\n",
            "Training acc over epoch: 0.3162\n",
            "Validation acc: 0.2854\n",
            "Time taken: 0.26s\n",
            "\n",
            "Start of epoch 62\n",
            "Training loss (for one batch) at step 0: 0.3289\n",
            "Seen so far: 164 samples\n",
            "Training acc over epoch: 0.3148\n",
            "Validation acc: 0.2855\n",
            "Time taken: 0.31s\n",
            "\n",
            "Start of epoch 63\n",
            "Training loss (for one batch) at step 0: 0.3158\n",
            "Seen so far: 164 samples\n",
            "Training acc over epoch: 0.3205\n",
            "Validation acc: 0.2848\n",
            "Time taken: 0.31s\n",
            "\n",
            "Start of epoch 64\n",
            "Training loss (for one batch) at step 0: 0.3087\n",
            "Seen so far: 164 samples\n",
            "Training acc over epoch: 0.3227\n",
            "Validation acc: 0.2852\n",
            "Time taken: 0.31s\n",
            "\n",
            "Start of epoch 65\n",
            "Training loss (for one batch) at step 0: 0.3337\n",
            "Seen so far: 164 samples\n",
            "Training acc over epoch: 0.3170\n",
            "Validation acc: 0.2855\n",
            "Time taken: 0.31s\n",
            "\n",
            "Start of epoch 66\n",
            "Training loss (for one batch) at step 0: 0.3245\n",
            "Seen so far: 164 samples\n",
            "Training acc over epoch: 0.3192\n",
            "Validation acc: 0.2857\n",
            "Time taken: 0.31s\n",
            "\n",
            "Start of epoch 67\n",
            "Training loss (for one batch) at step 0: 0.3048\n",
            "Seen so far: 164 samples\n",
            "Training acc over epoch: 0.3165\n",
            "Validation acc: 0.2858\n",
            "Time taken: 0.25s\n",
            "\n",
            "Start of epoch 68\n",
            "Training loss (for one batch) at step 0: 0.2802\n",
            "Seen so far: 164 samples\n",
            "Training acc over epoch: 0.3152\n",
            "Validation acc: 0.2853\n",
            "Time taken: 0.31s\n",
            "\n",
            "Start of epoch 69\n",
            "Training loss (for one batch) at step 0: 0.3207\n",
            "Seen so far: 164 samples\n",
            "Training acc over epoch: 0.3192\n",
            "Validation acc: 0.2852\n",
            "Time taken: 0.31s\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "\n",
        "epochs = 70\n",
        "for epoch in range(epochs):\n",
        "    print(\"\\nStart of epoch %d\" % (epoch,))\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Iterate over the batches of the dataset.\n",
        "    for step, (x_batch_train,y_batch_train ) in enumerate(train_dataset):\n",
        "        loss_value = train_step(x_batch_train, y_batch_train)\n",
        "\n",
        "        # Log every 200 batches.\n",
        "        if step % 200 == 0:\n",
        "            print(\n",
        "                \"Training loss (for one batch) at step %d: %.4f\"\n",
        "                % (step, float(loss_value))\n",
        "            )\n",
        "            print(\"Seen so far: %d samples\" % ((step + 1) * batch_size))\n",
        "\n",
        "    # Display metrics at the end of each epoch.\n",
        "    train_acc = train_acc_metric.result()\n",
        "    print(\"Training acc over epoch: %.4f\" % (float(train_acc),))\n",
        "\n",
        "    # Reset training metrics at the end of each epoch\n",
        "    train_acc_metric.reset_states()\n",
        "\n",
        "\n",
        "    for x_batch_val, y_batch_val in val_dataset:\n",
        "        test_step(x_batch_val, y_batch_val)\n",
        "\n",
        "    val_acc = val_acc_metric.result()\n",
        "    val_acc_metric.reset_states()\n",
        "    print(\"Validation acc: %.4f\" % (float(val_acc),))\n",
        "    print(\"Time taken: %.2fs\" % (time.time() - start_time))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sgoXkIuEpC-J"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Px0JPribVWo"
      },
      "outputs": [],
      "source": [
        "training=training.drop(\"Unnamed: 0\",axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "ogNFUbm7byqk",
        "outputId": "378d8d5f-9317-4ed0-b191-ee8609ef1c8b"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-934c1964-4d1e-45af-8145-df68a5fa2a4b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>credit_score</th>\n",
              "      <th>country</th>\n",
              "      <th>gender</th>\n",
              "      <th>age</th>\n",
              "      <th>tenure</th>\n",
              "      <th>balance</th>\n",
              "      <th>products_number</th>\n",
              "      <th>credit_card</th>\n",
              "      <th>active_member</th>\n",
              "      <th>estimated_salary</th>\n",
              "      <th>churn</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-0.839783</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.436870</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.987657</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-1.125050</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.101940</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>-1.445631</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.034827</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.427989</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.443701</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.352225</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.225041</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.279804</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-1.665020</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.342498</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1.623358</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-934c1964-4d1e-45af-8145-df68a5fa2a4b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-934c1964-4d1e-45af-8145-df68a5fa2a4b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-934c1964-4d1e-45af-8145-df68a5fa2a4b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   credit_score  country  gender  age  tenure   balance  products_number  \\\n",
              "0     -0.839783        0       0  2.0     0.0  0.436870                1   \n",
              "1     -1.125050        0       1  3.0     0.0 -0.101940                1   \n",
              "2      1.034827        2       1  2.0     1.0  0.427989                1   \n",
              "3      0.352225        1       0  1.0     0.0  0.225041                1   \n",
              "4     -1.665020        1       0  1.0     1.0  0.342498                2   \n",
              "\n",
              "   credit_card  active_member  estimated_salary  churn  \n",
              "0            1              1          0.987657      0  \n",
              "1            0              0         -1.445631      1  \n",
              "2            1              0          0.443701      1  \n",
              "3            1              1          0.279804      1  \n",
              "4            1              1          1.623358      0  "
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "training.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "40fiWDVSizJn",
        "outputId": "de8b0ab7-6850-4069-aab6-941d1cdd3980"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 11944 entries, 0 to 11943\n",
            "Data columns (total 11 columns):\n",
            " #   Column            Non-Null Count  Dtype  \n",
            "---  ------            --------------  -----  \n",
            " 0   credit_score      11944 non-null  float64\n",
            " 1   country           11944 non-null  int64  \n",
            " 2   gender            11944 non-null  int64  \n",
            " 3   age               11944 non-null  float64\n",
            " 4   tenure            11944 non-null  float64\n",
            " 5   balance           11944 non-null  float64\n",
            " 6   products_number   11944 non-null  int64  \n",
            " 7   credit_card       11944 non-null  int64  \n",
            " 8   active_member     11944 non-null  int64  \n",
            " 9   estimated_salary  11944 non-null  float64\n",
            " 10  churn             11944 non-null  int64  \n",
            "dtypes: float64(5), int64(6)\n",
            "memory usage: 1.0 MB\n"
          ]
        }
      ],
      "source": [
        "training.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "o7K4lfVNb5MG",
        "outputId": "26aa9d90-570e-427f-b57d-43eb67683454"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-d11b5855-1ba0-4daa-8d93-6dca0aa918a1\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>credit_score</th>\n",
              "      <th>country</th>\n",
              "      <th>gender</th>\n",
              "      <th>age</th>\n",
              "      <th>tenure</th>\n",
              "      <th>balance</th>\n",
              "      <th>products_number</th>\n",
              "      <th>credit_card</th>\n",
              "      <th>active_member</th>\n",
              "      <th>estimated_salary</th>\n",
              "      <th>churn</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>15802</td>\n",
              "      <td>0.718996</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.329709</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>-1.304275</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2757</td>\n",
              "      <td>-2.082732</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-1.328861</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1.060191</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>820</td>\n",
              "      <td>0.107710</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.838503</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.285781</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>8425</td>\n",
              "      <td>1.085768</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.584410</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>-1.372875</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>14670</td>\n",
              "      <td>-0.299814</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.538631</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1.254064</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d11b5855-1ba0-4daa-8d93-6dca0aa918a1')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d11b5855-1ba0-4daa-8d93-6dca0aa918a1 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d11b5855-1ba0-4daa-8d93-6dca0aa918a1');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   Unnamed: 0  credit_score  country  gender  age  tenure   balance  \\\n",
              "0       15802      0.718996        0       1  1.0     1.0  0.329709   \n",
              "1        2757     -2.082732        0       1  2.0     0.0 -1.328861   \n",
              "2         820      0.107710        2       0  1.0     0.0  0.838503   \n",
              "3        8425      1.085768        0       0  1.0     1.0  0.584410   \n",
              "4       14670     -0.299814        1       1  1.0     0.0  1.538631   \n",
              "\n",
              "   products_number  credit_card  active_member  estimated_salary  churn  \n",
              "0                1            1              0         -1.304275      1  \n",
              "1                2            1              0          1.060191      1  \n",
              "2                2            1              0         -0.285781      0  \n",
              "3                1            1              1         -1.372875      0  \n",
              "4                2            1              1          1.254064      1  "
            ]
          },
          "execution_count": 50,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wQLlyFRbgfAs"
      },
      "outputs": [],
      "source": [
        "testing=testing.drop('Unnamed: 0',axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rjbmnsLVgijU"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}